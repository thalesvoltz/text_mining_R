{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thalesvoltz/text_mining_R/blob/main/C%C3%B3pia_de_BA_Aplicado_ao_TM_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZbeSPbsio8B"
      },
      "source": [
        "# Disciplina de Business Analytics Aplicado ao Text Mining\n",
        "\n",
        "\n",
        "# Aula # 01 - Visão geral da Mineração de Textos\n",
        "\n",
        "#### Prof. Leandro Krug Wives\n",
        "\n",
        "Professor Titular do Instituto de Informática da UFRGS\n",
        "- http://www.inf.ufrgs.br/~wives\n",
        "- <font color=LightSteelBlue>leandro.wives@ufrgs.br </font>\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SjAHVwhrio8E"
      },
      "source": [
        "# Contexto e Necessidade\n",
        "\n",
        "**Necessitamos de dados, informações para tomarmos decisões** de maneira mais  assertiva e consistente, **minimizando riscos**.\n",
        "\n",
        "Porém, **temos acesso a uma vasta quantidade de dados**, seja na Web ou nos computadores empresariais e pessoais.\n",
        "\n",
        "O quadro seguinte apresenta alguns números de serviços que encontramos na Web, para que tenhamos uma ideia desse volume de dados:\n",
        "\n",
        "<center>\n",
        "\n",
        "| Serviço | Dados |\n",
        "|---|---|\n",
        "| Buscas Google | ~ 3.5 bilhões de consultas / dia\t|\n",
        "| E-mails | ~ 156 milhões / dia |\n",
        "| Tweets | ~ 500 milhões / dia |\n",
        "| Posts em Blogs | ~ 5.5 milhões / dia |\n",
        "\n",
        "<font size=1>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Fonte: https://www.internetlivestat.com/. Acesso em: 17/03/2023.</font>\n",
        "\n",
        "</center>\n",
        "\n",
        "Podemos perceber que **nossa capacidade de armazenamento de informações é muito maior do poderíamos consumir durante toda a nossa vida**!\n",
        "\n",
        "Mas qualquer informação serve?\n",
        "\n",
        "De qualquer forma:\n",
        "- as tecnologias e serviços que desenvolvemos ou consumimos produzem e propagam ainda mais a informação;\n",
        "- continuamos perdidos (*lost in the cyberspace*) e sobrecarregados por uma imensa quantidade de informação;\n",
        "- não somos capazes de administrar a quantidade de informações que é gerada.\n",
        "\n",
        "Uma alternativa consiste em **usarmos computadores, algoritmos e mecanismos de análise e mineração de dados para nos ajudar** a analisar essa massa de dados e resolver nossos problemas!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ca7Mdt-4io8L"
      },
      "source": [
        "# Mas o que é mineração afinal?\n",
        "\n",
        "<blockquote><font size=2>É o processo de <strong>extração de informação implícita</strong>, previamente desconhecida e potencialmente útil, sendo uma etapa do processo maior, de Descoberta de Conhecimento (Fayyard et al., 1996).</blockquote></font>\n",
        "\n",
        "Temos diferentes tipos de mineração: Mineração de Dados (**Data Mining**); Mineração de Textos (**Text Mining**); e Mineração na Web (**Web Mining**).\n",
        "\n",
        "Nesta disciplina, vamos estudar a Mineração de Textos (Text Mining).\n",
        "\n",
        "Mas antes, vamos revisitar alguns conceitos..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPXelASjio8L"
      },
      "source": [
        "# Conceitos Relevantes\n",
        "\n",
        "Antes de seguirmos adiante, vamos rever alguns conceitos importantes na área: Descoberta de Conhecimento e Análise de Dados.\n",
        "\n",
        "## Descoberta de Conhecimento\n",
        "\n",
        "Descobrir conhecimento significa <strong>identificar/receber informação relevante</strong> e poder <strong>computá-la</strong> e <strong>agregá-la</strong> ao seu <strong>conhecimento prévio</strong>, mudando o estado de conhecimento atual, a fim de <strong>resolver algum problema</strong> ou situação.\n",
        "\n",
        "Observações:\n",
        "- é um processo complexo e subjetivo;\n",
        "- depende de um problema a ser resolvido (foco, objetivo);\n",
        "- dependente de um indivíduo (ou grupo) e de sua percepção sobre o problema,  capacidade de receber e computar informações relevantes, e capacidade de tomar decisões adequadas com base no seu estado de conhecimento.\n",
        "\n",
        "## Análise de Dados\n",
        "\n",
        "Ciência de examinar dados brutos com o objetivo de encontrar padrões e tirar conclusões sobre essa informação, aplicando um processo algorítmico ou mecânico para obter informações.\n",
        "\n",
        "Pode ser de vários tipos:\n",
        "\n",
        "- descritiva (exploratória): consiste no uso de métricas e técnicas estatísticos para entender e explicar como os dados são;\n",
        "- preditiva: uso de modelos estatísticos para avaliar como serão os dados no futuro (ou como se comportam em condições diversas);\n",
        "- prescritiva: uso de ferramentas estatísticas (descritivas e preditivas), alinhadas à gestão de negócios, para gerar recomendações de ações a serem tomadas de forma (semi)automática para otimizar estratégias adotadas pelas empresas e alcançar melhores resultados no menor espaço de tempo;\n",
        "- diagnóstica: busca compreender as causas de um evento, ou seja, responder \"quem?\", \"quando?\", \"onde?\", \"como?\", \"por que?\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7OPMkGhio8L"
      },
      "source": [
        "# Mineração de Textos\n",
        "\n",
        "O texto é a forma mais predominante de dados disponível. Já na década de 90, Tan (1999) indicava que 80% das informações estavam nesse formato. Portanto, é relevante sabermos analisar, minerar esse tipo de dado.\n",
        "\n",
        "Mineração de Textos pode ser compreendida como o processo de derivar, obter (automaticamente) informações de alta qualidade a partir de dados textuais.\n",
        "\n",
        "A linguagem em si é vista como um dado (*Language as Data*):\n",
        "\n",
        "<blockquote><font size=2>A linguagem consiste em dados não estruturados produzidos por pessoas para serem compreendidos por outras pessoas. Por outro lado, os dados estruturados ou semiestruturados incluem campos ou marcações que permitem que sejam facilmente analisados por um computador. No entanto, embora não apresentem uma estrutura facilmente legível por máquina, os dados não estruturados não são aleatórios. Pelo contrário, são regidos por propriedades linguísticas que os tornam muito compreensíveis para outras pessoas (Begford, Bilbro e Ojeda, 2018).</font></blockquote>\n",
        "\n",
        "A mineração de textos possui diversas aplicações, entre elas:\n",
        "- filtragem de SPAM\n",
        "- análise de opiniões, sentimentos, polaridade\n",
        "- análise de mídias sociais\n",
        "- análise forense\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Etapas abstratas\n",
        "\n",
        "- Coleta de Dados;\n",
        "- Pré-processamento e limpeza de dados;\n",
        "- Representação do conteúdo;\n",
        "- Mineração propriamente dita;\n",
        "- Visualização / compreensão do resultado.\n"
      ],
      "metadata": {
        "id": "JEcYoxnWEd-7"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZ9CGMzfio8N"
      },
      "source": [
        "# Pré-processamento e limpeza de dados textuais <img src=\"https://media.giphy.com/media/kXBVtKjLxINji/giphy.gif\" width=\"120\" height=\"120\" align=\"right\"/>\n",
        "- **Tokenização (identificação de termos /palavras)**\n",
        "- Minimização de erros ortográficos\n",
        "- **Eliminação de stopwords (palavras-vazias)**\n",
        "- ***Stemmização* / lematização (minimização de variações morfológicas)**\n",
        "- Identificação de entidades mencionadas/nomeadas\n",
        "- Resolução de anáforas"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vamos praticar?\n",
        "\n",
        "Para identificarmos os elementos textuais (palavras ou termos), podemos fazer uso da biblioteca [`tokenizers`](https://github.com/ropensci/tokenizers). Ele oferece um conjunto de funções que convertem textos em `tokens`, de diferentes maneiras.\n",
        "\n",
        "Segue um exemplo:"
      ],
      "metadata": {
        "id": "akUR1f-cI7nB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-11-10T17:44:59.046850Z",
          "start_time": "2020-11-10T17:44:58.976Z"
        },
        "id": "hu_R2WrLio8N",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "de107d35-c475-4a88-9e6d-6e58c4bd3497"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading required package: tokenizers\n",
            "\n",
            "Warning message in library(package, lib.loc = lib.loc, character.only = TRUE, logical.return = TRUE, :\n",
            "“there is no package called ‘tokenizers’”\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "also installing the dependencies ‘Rcpp’, ‘SnowballC’\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<ol>\n",
              "\t<li><style>\n",
              ".list-inline {list-style: none; margin:0; padding: 0}\n",
              ".list-inline>li {display: inline-block}\n",
              ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
              "</style>\n",
              "<ol class=list-inline><li>'violência'</li><li>'simbólica'</li><li>'é'</li><li>'um'</li><li>'conceito'</li><li>'social'</li><li>'elaborado'</li><li>'pelo'</li><li>'sociólogo'</li><li>'francês'</li><li>'pierre'</li><li>'bourdieu'</li><li>'o'</li><li>'qual'</li><li>'aborda'</li><li>'uma'</li><li>'forma'</li><li>'de'</li><li>'violência'</li><li>'exercida'</li><li>'pelo'</li><li>'corpo'</li><li>'sem'</li><li>'coação'</li><li>'física'</li><li>'causando'</li><li>'danos'</li><li>'morais'</li><li>'e'</li><li>'psicológicos'</li></ol>\n",
              "</li>\n",
              "</ol>\n"
            ],
            "text/markdown": "1. 1. 'violência'\n2. 'simbólica'\n3. 'é'\n4. 'um'\n5. 'conceito'\n6. 'social'\n7. 'elaborado'\n8. 'pelo'\n9. 'sociólogo'\n10. 'francês'\n11. 'pierre'\n12. 'bourdieu'\n13. 'o'\n14. 'qual'\n15. 'aborda'\n16. 'uma'\n17. 'forma'\n18. 'de'\n19. 'violência'\n20. 'exercida'\n21. 'pelo'\n22. 'corpo'\n23. 'sem'\n24. 'coação'\n25. 'física'\n26. 'causando'\n27. 'danos'\n28. 'morais'\n29. 'e'\n30. 'psicológicos'\n\n\n\n\n\n",
            "text/latex": "\\begin{enumerate}\n\\item \\begin{enumerate*}\n\\item 'violência'\n\\item 'simbólica'\n\\item 'é'\n\\item 'um'\n\\item 'conceito'\n\\item 'social'\n\\item 'elaborado'\n\\item 'pelo'\n\\item 'sociólogo'\n\\item 'francês'\n\\item 'pierre'\n\\item 'bourdieu'\n\\item 'o'\n\\item 'qual'\n\\item 'aborda'\n\\item 'uma'\n\\item 'forma'\n\\item 'de'\n\\item 'violência'\n\\item 'exercida'\n\\item 'pelo'\n\\item 'corpo'\n\\item 'sem'\n\\item 'coação'\n\\item 'física'\n\\item 'causando'\n\\item 'danos'\n\\item 'morais'\n\\item 'e'\n\\item 'psicológicos'\n\\end{enumerate*}\n\n\\end{enumerate}\n",
            "text/plain": [
              "[[1]]\n",
              " [1] \"violência\"    \"simbólica\"    \"é\"            \"um\"           \"conceito\"    \n",
              " [6] \"social\"       \"elaborado\"    \"pelo\"         \"sociólogo\"    \"francês\"     \n",
              "[11] \"pierre\"       \"bourdieu\"     \"o\"            \"qual\"         \"aborda\"      \n",
              "[16] \"uma\"          \"forma\"        \"de\"           \"violência\"    \"exercida\"    \n",
              "[21] \"pelo\"         \"corpo\"        \"sem\"          \"coação\"       \"física\"      \n",
              "[26] \"causando\"     \"danos\"        \"morais\"       \"e\"            \"psicológicos\"\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "if(!require('tokenizers')) install.packages('tokenizers')\n",
        "\n",
        "library(tokenizers)\n",
        "\n",
        "text <- paste0(\n",
        "  \"Violência simbólica é um conceito social elaborado pelo\\n\",\n",
        "  \"sociólogo francês Pierre Bourdieu, o qual aborda uma forma\\n\",\n",
        "  \"de violência exercida pelo corpo sem coação física, causando\\n\",\n",
        "  \"danos morais e psicológicos.\")\n",
        "\n",
        "tokenize_words(text) # converte o texto em uma lista de tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos melhorar colocando o resultado em um `data frame` (veja linha 11 do código seguinte).\n",
        "\n",
        "Um `data frame` é uma estrutura de dados que nos facilitará a manipulação no futuro."
      ],
      "metadata": {
        "id": "hTCC7AcRP8bL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if(!require('tokenizers')) install.packages('tokenizers')\n",
        "\n",
        "library(tokenizers)\n",
        "\n",
        "text <- paste0(\n",
        "  \"Violência simbólica é um conceito social elaborado pelo\\n\",\n",
        "  \"sociólogo francês Pierre Bourdieu, o qual aborda uma forma\\n\",\n",
        "  \"de violência exercida pelo corpo sem coação física, causando\\n\",\n",
        "  \"danos morais e psicológicos.\")\n",
        "\n",
        "lst_words <- tokenize_words(text)\n",
        "\n",
        "df_words <- data.frame(Reduce(rbind, lst_words)) # Cria um data frame contendo uma coluna com os tokens\n",
        "\n",
        "head(df_words,n=10) # lista 10 primeiras"
      ],
      "metadata": {
        "id": "pCguTmq0QE-6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        },
        "outputId": "382af2ac-36fe-40b3-ca89-7bf46889561c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A data.frame: 10 × 1</caption>\n",
              "<thead>\n",
              "\t<tr><th></th><th scope=col>Reduce.rbind..lst_words.</th></tr>\n",
              "\t<tr><th></th><th scope=col>&lt;chr&gt;</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><th scope=row>1</th><td>violência</td></tr>\n",
              "\t<tr><th scope=row>2</th><td>simbólica</td></tr>\n",
              "\t<tr><th scope=row>3</th><td>é        </td></tr>\n",
              "\t<tr><th scope=row>4</th><td>um       </td></tr>\n",
              "\t<tr><th scope=row>5</th><td>conceito </td></tr>\n",
              "\t<tr><th scope=row>6</th><td>social   </td></tr>\n",
              "\t<tr><th scope=row>7</th><td>elaborado</td></tr>\n",
              "\t<tr><th scope=row>8</th><td>pelo     </td></tr>\n",
              "\t<tr><th scope=row>9</th><td>sociólogo</td></tr>\n",
              "\t<tr><th scope=row>10</th><td>francês  </td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ],
            "text/markdown": "\nA data.frame: 10 × 1\n\n| <!--/--> | Reduce.rbind..lst_words. &lt;chr&gt; |\n|---|---|\n| 1 | violência |\n| 2 | simbólica |\n| 3 | é         |\n| 4 | um        |\n| 5 | conceito  |\n| 6 | social    |\n| 7 | elaborado |\n| 8 | pelo      |\n| 9 | sociólogo |\n| 10 | francês   |\n\n",
            "text/latex": "A data.frame: 10 × 1\n\\begin{tabular}{r|l}\n  & Reduce.rbind..lst\\_words.\\\\\n  & <chr>\\\\\n\\hline\n\t1 & violência\\\\\n\t2 & simbólica\\\\\n\t3 & é        \\\\\n\t4 & um       \\\\\n\t5 & conceito \\\\\n\t6 & social   \\\\\n\t7 & elaborado\\\\\n\t8 & pelo     \\\\\n\t9 & sociólogo\\\\\n\t10 & francês  \\\\\n\\end{tabular}\n",
            "text/plain": [
              "   Reduce.rbind..lst_words.\n",
              "1  violência               \n",
              "2  simbólica               \n",
              "3  é                       \n",
              "4  um                      \n",
              "5  conceito                \n",
              "6  social                  \n",
              "7  elaborado               \n",
              "8  pelo                    \n",
              "9  sociólogo               \n",
              "10 francês                 "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos trocar o nome da coluna para algo mais significativo (linha 13):"
      ],
      "metadata": {
        "id": "NBUsEoCKQr0L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if(!require('tokenizers')) install.packages('tokenizers')\n",
        "\n",
        "library(tokenizers)\n",
        "\n",
        "text <- paste0(\n",
        "  \"Violência simbólica é um conceito social elaborado pelo\\n\",\n",
        "  \"sociólogo francês Pierre Bourdieu, o qual aborda uma forma\\n\",\n",
        "  \"de violência exercida pelo corpo sem coação física, causando\\n\",\n",
        "  \"danos morais e psicológicos.\")\n",
        "\n",
        "lst_words <- tokenize_words(text)\n",
        "\n",
        "df_words <- data.frame(Reduce(rbind, lst_words))\n",
        "\n",
        "names(df_words)[names(df_words) == \"Reduce.rbind..lst_words.\"] <- \"termo\" # troca o nome da coluna\n",
        "\n",
        "head(df_words,n=10)"
      ],
      "metadata": {
        "id": "BN4Vi6qRQwb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        },
        "outputId": "eb4c0223-9b2f-4b3d-b564-39dcdae19bd6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A data.frame: 10 × 1</caption>\n",
              "<thead>\n",
              "\t<tr><th></th><th scope=col>termo</th></tr>\n",
              "\t<tr><th></th><th scope=col>&lt;chr&gt;</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><th scope=row>1</th><td>violência</td></tr>\n",
              "\t<tr><th scope=row>2</th><td>simbólica</td></tr>\n",
              "\t<tr><th scope=row>3</th><td>é        </td></tr>\n",
              "\t<tr><th scope=row>4</th><td>um       </td></tr>\n",
              "\t<tr><th scope=row>5</th><td>conceito </td></tr>\n",
              "\t<tr><th scope=row>6</th><td>social   </td></tr>\n",
              "\t<tr><th scope=row>7</th><td>elaborado</td></tr>\n",
              "\t<tr><th scope=row>8</th><td>pelo     </td></tr>\n",
              "\t<tr><th scope=row>9</th><td>sociólogo</td></tr>\n",
              "\t<tr><th scope=row>10</th><td>francês  </td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ],
            "text/markdown": "\nA data.frame: 10 × 1\n\n| <!--/--> | termo &lt;chr&gt; |\n|---|---|\n| 1 | violência |\n| 2 | simbólica |\n| 3 | é         |\n| 4 | um        |\n| 5 | conceito  |\n| 6 | social    |\n| 7 | elaborado |\n| 8 | pelo      |\n| 9 | sociólogo |\n| 10 | francês   |\n\n",
            "text/latex": "A data.frame: 10 × 1\n\\begin{tabular}{r|l}\n  & termo\\\\\n  & <chr>\\\\\n\\hline\n\t1 & violência\\\\\n\t2 & simbólica\\\\\n\t3 & é        \\\\\n\t4 & um       \\\\\n\t5 & conceito \\\\\n\t6 & social   \\\\\n\t7 & elaborado\\\\\n\t8 & pelo     \\\\\n\t9 & sociólogo\\\\\n\t10 & francês  \\\\\n\\end{tabular}\n",
            "text/plain": [
              "   termo    \n",
              "1  violência\n",
              "2  simbólica\n",
              "3  é        \n",
              "4  um       \n",
              "5  conceito \n",
              "6  social   \n",
              "7  elaborado\n",
              "8  pelo     \n",
              "9  sociólogo\n",
              "10 francês  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ao invés de usarmos os comandos mais básicos da `linguagem R`, podemos usar a biblioteca [`dplyr`](https://dplyr.tidyverse.org/). Ela fornece um conjunto de verbos (comandos) que facilitam a manipulação de dados, pois são mais abstratos (próximos do homem) e expressivos, tornando o código mais curto. São eles: `mutate`, `select`, `filter`, `summarise` e `arrange`.\n",
        "\n",
        "Além disso, ao invés de usarmos `data frames` tradicionais, vamos usar [`tibbles`](https://r4ds.had.co.nz/tibbles.html), que são mais amigáveis e simplificados, mas que servem bem ao nosso propósito.\n",
        "\n",
        "Veja como fica o código com esses elementos:"
      ],
      "metadata": {
        "id": "5JcgzEdVRA57"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if(!require('dplyr')) install.packages('dplyr')\n",
        "if(!require('tokenizers')) install.packages('tokenizers')\n",
        "\n",
        "library(dplyr, warn.conflicts = FALSE)\n",
        "library(tokenizers)\n",
        "\n",
        "text <- paste0(\n",
        "  \"Violência simbólica é um conceito social elaborado pelo\\n\",\n",
        "  \"sociólogo francês Pierre Bourdieu, o qual aborda uma forma\\n\",\n",
        "  \"de violência exercida pelo corpo sem coação física, causando\\n\",\n",
        "  \"danos morais e psicológicos.\")\n",
        "\n",
        "lst_words <- tokenize_words(text)\n",
        "\n",
        "# usa dplyr ao invés de R puro:\n",
        "df_words <- data.frame(Reduce(rbind, lst_words)) %>%\n",
        "  rename(\"termo\" = \"Reduce.rbind..lst_words.\")\n",
        "\n",
        "tb_words <- as_tibble(df_words)  # Converte o data frame em um tibble\n",
        "tb_words <- mutate(tb_words, termo = as.character(termo)) # muda o tipo da coluna \"termo\" para \"caracter\"\n",
        "\n",
        "head(tb_words,n=10)"
      ],
      "metadata": {
        "id": "CkKPo8XJSLPo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        },
        "outputId": "ab088dc6-8e84-4234-9d60-89e935116ed4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A tibble: 10 × 1</caption>\n",
              "<thead>\n",
              "\t<tr><th scope=col>termo</th></tr>\n",
              "\t<tr><th scope=col>&lt;chr&gt;</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><td>violência</td></tr>\n",
              "\t<tr><td>simbólica</td></tr>\n",
              "\t<tr><td>é        </td></tr>\n",
              "\t<tr><td>um       </td></tr>\n",
              "\t<tr><td>conceito </td></tr>\n",
              "\t<tr><td>social   </td></tr>\n",
              "\t<tr><td>elaborado</td></tr>\n",
              "\t<tr><td>pelo     </td></tr>\n",
              "\t<tr><td>sociólogo</td></tr>\n",
              "\t<tr><td>francês  </td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ],
            "text/markdown": "\nA tibble: 10 × 1\n\n| termo &lt;chr&gt; |\n|---|\n| violência |\n| simbólica |\n| é         |\n| um        |\n| conceito  |\n| social    |\n| elaborado |\n| pelo      |\n| sociólogo |\n| francês   |\n\n",
            "text/latex": "A tibble: 10 × 1\n\\begin{tabular}{l}\n termo\\\\\n <chr>\\\\\n\\hline\n\t violência\\\\\n\t simbólica\\\\\n\t é        \\\\\n\t um       \\\\\n\t conceito \\\\\n\t social   \\\\\n\t elaborado\\\\\n\t pelo     \\\\\n\t sociólogo\\\\\n\t francês  \\\\\n\\end{tabular}\n",
            "text/plain": [
              "   termo    \n",
              "1  violência\n",
              "2  simbólica\n",
              "3  é        \n",
              "4  um       \n",
              "5  conceito \n",
              "6  social   \n",
              "7  elaborado\n",
              "8  pelo     \n",
              "9  sociólogo\n",
              "10 francês  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Antes de seguirmos adiante, vamos experimentar outras funções de tokenização!\n",
        "\n",
        "---\n",
        "\n",
        "**Exercício 1**: experimentando diferentes funções de tokenização.\n",
        "\n",
        "Para este exercício, você necessitará de um texto de entrada. Você pode usar o mesmo texto fornecido pelo professor nos exemplos anteriores ou pode definir um texto próprio, usando a mesma sintaxe ou de outra forma que você conheça. Pode ainda carregar um texto de um arquivo ou da web (p.ex., usando a biblioteca `gutemberg`).\n",
        "\n",
        "De posse do texto, crie três *scripts*, cada um usando uma função de tokenização diferente (p.ex., `tokenize_ngrams`, `tokenize_character_shingles`, `tokenize_characters`). Você deve ilustrar os termos que foram identificados por cada função, colocando-os em um `tibble`.\n",
        "\n",
        "Para obter a lista completa de funções de tokenização disponíveis, consulte a página da biblioteca [`tokenizers`](https://github.com/ropensci/tokenizers)."
      ],
      "metadata": {
        "id": "24Lf2V-FN8mW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Script 01 - 'Tokezine_Ngrams'"
      ],
      "metadata": {
        "id": "l3bCTNNTuTi4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if(!require('tokenizers')) install.packages('tokenizers')\n",
        "\n",
        "library(tokenizers)\n",
        "\n",
        "# Texto de entrada\n",
        "text <- paste0(\n",
        "  \"Violência simbólica é um conceito social elaborado pelo\\n\",\n",
        "  \"sociólogo francês Pierre Bourdieu, o qual aborda uma forma\\n\",\n",
        "  \"de violência exercida pelo corpo sem coação física, causando\\n\",\n",
        "  \"danos morais e psicológicos.\")\n",
        "\n",
        "# Tokenização utilizando tokenize_ngrams\n",
        "lst_ngrams <- tokenize_ngrams(text, n = 1)\n",
        "\n",
        "# Criando um tibble com os termos identificados\n",
        "tb_ngrams <- tibble(termo = lst_ngrams)\n",
        "\n",
        "# Visualizando os primeiros termos identificados\n",
        "head(tb_ngrams, n = 10)\n"
      ],
      "metadata": {
        "id": "w0wE-tUhLV40"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Script 02 - 'tokenize_character_shingles'"
      ],
      "metadata": {
        "id": "vDnxpSAcvFZG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if(!require('tokenizers')) install.packages('tokenizers')\n",
        "\n",
        "library(tokenizers)\n",
        "\n",
        "# Texto de entrada\n",
        "text <- paste0(\n",
        "  \"Violência simbólica é um conceito social elaborado pelo\\n\",\n",
        "  \"sociólogo francês Pierre Bourdieu, o qual aborda uma forma\\n\",\n",
        "  \"de violência exercida pelo corpo sem coação física, causando\\n\",\n",
        "  \"danos morais e psicológicos.\")\n",
        "\n",
        "# Tokenização utilizando tokenize_character_shingles\n",
        "lst_shingles <- tokenize_character_shingles(text, n = 2)\n",
        "\n",
        "# Criando um tibble com os termos identificados\n",
        "tb_shingles <- tibble(termo = lst_shingles)\n",
        "\n",
        "# Visualizando os primeiros termos identificados\n",
        "head(tb_shingles, n = 10)"
      ],
      "metadata": {
        "id": "pqTVQKt85hoG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Script 03 - Utilizando 'tokenize_characters'"
      ],
      "metadata": {
        "id": "qIYR3_0Ev9gj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if(!require('tokenizers')) install.packages('tokenizers')\n",
        "\n",
        "library(tokenizers)\n",
        "\n",
        "# Texto de entrada\n",
        "text <- paste0(\n",
        "  \"Violência simbólica é um conceito social elaborado pelo\\n\",\n",
        "  \"sociólogo francês Pierre Bourdieu, o qual aborda uma forma\\n\",\n",
        "  \"de violência exercida pelo corpo sem coação física, causando\\n\",\n",
        "  \"danos morais e psicológicos.\")\n",
        "\n",
        "# Tokenização utilizando tokenize_characters\n",
        "lst_characters <- tokenize_characters(text)\n",
        "\n",
        "# Criando um tibble com os termos identificados\n",
        "tb_characters <- tibble(termo = lst_characters)\n",
        "\n",
        "# Visualizando os primeiros termos identificados\n",
        "head(tb_characters, n = 10)"
      ],
      "metadata": {
        "id": "5G6rmHjL5hs5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2CteG3tio8O"
      },
      "source": [
        "---\n",
        "Outra etapa comum consiste na remoção das *stopwords* (palavras-vazias), que são palavras normalmente utilizadas para conectar elementos. São, basicamente, preposições, artigos, pronomes, entre outros elementos, alguns específicos de domínio.\n",
        "\n",
        "A seguir, vamos carregar a lista de `stopwords` definidas pela comunidade, disponível na biblioteca `tm`, acrescentar algumas palavras e depois listá-las na tela:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# A biblioteca tidyverse inclui a dplyr e outras relevantes para o processamento de textos\n",
        "if(!require('tidytext')) install.packages('tidytext')\n",
        "if(!require('tokenizers')) install.packages('tokenizers')\n",
        "if(!require('tm')) install.packages('tm')\n",
        "\n",
        "library(tidytext)\n",
        "library(tokenizers)\n",
        "library(tm)\n",
        "\n",
        "# define lista de stopwords\n",
        "# carrega lista padrão da comunidade e acrescenta as palavras 'é' e 'um'\n",
        "# acrescente outras se considerar relevante\n",
        "custom_stop_words <- tibble(word = append(tm::stopwords('portuguese'), list('é', 'um')))\n",
        "custom_stop_words <- mutate(custom_stop_words, word = as.character(word))\n",
        "\n",
        "custom_stop_words$word"
      ],
      "metadata": {
        "id": "EWJ_-nzyNi9y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 572
        },
        "outputId": "f79b1c2a-90d8-43d7-f1bf-1578b9a4f53d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading required package: tidytext\n",
            "\n",
            "Warning message in library(package, lib.loc = lib.loc, character.only = TRUE, logical.return = TRUE, :\n",
            "“there is no package called ‘tidytext’”\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "also installing the dependency ‘janeaustenr’\n",
            "\n",
            "\n",
            "Loading required package: tm\n",
            "\n",
            "Warning message in library(package, lib.loc = lib.loc, character.only = TRUE, logical.return = TRUE, :\n",
            "“there is no package called ‘tm’”\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "also installing the dependencies ‘NLP’, ‘slam’, ‘BH’\n",
            "\n",
            "\n",
            "Loading required package: NLP\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style>\n",
              ".list-inline {list-style: none; margin:0; padding: 0}\n",
              ".list-inline>li {display: inline-block}\n",
              ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
              "</style>\n",
              "<ol class=list-inline><li>'de'</li><li>'a'</li><li>'o'</li><li>'que'</li><li>'e'</li><li>'do'</li><li>'da'</li><li>'em'</li><li>'um'</li><li>'para'</li><li>'com'</li><li>'não'</li><li>'uma'</li><li>'os'</li><li>'no'</li><li>'se'</li><li>'na'</li><li>'por'</li><li>'mais'</li><li>'as'</li><li>'dos'</li><li>'como'</li><li>'mas'</li><li>'ao'</li><li>'ele'</li><li>'das'</li><li>'à'</li><li>'seu'</li><li>'sua'</li><li>'ou'</li><li>'quando'</li><li>'muito'</li><li>'nos'</li><li>'já'</li><li>'eu'</li><li>'também'</li><li>'só'</li><li>'pelo'</li><li>'pela'</li><li>'até'</li><li>'isso'</li><li>'ela'</li><li>'entre'</li><li>'depois'</li><li>'sem'</li><li>'mesmo'</li><li>'aos'</li><li>'seus'</li><li>'quem'</li><li>'nas'</li><li>'me'</li><li>'esse'</li><li>'eles'</li><li>'você'</li><li>'essa'</li><li>'num'</li><li>'nem'</li><li>'suas'</li><li>'meu'</li><li>'às'</li><li>'minha'</li><li>'numa'</li><li>'pelos'</li><li>'elas'</li><li>'qual'</li><li>'nós'</li><li>'lhe'</li><li>'deles'</li><li>'essas'</li><li>'esses'</li><li>'pelas'</li><li>'este'</li><li>'dele'</li><li>'tu'</li><li>'te'</li><li>'vocês'</li><li>'vos'</li><li>'lhes'</li><li>'meus'</li><li>'minhas'</li><li>'teu'</li><li>'tua'</li><li>'teus'</li><li>'tuas'</li><li>'nosso'</li><li>'nossa'</li><li>'nossos'</li><li>'nossas'</li><li>'dela'</li><li>'delas'</li><li>'esta'</li><li>'estes'</li><li>'estas'</li><li>'aquele'</li><li>'aquela'</li><li>'aqueles'</li><li>'aquelas'</li><li>'isto'</li><li>'aquilo'</li><li>'estou'</li><li>'está'</li><li>'estamos'</li><li>'estão'</li><li>'estive'</li><li>'esteve'</li><li>'estivemos'</li><li>'estiveram'</li><li>'estava'</li><li>'estávamos'</li><li>'estavam'</li><li>'estivera'</li><li>'estivéramos'</li><li>'esteja'</li><li>'estejamos'</li><li>'estejam'</li><li>'estivesse'</li><li>'estivéssemos'</li><li>'estivessem'</li><li>'estiver'</li><li>'estivermos'</li><li>'estiverem'</li><li>'hei'</li><li>'há'</li><li>'havemos'</li><li>'hão'</li><li>'houve'</li><li>'houvemos'</li><li>'houveram'</li><li>'houvera'</li><li>'houvéramos'</li><li>'haja'</li><li>'hajamos'</li><li>'hajam'</li><li>'houvesse'</li><li>'houvéssemos'</li><li>'houvessem'</li><li>'houver'</li><li>'houvermos'</li><li>'houverem'</li><li>'houverei'</li><li>'houverá'</li><li>'houveremos'</li><li>'houverão'</li><li>'houveria'</li><li>'houveríamos'</li><li>'houveriam'</li><li>'sou'</li><li>'somos'</li><li>'são'</li><li>'era'</li><li>'éramos'</li><li>'eram'</li><li>'fui'</li><li>'foi'</li><li>'fomos'</li><li>'foram'</li><li>'fora'</li><li>'fôramos'</li><li>'seja'</li><li>'sejamos'</li><li>'sejam'</li><li>'fosse'</li><li>'fôssemos'</li><li>'fossem'</li><li>'for'</li><li>'formos'</li><li>'forem'</li><li>'serei'</li><li>'será'</li><li>'seremos'</li><li>'serão'</li><li>'seria'</li><li>'seríamos'</li><li>'seriam'</li><li>'tenho'</li><li>'tem'</li><li>'temos'</li><li>'tém'</li><li>'tinha'</li><li>'tínhamos'</li><li>'tinham'</li><li>'tive'</li><li>'teve'</li><li>'tivemos'</li><li>'tiveram'</li><li>'tivera'</li><li>'tivéramos'</li><li>'tenha'</li><li>'tenhamos'</li><li>'tenham'</li><li>'tivesse'</li><li>'tivéssemos'</li><li>'tivessem'</li><li>'tiver'</li><li>'tivermos'</li><li>'tiverem'</li><li>'terei'</li><li>'terá'</li><li>'teremos'</li><li>'terão'</li><li>'teria'</li><li>'teríamos'</li><li>'teriam'</li><li>'é'</li><li>'um'</li></ol>\n"
            ],
            "text/markdown": "1. 'de'\n2. 'a'\n3. 'o'\n4. 'que'\n5. 'e'\n6. 'do'\n7. 'da'\n8. 'em'\n9. 'um'\n10. 'para'\n11. 'com'\n12. 'não'\n13. 'uma'\n14. 'os'\n15. 'no'\n16. 'se'\n17. 'na'\n18. 'por'\n19. 'mais'\n20. 'as'\n21. 'dos'\n22. 'como'\n23. 'mas'\n24. 'ao'\n25. 'ele'\n26. 'das'\n27. 'à'\n28. 'seu'\n29. 'sua'\n30. 'ou'\n31. 'quando'\n32. 'muito'\n33. 'nos'\n34. 'já'\n35. 'eu'\n36. 'também'\n37. 'só'\n38. 'pelo'\n39. 'pela'\n40. 'até'\n41. 'isso'\n42. 'ela'\n43. 'entre'\n44. 'depois'\n45. 'sem'\n46. 'mesmo'\n47. 'aos'\n48. 'seus'\n49. 'quem'\n50. 'nas'\n51. 'me'\n52. 'esse'\n53. 'eles'\n54. 'você'\n55. 'essa'\n56. 'num'\n57. 'nem'\n58. 'suas'\n59. 'meu'\n60. 'às'\n61. 'minha'\n62. 'numa'\n63. 'pelos'\n64. 'elas'\n65. 'qual'\n66. 'nós'\n67. 'lhe'\n68. 'deles'\n69. 'essas'\n70. 'esses'\n71. 'pelas'\n72. 'este'\n73. 'dele'\n74. 'tu'\n75. 'te'\n76. 'vocês'\n77. 'vos'\n78. 'lhes'\n79. 'meus'\n80. 'minhas'\n81. 'teu'\n82. 'tua'\n83. 'teus'\n84. 'tuas'\n85. 'nosso'\n86. 'nossa'\n87. 'nossos'\n88. 'nossas'\n89. 'dela'\n90. 'delas'\n91. 'esta'\n92. 'estes'\n93. 'estas'\n94. 'aquele'\n95. 'aquela'\n96. 'aqueles'\n97. 'aquelas'\n98. 'isto'\n99. 'aquilo'\n100. 'estou'\n101. 'está'\n102. 'estamos'\n103. 'estão'\n104. 'estive'\n105. 'esteve'\n106. 'estivemos'\n107. 'estiveram'\n108. 'estava'\n109. 'estávamos'\n110. 'estavam'\n111. 'estivera'\n112. 'estivéramos'\n113. 'esteja'\n114. 'estejamos'\n115. 'estejam'\n116. 'estivesse'\n117. 'estivéssemos'\n118. 'estivessem'\n119. 'estiver'\n120. 'estivermos'\n121. 'estiverem'\n122. 'hei'\n123. 'há'\n124. 'havemos'\n125. 'hão'\n126. 'houve'\n127. 'houvemos'\n128. 'houveram'\n129. 'houvera'\n130. 'houvéramos'\n131. 'haja'\n132. 'hajamos'\n133. 'hajam'\n134. 'houvesse'\n135. 'houvéssemos'\n136. 'houvessem'\n137. 'houver'\n138. 'houvermos'\n139. 'houverem'\n140. 'houverei'\n141. 'houverá'\n142. 'houveremos'\n143. 'houverão'\n144. 'houveria'\n145. 'houveríamos'\n146. 'houveriam'\n147. 'sou'\n148. 'somos'\n149. 'são'\n150. 'era'\n151. 'éramos'\n152. 'eram'\n153. 'fui'\n154. 'foi'\n155. 'fomos'\n156. 'foram'\n157. 'fora'\n158. 'fôramos'\n159. 'seja'\n160. 'sejamos'\n161. 'sejam'\n162. 'fosse'\n163. 'fôssemos'\n164. 'fossem'\n165. 'for'\n166. 'formos'\n167. 'forem'\n168. 'serei'\n169. 'será'\n170. 'seremos'\n171. 'serão'\n172. 'seria'\n173. 'seríamos'\n174. 'seriam'\n175. 'tenho'\n176. 'tem'\n177. 'temos'\n178. 'tém'\n179. 'tinha'\n180. 'tínhamos'\n181. 'tinham'\n182. 'tive'\n183. 'teve'\n184. 'tivemos'\n185. 'tiveram'\n186. 'tivera'\n187. 'tivéramos'\n188. 'tenha'\n189. 'tenhamos'\n190. 'tenham'\n191. 'tivesse'\n192. 'tivéssemos'\n193. 'tivessem'\n194. 'tiver'\n195. 'tivermos'\n196. 'tiverem'\n197. 'terei'\n198. 'terá'\n199. 'teremos'\n200. 'terão'\n201. 'teria'\n202. 'teríamos'\n203. 'teriam'\n204. 'é'\n205. 'um'\n\n\n",
            "text/latex": "\\begin{enumerate*}\n\\item 'de'\n\\item 'a'\n\\item 'o'\n\\item 'que'\n\\item 'e'\n\\item 'do'\n\\item 'da'\n\\item 'em'\n\\item 'um'\n\\item 'para'\n\\item 'com'\n\\item 'não'\n\\item 'uma'\n\\item 'os'\n\\item 'no'\n\\item 'se'\n\\item 'na'\n\\item 'por'\n\\item 'mais'\n\\item 'as'\n\\item 'dos'\n\\item 'como'\n\\item 'mas'\n\\item 'ao'\n\\item 'ele'\n\\item 'das'\n\\item 'à'\n\\item 'seu'\n\\item 'sua'\n\\item 'ou'\n\\item 'quando'\n\\item 'muito'\n\\item 'nos'\n\\item 'já'\n\\item 'eu'\n\\item 'também'\n\\item 'só'\n\\item 'pelo'\n\\item 'pela'\n\\item 'até'\n\\item 'isso'\n\\item 'ela'\n\\item 'entre'\n\\item 'depois'\n\\item 'sem'\n\\item 'mesmo'\n\\item 'aos'\n\\item 'seus'\n\\item 'quem'\n\\item 'nas'\n\\item 'me'\n\\item 'esse'\n\\item 'eles'\n\\item 'você'\n\\item 'essa'\n\\item 'num'\n\\item 'nem'\n\\item 'suas'\n\\item 'meu'\n\\item 'às'\n\\item 'minha'\n\\item 'numa'\n\\item 'pelos'\n\\item 'elas'\n\\item 'qual'\n\\item 'nós'\n\\item 'lhe'\n\\item 'deles'\n\\item 'essas'\n\\item 'esses'\n\\item 'pelas'\n\\item 'este'\n\\item 'dele'\n\\item 'tu'\n\\item 'te'\n\\item 'vocês'\n\\item 'vos'\n\\item 'lhes'\n\\item 'meus'\n\\item 'minhas'\n\\item 'teu'\n\\item 'tua'\n\\item 'teus'\n\\item 'tuas'\n\\item 'nosso'\n\\item 'nossa'\n\\item 'nossos'\n\\item 'nossas'\n\\item 'dela'\n\\item 'delas'\n\\item 'esta'\n\\item 'estes'\n\\item 'estas'\n\\item 'aquele'\n\\item 'aquela'\n\\item 'aqueles'\n\\item 'aquelas'\n\\item 'isto'\n\\item 'aquilo'\n\\item 'estou'\n\\item 'está'\n\\item 'estamos'\n\\item 'estão'\n\\item 'estive'\n\\item 'esteve'\n\\item 'estivemos'\n\\item 'estiveram'\n\\item 'estava'\n\\item 'estávamos'\n\\item 'estavam'\n\\item 'estivera'\n\\item 'estivéramos'\n\\item 'esteja'\n\\item 'estejamos'\n\\item 'estejam'\n\\item 'estivesse'\n\\item 'estivéssemos'\n\\item 'estivessem'\n\\item 'estiver'\n\\item 'estivermos'\n\\item 'estiverem'\n\\item 'hei'\n\\item 'há'\n\\item 'havemos'\n\\item 'hão'\n\\item 'houve'\n\\item 'houvemos'\n\\item 'houveram'\n\\item 'houvera'\n\\item 'houvéramos'\n\\item 'haja'\n\\item 'hajamos'\n\\item 'hajam'\n\\item 'houvesse'\n\\item 'houvéssemos'\n\\item 'houvessem'\n\\item 'houver'\n\\item 'houvermos'\n\\item 'houverem'\n\\item 'houverei'\n\\item 'houverá'\n\\item 'houveremos'\n\\item 'houverão'\n\\item 'houveria'\n\\item 'houveríamos'\n\\item 'houveriam'\n\\item 'sou'\n\\item 'somos'\n\\item 'são'\n\\item 'era'\n\\item 'éramos'\n\\item 'eram'\n\\item 'fui'\n\\item 'foi'\n\\item 'fomos'\n\\item 'foram'\n\\item 'fora'\n\\item 'fôramos'\n\\item 'seja'\n\\item 'sejamos'\n\\item 'sejam'\n\\item 'fosse'\n\\item 'fôssemos'\n\\item 'fossem'\n\\item 'for'\n\\item 'formos'\n\\item 'forem'\n\\item 'serei'\n\\item 'será'\n\\item 'seremos'\n\\item 'serão'\n\\item 'seria'\n\\item 'seríamos'\n\\item 'seriam'\n\\item 'tenho'\n\\item 'tem'\n\\item 'temos'\n\\item 'tém'\n\\item 'tinha'\n\\item 'tínhamos'\n\\item 'tinham'\n\\item 'tive'\n\\item 'teve'\n\\item 'tivemos'\n\\item 'tiveram'\n\\item 'tivera'\n\\item 'tivéramos'\n\\item 'tenha'\n\\item 'tenhamos'\n\\item 'tenham'\n\\item 'tivesse'\n\\item 'tivéssemos'\n\\item 'tivessem'\n\\item 'tiver'\n\\item 'tivermos'\n\\item 'tiverem'\n\\item 'terei'\n\\item 'terá'\n\\item 'teremos'\n\\item 'terão'\n\\item 'teria'\n\\item 'teríamos'\n\\item 'teriam'\n\\item 'é'\n\\item 'um'\n\\end{enumerate*}\n",
            "text/plain": [
              "  [1] \"de\"           \"a\"            \"o\"            \"que\"          \"e\"           \n",
              "  [6] \"do\"           \"da\"           \"em\"           \"um\"           \"para\"        \n",
              " [11] \"com\"          \"não\"          \"uma\"          \"os\"           \"no\"          \n",
              " [16] \"se\"           \"na\"           \"por\"          \"mais\"         \"as\"          \n",
              " [21] \"dos\"          \"como\"         \"mas\"          \"ao\"           \"ele\"         \n",
              " [26] \"das\"          \"à\"            \"seu\"          \"sua\"          \"ou\"          \n",
              " [31] \"quando\"       \"muito\"        \"nos\"          \"já\"           \"eu\"          \n",
              " [36] \"também\"       \"só\"           \"pelo\"         \"pela\"         \"até\"         \n",
              " [41] \"isso\"         \"ela\"          \"entre\"        \"depois\"       \"sem\"         \n",
              " [46] \"mesmo\"        \"aos\"          \"seus\"         \"quem\"         \"nas\"         \n",
              " [51] \"me\"           \"esse\"         \"eles\"         \"você\"         \"essa\"        \n",
              " [56] \"num\"          \"nem\"          \"suas\"         \"meu\"          \"às\"          \n",
              " [61] \"minha\"        \"numa\"         \"pelos\"        \"elas\"         \"qual\"        \n",
              " [66] \"nós\"          \"lhe\"          \"deles\"        \"essas\"        \"esses\"       \n",
              " [71] \"pelas\"        \"este\"         \"dele\"         \"tu\"           \"te\"          \n",
              " [76] \"vocês\"        \"vos\"          \"lhes\"         \"meus\"         \"minhas\"      \n",
              " [81] \"teu\"          \"tua\"          \"teus\"         \"tuas\"         \"nosso\"       \n",
              " [86] \"nossa\"        \"nossos\"       \"nossas\"       \"dela\"         \"delas\"       \n",
              " [91] \"esta\"         \"estes\"        \"estas\"        \"aquele\"       \"aquela\"      \n",
              " [96] \"aqueles\"      \"aquelas\"      \"isto\"         \"aquilo\"       \"estou\"       \n",
              "[101] \"está\"         \"estamos\"      \"estão\"        \"estive\"       \"esteve\"      \n",
              "[106] \"estivemos\"    \"estiveram\"    \"estava\"       \"estávamos\"    \"estavam\"     \n",
              "[111] \"estivera\"     \"estivéramos\"  \"esteja\"       \"estejamos\"    \"estejam\"     \n",
              "[116] \"estivesse\"    \"estivéssemos\" \"estivessem\"   \"estiver\"      \"estivermos\"  \n",
              "[121] \"estiverem\"    \"hei\"          \"há\"           \"havemos\"      \"hão\"         \n",
              "[126] \"houve\"        \"houvemos\"     \"houveram\"     \"houvera\"      \"houvéramos\"  \n",
              "[131] \"haja\"         \"hajamos\"      \"hajam\"        \"houvesse\"     \"houvéssemos\" \n",
              "[136] \"houvessem\"    \"houver\"       \"houvermos\"    \"houverem\"     \"houverei\"    \n",
              "[141] \"houverá\"      \"houveremos\"   \"houverão\"     \"houveria\"     \"houveríamos\" \n",
              "[146] \"houveriam\"    \"sou\"          \"somos\"        \"são\"          \"era\"         \n",
              "[151] \"éramos\"       \"eram\"         \"fui\"          \"foi\"          \"fomos\"       \n",
              "[156] \"foram\"        \"fora\"         \"fôramos\"      \"seja\"         \"sejamos\"     \n",
              "[161] \"sejam\"        \"fosse\"        \"fôssemos\"     \"fossem\"       \"for\"         \n",
              "[166] \"formos\"       \"forem\"        \"serei\"        \"será\"         \"seremos\"     \n",
              "[171] \"serão\"        \"seria\"        \"seríamos\"     \"seriam\"       \"tenho\"       \n",
              "[176] \"tem\"          \"temos\"        \"tém\"          \"tinha\"        \"tínhamos\"    \n",
              "[181] \"tinham\"       \"tive\"         \"teve\"         \"tivemos\"      \"tiveram\"     \n",
              "[186] \"tivera\"       \"tivéramos\"    \"tenha\"        \"tenhamos\"     \"tenham\"      \n",
              "[191] \"tivesse\"      \"tivéssemos\"   \"tivessem\"     \"tiver\"        \"tivermos\"    \n",
              "[196] \"tiverem\"      \"terei\"        \"terá\"         \"teremos\"      \"terão\"       \n",
              "[201] \"teria\"        \"teríamos\"     \"teriam\"       \"é\"            \"um\"          "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agora que já temos a lista, podemos verificar se alguma delas se encontra no nosso texto:"
      ],
      "metadata": {
        "id": "00OpsK7MOfkS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if(!require('tidyverse')) install.packages('tidyverse')\n",
        "if(!require('tidytext')) install.packages('tidytext')\n",
        "if(!require('tokenizers')) install.packages('tokenizers')\n",
        "if(!require('tm')) install.packages('tm')\n",
        "\n",
        "library(tidyverse)\n",
        "library(tidytext)\n",
        "library(tokenizers)\n",
        "library(tm)\n",
        "\n",
        "# define lista de stopwords\n",
        "custom_stop_words <- tibble(word = append(tm::stopwords('portuguese'), list('é', 'um')))\n",
        "custom_stop_words <- mutate(custom_stop_words, word = as.character(word))\n",
        "\n",
        "# define o texto a ser processado e cria um tibble correspondente\n",
        "text <- paste0(\n",
        "  \"Violência simbólica é um conceito social elaborado pelo\\n\",\n",
        "  \"sociólogo francês Pierre Bourdieu, o qual aborda uma forma\\n\",\n",
        "  \"de violência exercida pelo corpo sem coação física, causando\\n\",\n",
        "  \"danos morais e psicológicos.\")\n",
        "\n",
        "lst_words <- tokenize_words(text)\n",
        "\n",
        "df_words <- data.frame(Reduce(rbind, lst_words)) %>%\n",
        "  rename(\"termo\" = \"Reduce.rbind..lst_words.\")\n",
        "\n",
        "tb_words <- as_tibble(df_words)\n",
        "tb_words <- mutate(tb_words, termo = as.character(termo))\n",
        "\n",
        "# verifica se algum termo encontra-se na lista de stopwords e acrescenta uma coluna informando se são ou não stopwords\n",
        "df_words <- df_words %>% mutate(stopword = ifelse((termo %in% custom_stop_words$word), TRUE,FALSE))\n",
        "df_words"
      ],
      "metadata": {
        "id": "zrVHgIXbTM9g",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f7a1414a-7f4d-4ce6-b740-6b3e946ea057"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading required package: tidyverse\n",
            "\n",
            "── \u001b[1mAttaching core tidyverse packages\u001b[22m ──────────────────────── tidyverse 2.0.0 ──\n",
            "\u001b[32m✔\u001b[39m \u001b[34mforcats  \u001b[39m 1.0.0     \u001b[32m✔\u001b[39m \u001b[34mreadr    \u001b[39m 2.1.5\n",
            "\u001b[32m✔\u001b[39m \u001b[34mggplot2  \u001b[39m 3.4.4     \u001b[32m✔\u001b[39m \u001b[34mstringr  \u001b[39m 1.5.1\n",
            "\u001b[32m✔\u001b[39m \u001b[34mlubridate\u001b[39m 1.9.3     \u001b[32m✔\u001b[39m \u001b[34mtibble   \u001b[39m 3.2.1\n",
            "\u001b[32m✔\u001b[39m \u001b[34mpurrr    \u001b[39m 1.0.2     \u001b[32m✔\u001b[39m \u001b[34mtidyr    \u001b[39m 1.3.1\n",
            "── \u001b[1mConflicts\u001b[22m ────────────────────────────────────────── tidyverse_conflicts() ──\n",
            "\u001b[31m✖\u001b[39m \u001b[34mggplot2\u001b[39m::\u001b[32mannotate()\u001b[39m masks \u001b[34mNLP\u001b[39m::annotate()\n",
            "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m     masks \u001b[34mstats\u001b[39m::filter()\n",
            "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m        masks \u001b[34mstats\u001b[39m::lag()\n",
            "\u001b[36mℹ\u001b[39m Use the conflicted package (\u001b[3m\u001b[34m<http://conflicted.r-lib.org/>\u001b[39m\u001b[23m) to force all conflicts to become errors\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A data.frame: 30 × 2</caption>\n",
              "<thead>\n",
              "\t<tr><th scope=col>termo</th><th scope=col>stopword</th></tr>\n",
              "\t<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;lgl&gt;</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><td>violência   </td><td>FALSE</td></tr>\n",
              "\t<tr><td>simbólica   </td><td>FALSE</td></tr>\n",
              "\t<tr><td>é           </td><td> TRUE</td></tr>\n",
              "\t<tr><td>um          </td><td> TRUE</td></tr>\n",
              "\t<tr><td>conceito    </td><td>FALSE</td></tr>\n",
              "\t<tr><td>social      </td><td>FALSE</td></tr>\n",
              "\t<tr><td>elaborado   </td><td>FALSE</td></tr>\n",
              "\t<tr><td>pelo        </td><td> TRUE</td></tr>\n",
              "\t<tr><td>sociólogo   </td><td>FALSE</td></tr>\n",
              "\t<tr><td>francês     </td><td>FALSE</td></tr>\n",
              "\t<tr><td>pierre      </td><td>FALSE</td></tr>\n",
              "\t<tr><td>bourdieu    </td><td>FALSE</td></tr>\n",
              "\t<tr><td>o           </td><td> TRUE</td></tr>\n",
              "\t<tr><td>qual        </td><td> TRUE</td></tr>\n",
              "\t<tr><td>aborda      </td><td>FALSE</td></tr>\n",
              "\t<tr><td>uma         </td><td> TRUE</td></tr>\n",
              "\t<tr><td>forma       </td><td>FALSE</td></tr>\n",
              "\t<tr><td>de          </td><td> TRUE</td></tr>\n",
              "\t<tr><td>violência   </td><td>FALSE</td></tr>\n",
              "\t<tr><td>exercida    </td><td>FALSE</td></tr>\n",
              "\t<tr><td>pelo        </td><td> TRUE</td></tr>\n",
              "\t<tr><td>corpo       </td><td>FALSE</td></tr>\n",
              "\t<tr><td>sem         </td><td> TRUE</td></tr>\n",
              "\t<tr><td>coação      </td><td>FALSE</td></tr>\n",
              "\t<tr><td>física      </td><td>FALSE</td></tr>\n",
              "\t<tr><td>causando    </td><td>FALSE</td></tr>\n",
              "\t<tr><td>danos       </td><td>FALSE</td></tr>\n",
              "\t<tr><td>morais      </td><td>FALSE</td></tr>\n",
              "\t<tr><td>e           </td><td> TRUE</td></tr>\n",
              "\t<tr><td>psicológicos</td><td>FALSE</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ],
            "text/markdown": "\nA data.frame: 30 × 2\n\n| termo &lt;chr&gt; | stopword &lt;lgl&gt; |\n|---|---|\n| violência    | FALSE |\n| simbólica    | FALSE |\n| é            |  TRUE |\n| um           |  TRUE |\n| conceito     | FALSE |\n| social       | FALSE |\n| elaborado    | FALSE |\n| pelo         |  TRUE |\n| sociólogo    | FALSE |\n| francês      | FALSE |\n| pierre       | FALSE |\n| bourdieu     | FALSE |\n| o            |  TRUE |\n| qual         |  TRUE |\n| aborda       | FALSE |\n| uma          |  TRUE |\n| forma        | FALSE |\n| de           |  TRUE |\n| violência    | FALSE |\n| exercida     | FALSE |\n| pelo         |  TRUE |\n| corpo        | FALSE |\n| sem          |  TRUE |\n| coação       | FALSE |\n| física       | FALSE |\n| causando     | FALSE |\n| danos        | FALSE |\n| morais       | FALSE |\n| e            |  TRUE |\n| psicológicos | FALSE |\n\n",
            "text/latex": "A data.frame: 30 × 2\n\\begin{tabular}{ll}\n termo & stopword\\\\\n <chr> & <lgl>\\\\\n\\hline\n\t violência    & FALSE\\\\\n\t simbólica    & FALSE\\\\\n\t é            &  TRUE\\\\\n\t um           &  TRUE\\\\\n\t conceito     & FALSE\\\\\n\t social       & FALSE\\\\\n\t elaborado    & FALSE\\\\\n\t pelo         &  TRUE\\\\\n\t sociólogo    & FALSE\\\\\n\t francês      & FALSE\\\\\n\t pierre       & FALSE\\\\\n\t bourdieu     & FALSE\\\\\n\t o            &  TRUE\\\\\n\t qual         &  TRUE\\\\\n\t aborda       & FALSE\\\\\n\t uma          &  TRUE\\\\\n\t forma        & FALSE\\\\\n\t de           &  TRUE\\\\\n\t violência    & FALSE\\\\\n\t exercida     & FALSE\\\\\n\t pelo         &  TRUE\\\\\n\t corpo        & FALSE\\\\\n\t sem          &  TRUE\\\\\n\t coação       & FALSE\\\\\n\t física       & FALSE\\\\\n\t causando     & FALSE\\\\\n\t danos        & FALSE\\\\\n\t morais       & FALSE\\\\\n\t e            &  TRUE\\\\\n\t psicológicos & FALSE\\\\\n\\end{tabular}\n",
            "text/plain": [
              "   termo        stopword\n",
              "1  violência    FALSE   \n",
              "2  simbólica    FALSE   \n",
              "3  é             TRUE   \n",
              "4  um            TRUE   \n",
              "5  conceito     FALSE   \n",
              "6  social       FALSE   \n",
              "7  elaborado    FALSE   \n",
              "8  pelo          TRUE   \n",
              "9  sociólogo    FALSE   \n",
              "10 francês      FALSE   \n",
              "11 pierre       FALSE   \n",
              "12 bourdieu     FALSE   \n",
              "13 o             TRUE   \n",
              "14 qual          TRUE   \n",
              "15 aborda       FALSE   \n",
              "16 uma           TRUE   \n",
              "17 forma        FALSE   \n",
              "18 de            TRUE   \n",
              "19 violência    FALSE   \n",
              "20 exercida     FALSE   \n",
              "21 pelo          TRUE   \n",
              "22 corpo        FALSE   \n",
              "23 sem           TRUE   \n",
              "24 coação       FALSE   \n",
              "25 física       FALSE   \n",
              "26 causando     FALSE   \n",
              "27 danos        FALSE   \n",
              "28 morais       FALSE   \n",
              "29 e             TRUE   \n",
              "30 psicológicos FALSE   "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# quantitativo por tipo\n",
        "df_words %>% count(stopword)"
      ],
      "metadata": {
        "id": "XVJWoRqkVON_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160
        },
        "outputId": "7db9a6ca-457f-47a1-b94b-842ec34f2920"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A data.frame: 2 × 2</caption>\n",
              "<thead>\n",
              "\t<tr><th scope=col>stopword</th><th scope=col>n</th></tr>\n",
              "\t<tr><th scope=col>&lt;lgl&gt;</th><th scope=col>&lt;int&gt;</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><td>FALSE</td><td>20</td></tr>\n",
              "\t<tr><td> TRUE</td><td>10</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ],
            "text/markdown": "\nA data.frame: 2 × 2\n\n| stopword &lt;lgl&gt; | n &lt;int&gt; |\n|---|---|\n| FALSE | 20 |\n|  TRUE | 10 |\n\n",
            "text/latex": "A data.frame: 2 × 2\n\\begin{tabular}{ll}\n stopword & n\\\\\n <lgl> & <int>\\\\\n\\hline\n\t FALSE & 20\\\\\n\t  TRUE & 10\\\\\n\\end{tabular}\n",
            "text/plain": [
              "  stopword n \n",
              "1 FALSE    20\n",
              "2  TRUE    10"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtra só as que são stopwords\n",
        "df_words %>% filter(stopword == TRUE)"
      ],
      "metadata": {
        "id": "ITdli8osUsy_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "outputId": "efafa461-35a9-43e6-ada8-3033544d8cae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A data.frame: 10 × 2</caption>\n",
              "<thead>\n",
              "\t<tr><th scope=col>termo</th><th scope=col>stopword</th></tr>\n",
              "\t<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;lgl&gt;</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><td>é   </td><td>TRUE</td></tr>\n",
              "\t<tr><td>um  </td><td>TRUE</td></tr>\n",
              "\t<tr><td>pelo</td><td>TRUE</td></tr>\n",
              "\t<tr><td>o   </td><td>TRUE</td></tr>\n",
              "\t<tr><td>qual</td><td>TRUE</td></tr>\n",
              "\t<tr><td>uma </td><td>TRUE</td></tr>\n",
              "\t<tr><td>de  </td><td>TRUE</td></tr>\n",
              "\t<tr><td>pelo</td><td>TRUE</td></tr>\n",
              "\t<tr><td>sem </td><td>TRUE</td></tr>\n",
              "\t<tr><td>e   </td><td>TRUE</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ],
            "text/markdown": "\nA data.frame: 10 × 2\n\n| termo &lt;chr&gt; | stopword &lt;lgl&gt; |\n|---|---|\n| é    | TRUE |\n| um   | TRUE |\n| pelo | TRUE |\n| o    | TRUE |\n| qual | TRUE |\n| uma  | TRUE |\n| de   | TRUE |\n| pelo | TRUE |\n| sem  | TRUE |\n| e    | TRUE |\n\n",
            "text/latex": "A data.frame: 10 × 2\n\\begin{tabular}{ll}\n termo & stopword\\\\\n <chr> & <lgl>\\\\\n\\hline\n\t é    & TRUE\\\\\n\t um   & TRUE\\\\\n\t pelo & TRUE\\\\\n\t o    & TRUE\\\\\n\t qual & TRUE\\\\\n\t uma  & TRUE\\\\\n\t de   & TRUE\\\\\n\t pelo & TRUE\\\\\n\t sem  & TRUE\\\\\n\t e    & TRUE\\\\\n\\end{tabular}\n",
            "text/plain": [
              "   termo stopword\n",
              "1  é     TRUE    \n",
              "2  um    TRUE    \n",
              "3  pelo  TRUE    \n",
              "4  o     TRUE    \n",
              "5  qual  TRUE    \n",
              "6  uma   TRUE    \n",
              "7  de    TRUE    \n",
              "8  pelo  TRUE    \n",
              "9  sem   TRUE    \n",
              "10 e     TRUE    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtra as que não são stopwords\n",
        "df_words %>% filter(stopword == FALSE)"
      ],
      "metadata": {
        "id": "L9nERrNwUtS7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 725
        },
        "outputId": "b797f914-9b0b-4d76-884c-e556a5ec31bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A data.frame: 20 × 2</caption>\n",
              "<thead>\n",
              "\t<tr><th scope=col>termo</th><th scope=col>stopword</th></tr>\n",
              "\t<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;lgl&gt;</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><td>violência   </td><td>FALSE</td></tr>\n",
              "\t<tr><td>simbólica   </td><td>FALSE</td></tr>\n",
              "\t<tr><td>conceito    </td><td>FALSE</td></tr>\n",
              "\t<tr><td>social      </td><td>FALSE</td></tr>\n",
              "\t<tr><td>elaborado   </td><td>FALSE</td></tr>\n",
              "\t<tr><td>sociólogo   </td><td>FALSE</td></tr>\n",
              "\t<tr><td>francês     </td><td>FALSE</td></tr>\n",
              "\t<tr><td>pierre      </td><td>FALSE</td></tr>\n",
              "\t<tr><td>bourdieu    </td><td>FALSE</td></tr>\n",
              "\t<tr><td>aborda      </td><td>FALSE</td></tr>\n",
              "\t<tr><td>forma       </td><td>FALSE</td></tr>\n",
              "\t<tr><td>violência   </td><td>FALSE</td></tr>\n",
              "\t<tr><td>exercida    </td><td>FALSE</td></tr>\n",
              "\t<tr><td>corpo       </td><td>FALSE</td></tr>\n",
              "\t<tr><td>coação      </td><td>FALSE</td></tr>\n",
              "\t<tr><td>física      </td><td>FALSE</td></tr>\n",
              "\t<tr><td>causando    </td><td>FALSE</td></tr>\n",
              "\t<tr><td>danos       </td><td>FALSE</td></tr>\n",
              "\t<tr><td>morais      </td><td>FALSE</td></tr>\n",
              "\t<tr><td>psicológicos</td><td>FALSE</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ],
            "text/markdown": "\nA data.frame: 20 × 2\n\n| termo &lt;chr&gt; | stopword &lt;lgl&gt; |\n|---|---|\n| violência    | FALSE |\n| simbólica    | FALSE |\n| conceito     | FALSE |\n| social       | FALSE |\n| elaborado    | FALSE |\n| sociólogo    | FALSE |\n| francês      | FALSE |\n| pierre       | FALSE |\n| bourdieu     | FALSE |\n| aborda       | FALSE |\n| forma        | FALSE |\n| violência    | FALSE |\n| exercida     | FALSE |\n| corpo        | FALSE |\n| coação       | FALSE |\n| física       | FALSE |\n| causando     | FALSE |\n| danos        | FALSE |\n| morais       | FALSE |\n| psicológicos | FALSE |\n\n",
            "text/latex": "A data.frame: 20 × 2\n\\begin{tabular}{ll}\n termo & stopword\\\\\n <chr> & <lgl>\\\\\n\\hline\n\t violência    & FALSE\\\\\n\t simbólica    & FALSE\\\\\n\t conceito     & FALSE\\\\\n\t social       & FALSE\\\\\n\t elaborado    & FALSE\\\\\n\t sociólogo    & FALSE\\\\\n\t francês      & FALSE\\\\\n\t pierre       & FALSE\\\\\n\t bourdieu     & FALSE\\\\\n\t aborda       & FALSE\\\\\n\t forma        & FALSE\\\\\n\t violência    & FALSE\\\\\n\t exercida     & FALSE\\\\\n\t corpo        & FALSE\\\\\n\t coação       & FALSE\\\\\n\t física       & FALSE\\\\\n\t causando     & FALSE\\\\\n\t danos        & FALSE\\\\\n\t morais       & FALSE\\\\\n\t psicológicos & FALSE\\\\\n\\end{tabular}\n",
            "text/plain": [
              "   termo        stopword\n",
              "1  violência    FALSE   \n",
              "2  simbólica    FALSE   \n",
              "3  conceito     FALSE   \n",
              "4  social       FALSE   \n",
              "5  elaborado    FALSE   \n",
              "6  sociólogo    FALSE   \n",
              "7  francês      FALSE   \n",
              "8  pierre       FALSE   \n",
              "9  bourdieu     FALSE   \n",
              "10 aborda       FALSE   \n",
              "11 forma        FALSE   \n",
              "12 violência    FALSE   \n",
              "13 exercida     FALSE   \n",
              "14 corpo        FALSE   \n",
              "15 coação       FALSE   \n",
              "16 física       FALSE   \n",
              "17 causando     FALSE   \n",
              "18 danos        FALSE   \n",
              "19 morais       FALSE   \n",
              "20 psicológicos FALSE   "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos efetivamente remover as `stopwords` do `tibble`, para que possamos seguir adiante no processamento:"
      ],
      "metadata": {
        "id": "Ninbs1YLVUc0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if(!require('tidyverse')) install.packages('tidyverse')\n",
        "if(!require('tidytext')) install.packages('tidytext')\n",
        "if(!require('tokenizers')) install.packages('tokenizers')\n",
        "if(!require('tm')) install.packages('tm')\n",
        "\n",
        "library(tidyverse)\n",
        "library(tidytext)\n",
        "library(tokenizers)\n",
        "library(tm)\n",
        "\n",
        "# define lista de stopwords\n",
        "custom_stop_words <- tibble(word = append(tm::stopwords('portuguese'), list('é', 'um')))\n",
        "custom_stop_words <- mutate(custom_stop_words, word = as.character(word))\n",
        "\n",
        "# define o texto a ser processado e cria um tibble correspondente\n",
        "text <- paste0(\n",
        "  \"Violência simbólica é um conceito social elaborado pelo\\n\",\n",
        "  \"sociólogo francês Pierre Bourdieu, o qual aborda uma forma\\n\",\n",
        "  \"de violência exercida pelo corpo sem coação física, causando\\n\",\n",
        "  \"danos morais e psicológicos.\")\n",
        "\n",
        "lst_words <- tokenize_words(text)\n",
        "\n",
        "df_words <- data.frame(Reduce(rbind, lst_words)) %>%\n",
        "  rename(\"termo\" = \"Reduce.rbind..lst_words.\")\n",
        "\n",
        "tb_words <- as_tibble(df_words)\n",
        "tb_words <- mutate(tb_words, termo = as.character(termo))\n",
        "\n",
        "# cria uma lista das palavras em 'tb_words' que não pertencem à lista de stopwords\n",
        "# para detalhes do 'anti_join' e outras possibilidades, ver\n",
        "# https://dplyr.tidyverse.org/reference/filter-joins.html\n",
        "tb_final_words <- tb_words %>%\n",
        "  anti_join(custom_stop_words, by=join_by(termo==word))\n",
        "\n",
        "head(tb_final_words, n=10) # mude para mostrar mais do que 10"
      ],
      "metadata": {
        "id": "hcyGNPGjJmi6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        },
        "outputId": "8e909cd9-f4f8-4528-a041-648dbbf88d61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A tibble: 10 × 1</caption>\n",
              "<thead>\n",
              "\t<tr><th scope=col>termo</th></tr>\n",
              "\t<tr><th scope=col>&lt;chr&gt;</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><td>violência</td></tr>\n",
              "\t<tr><td>simbólica</td></tr>\n",
              "\t<tr><td>conceito </td></tr>\n",
              "\t<tr><td>social   </td></tr>\n",
              "\t<tr><td>elaborado</td></tr>\n",
              "\t<tr><td>sociólogo</td></tr>\n",
              "\t<tr><td>francês  </td></tr>\n",
              "\t<tr><td>pierre   </td></tr>\n",
              "\t<tr><td>bourdieu </td></tr>\n",
              "\t<tr><td>aborda   </td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ],
            "text/markdown": "\nA tibble: 10 × 1\n\n| termo &lt;chr&gt; |\n|---|\n| violência |\n| simbólica |\n| conceito  |\n| social    |\n| elaborado |\n| sociólogo |\n| francês   |\n| pierre    |\n| bourdieu  |\n| aborda    |\n\n",
            "text/latex": "A tibble: 10 × 1\n\\begin{tabular}{l}\n termo\\\\\n <chr>\\\\\n\\hline\n\t violência\\\\\n\t simbólica\\\\\n\t conceito \\\\\n\t social   \\\\\n\t elaborado\\\\\n\t sociólogo\\\\\n\t francês  \\\\\n\t pierre   \\\\\n\t bourdieu \\\\\n\t aborda   \\\\\n\\end{tabular}\n",
            "text/plain": [
              "   termo    \n",
              "1  violência\n",
              "2  simbólica\n",
              "3  conceito \n",
              "4  social   \n",
              "5  elaborado\n",
              "6  sociólogo\n",
              "7  francês  \n",
              "8  pierre   \n",
              "9  bourdieu \n",
              "10 aborda   "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJ-sjIMUio8P"
      },
      "source": [
        "# Stemmização\n",
        "\n",
        "As palavras utilizadas nos textos escritos em linguagem natural possuem variações de diferentes tipos, incluindo gênero (masculino ou feminino), número (singular ou plural) e grau (aumentativo, diminutivo, superlativo).\n",
        "\n",
        "Como o computador analisa sequências de caracteres, se houver qualquer diferença nessa sequência, ele não detectará que as palavras representam a mesma entidade.\n",
        "\n",
        "Veja:\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"menino\"==\"meninos\""
      ],
      "metadata": {
        "id": "JVeloqoObPEQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "81022651-6098-4d3d-c7c7-c5fe4d5f941b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "FALSE"
            ],
            "text/markdown": "FALSE",
            "text/latex": "FALSE",
            "text/plain": [
              "[1] FALSE"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"menino\"==\"menina\""
      ],
      "metadata": {
        "id": "jeaADMu-bTA8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "54aaf176-a9d8-4868-b21a-5927157879f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "FALSE"
            ],
            "text/markdown": "FALSE",
            "text/latex": "FALSE",
            "text/plain": [
              "[1] FALSE"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"menino\"==\"meninão\""
      ],
      "metadata": {
        "id": "4AO70IyObVEO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "be470791-87af-4ec8-970c-e9ad77a9a829"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "FALSE"
            ],
            "text/markdown": "FALSE",
            "text/latex": "FALSE",
            "text/plain": [
              "[1] FALSE"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Temos que considerar ainda que podemos ter advérbios, adjetivos ou substantivos, entre outros, representando a mesma entidade ou ideia.\n",
        "\n",
        "Diante disso, esses elementos serão considerados diferentes em uma análise textual. Algumas vezes podemos querer que isso aconteça de fato, mas outras não.\n",
        "\n",
        "Quando desejarmos minimizar as diferenças entre palavras, podemos utilizar uma técnica chamada de `Stemming` (i.e., identificação do `stem`).\n",
        "\n",
        "---\n",
        "**Atenção**: em linguística, `stem` (radical ou tema) e `root` (raíz) são elementos diferentes. O `stem` é o elemento mórfico que fornece a significação de uma palavra. O `root` é o elemento mórfico mais simples ao qual uma palavra pode ser reduzida (De Lucca, 2002).\n",
        "\n",
        "Segundo De Lucca (2002), há ainda o `lema`, que representa a forma canônica de uma palavra em um contexto lexicográfico. Em dicionários, por exemplo, as palavras são representadas por seus lemas, e a lematização se dá da seguinte forma: verbos são representados através de seus infinitivos e substantivos e adjetivos são representados pela forma masculina singular.\n",
        "\n",
        "Para mais detalhes, sugere-se a leitura do documento [\"Lematização versus Stemming\"](http://www.nilc.icmc.usp.br/nilc/download/lematizacao_versus_steming.pdf), de J. L. De Lucca (2002).\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "ZLOdzfqWbns1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vamos praticar?\n",
        "\n",
        "Para identificarmos os `stems` das palavras, podemos utilizar a própria biblioteca `tokenizers`, pois ela possui uma função de tokenização que já faz isso para nós, veja:"
      ],
      "metadata": {
        "id": "jDudeEALWZEb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if(!require('tokenizers')) install.packages('tokenizers')\n",
        "\n",
        "library(tokenizers)\n",
        "\n",
        "# define o texto a ser processado e cria um tibble correspondente\n",
        "text <- paste0(\n",
        "  \"Violência simbólica é um conceito social elaborado pelo\\n\",\n",
        "  \"sociólogo francês Pierre Bourdieu, o qual aborda uma forma\\n\",\n",
        "  \"de violência exercida pelo corpo sem coação física, causando\\n\",\n",
        "  \"danos morais e psicológicos.\")\n",
        "\n",
        "lst_words <- tokenize_word_stems(text)\n",
        "\n",
        "lst_words"
      ],
      "metadata": {
        "id": "BVu6VASbWWnf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "0f102dfd-4203-4a61-b640-36f14369133b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<ol>\n",
              "\t<li><style>\n",
              ".list-inline {list-style: none; margin:0; padding: 0}\n",
              ".list-inline>li {display: inline-block}\n",
              ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
              "</style>\n",
              "<ol class=list-inline><li>'violência'</li><li>'simbólica'</li><li>'é'</li><li>'um'</li><li>'conceito'</li><li>'social'</li><li>'elaborado'</li><li>'pelo'</li><li>'sociólogo'</li><li>'francê'</li><li>'pierr'</li><li>'bourdieu'</li><li>'o'</li><li>'qual'</li><li>'aborda'</li><li>'uma'</li><li>'forma'</li><li>'de'</li><li>'violência'</li><li>'exercida'</li><li>'pelo'</li><li>'corpo'</li><li>'sem'</li><li>'coação'</li><li>'física'</li><li>'causando'</li><li>'dano'</li><li>'morai'</li><li>'e'</li><li>'psicológico'</li></ol>\n",
              "</li>\n",
              "</ol>\n"
            ],
            "text/markdown": "1. 1. 'violência'\n2. 'simbólica'\n3. 'é'\n4. 'um'\n5. 'conceito'\n6. 'social'\n7. 'elaborado'\n8. 'pelo'\n9. 'sociólogo'\n10. 'francê'\n11. 'pierr'\n12. 'bourdieu'\n13. 'o'\n14. 'qual'\n15. 'aborda'\n16. 'uma'\n17. 'forma'\n18. 'de'\n19. 'violência'\n20. 'exercida'\n21. 'pelo'\n22. 'corpo'\n23. 'sem'\n24. 'coação'\n25. 'física'\n26. 'causando'\n27. 'dano'\n28. 'morai'\n29. 'e'\n30. 'psicológico'\n\n\n\n\n\n",
            "text/latex": "\\begin{enumerate}\n\\item \\begin{enumerate*}\n\\item 'violência'\n\\item 'simbólica'\n\\item 'é'\n\\item 'um'\n\\item 'conceito'\n\\item 'social'\n\\item 'elaborado'\n\\item 'pelo'\n\\item 'sociólogo'\n\\item 'francê'\n\\item 'pierr'\n\\item 'bourdieu'\n\\item 'o'\n\\item 'qual'\n\\item 'aborda'\n\\item 'uma'\n\\item 'forma'\n\\item 'de'\n\\item 'violência'\n\\item 'exercida'\n\\item 'pelo'\n\\item 'corpo'\n\\item 'sem'\n\\item 'coação'\n\\item 'física'\n\\item 'causando'\n\\item 'dano'\n\\item 'morai'\n\\item 'e'\n\\item 'psicológico'\n\\end{enumerate*}\n\n\\end{enumerate}\n",
            "text/plain": [
              "[[1]]\n",
              " [1] \"violência\"   \"simbólica\"   \"é\"           \"um\"          \"conceito\"   \n",
              " [6] \"social\"      \"elaborado\"   \"pelo\"        \"sociólogo\"   \"francê\"     \n",
              "[11] \"pierr\"       \"bourdieu\"    \"o\"           \"qual\"        \"aborda\"     \n",
              "[16] \"uma\"         \"forma\"       \"de\"          \"violência\"   \"exercida\"   \n",
              "[21] \"pelo\"        \"corpo\"       \"sem\"         \"coação\"      \"física\"     \n",
              "[26] \"causando\"    \"dano\"        \"morai\"       \"e\"           \"psicológico\"\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "No entanto, a biblioteca `tokenizers` não é muito flexível e eventualmente precisamos utilizar outros algoritmos de detecção de `stems`.\n",
        "\n",
        "Nesses casos, podemos usar a função padrão para identificar os `tokens` e, depois, usarmos outra biblioteca para a identificação de `stems`.\n",
        "\n",
        "No exemplo seguinte, usaremos a biblioteca [`Snowball`](https://snowballstem.org/), que pode apresentar resultados melhores para a língua portuguesa.\n",
        "\n",
        "O resultado do *script* é uma tabela do tipo `tibble` que contém as palavras do texto e mais duas colunas: uma indicando se elas são ou não `stopwords` e outra indicando qual é o `stem` correspondente."
      ],
      "metadata": {
        "id": "gtvLTjQQWXFQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# A biblioteca SnowBallC já é carregada junto com a 'tokenizers'\n",
        "if(!require('tidyverse')) install.packages('tidyverse')\n",
        "if(!require('tidytext')) install.packages('tidytext')\n",
        "if(!require('tokenizers')) install.packages('tokenizers')\n",
        "if(!require('tm')) install.packages('tm')\n",
        "\n",
        "library(tidyverse)\n",
        "library(tidytext)\n",
        "library(tokenizers)\n",
        "library(tm)\n",
        "\n",
        "# define lista de stopwords\n",
        "custom_stop_words <- tibble(word = append(tm::stopwords('portuguese'), list('é', 'um')))\n",
        "custom_stop_words <- mutate(custom_stop_words, word = as.character(word))\n",
        "\n",
        "# define o texto a ser processado e cria um tibble correspondente\n",
        "text <- paste0(\n",
        "  \"Violência simbólica é um conceito social elaborado pelo\\n\",\n",
        "  \"sociólogo francês Pierre Bourdieu, o qual aborda uma forma\\n\",\n",
        "  \"de violência exercida pelo corpo sem coação física, causando\\n\",\n",
        "  \"danos morais e psicológicos.\")\n",
        "\n",
        "lst_words <- tokenize_words(text)\n",
        "\n",
        "# renomeia para 'token', pois é mais apropriado\n",
        "df_words <- data.frame(Reduce(rbind, lst_words)) %>%\n",
        "  rename(\"token\" = \"Reduce.rbind..lst_words.\") %>%\n",
        "  as_tibble()\n",
        "\n",
        "# verifica se algum termo encontra-se na lista de stopwords e acrescenta uma coluna informando se são ou não stopwords\n",
        "df_words <- df_words %>% mutate(stopword = ifelse((token %in% custom_stop_words$word), TRUE,FALSE))\n",
        "\n",
        "# identifica o 'stem' em português, via biblioteca SnowBallC\n",
        "df_words <- df_words %>% mutate(stem = SnowballC::wordStem(token, language = \"portuguese\"))\n",
        "\n",
        "df_words"
      ],
      "metadata": {
        "id": "YZM936SPYgWR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f73c2d1a-64a1-4575-cd67-52e59d28d1cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A tibble: 30 × 3</caption>\n",
              "<thead>\n",
              "\t<tr><th scope=col>token</th><th scope=col>stopword</th><th scope=col>stem</th></tr>\n",
              "\t<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;lgl&gt;</th><th scope=col>&lt;chr&gt;</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><td>violência   </td><td>FALSE</td><td>violênc </td></tr>\n",
              "\t<tr><td>simbólica   </td><td>FALSE</td><td>simból  </td></tr>\n",
              "\t<tr><td>é           </td><td> TRUE</td><td>é       </td></tr>\n",
              "\t<tr><td>um          </td><td> TRUE</td><td>um      </td></tr>\n",
              "\t<tr><td>conceito    </td><td>FALSE</td><td>conceit </td></tr>\n",
              "\t<tr><td>social      </td><td>FALSE</td><td>social  </td></tr>\n",
              "\t<tr><td>elaborado   </td><td>FALSE</td><td>elabor  </td></tr>\n",
              "\t<tr><td>pelo        </td><td> TRUE</td><td>pel     </td></tr>\n",
              "\t<tr><td>sociólogo   </td><td>FALSE</td><td>sociólog</td></tr>\n",
              "\t<tr><td>francês     </td><td>FALSE</td><td>francês </td></tr>\n",
              "\t<tr><td>pierre      </td><td>FALSE</td><td>pierr   </td></tr>\n",
              "\t<tr><td>bourdieu    </td><td>FALSE</td><td>bourdi  </td></tr>\n",
              "\t<tr><td>o           </td><td> TRUE</td><td>o       </td></tr>\n",
              "\t<tr><td>qual        </td><td> TRUE</td><td>qual    </td></tr>\n",
              "\t<tr><td>aborda      </td><td>FALSE</td><td>abord   </td></tr>\n",
              "\t<tr><td>uma         </td><td> TRUE</td><td>uma     </td></tr>\n",
              "\t<tr><td>forma       </td><td>FALSE</td><td>form    </td></tr>\n",
              "\t<tr><td>de          </td><td> TRUE</td><td>de      </td></tr>\n",
              "\t<tr><td>violência   </td><td>FALSE</td><td>violênc </td></tr>\n",
              "\t<tr><td>exercida    </td><td>FALSE</td><td>exerc   </td></tr>\n",
              "\t<tr><td>pelo        </td><td> TRUE</td><td>pel     </td></tr>\n",
              "\t<tr><td>corpo       </td><td>FALSE</td><td>corp    </td></tr>\n",
              "\t<tr><td>sem         </td><td> TRUE</td><td>sem     </td></tr>\n",
              "\t<tr><td>coação      </td><td>FALSE</td><td>coaçã   </td></tr>\n",
              "\t<tr><td>física      </td><td>FALSE</td><td>físic   </td></tr>\n",
              "\t<tr><td>causando    </td><td>FALSE</td><td>caus    </td></tr>\n",
              "\t<tr><td>danos       </td><td>FALSE</td><td>dan     </td></tr>\n",
              "\t<tr><td>morais      </td><td>FALSE</td><td>mor     </td></tr>\n",
              "\t<tr><td>e           </td><td> TRUE</td><td>e       </td></tr>\n",
              "\t<tr><td>psicológicos</td><td>FALSE</td><td>psicológ</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ],
            "text/markdown": "\nA tibble: 30 × 3\n\n| token &lt;chr&gt; | stopword &lt;lgl&gt; | stem &lt;chr&gt; |\n|---|---|---|\n| violência    | FALSE | violênc  |\n| simbólica    | FALSE | simból   |\n| é            |  TRUE | é        |\n| um           |  TRUE | um       |\n| conceito     | FALSE | conceit  |\n| social       | FALSE | social   |\n| elaborado    | FALSE | elabor   |\n| pelo         |  TRUE | pel      |\n| sociólogo    | FALSE | sociólog |\n| francês      | FALSE | francês  |\n| pierre       | FALSE | pierr    |\n| bourdieu     | FALSE | bourdi   |\n| o            |  TRUE | o        |\n| qual         |  TRUE | qual     |\n| aborda       | FALSE | abord    |\n| uma          |  TRUE | uma      |\n| forma        | FALSE | form     |\n| de           |  TRUE | de       |\n| violência    | FALSE | violênc  |\n| exercida     | FALSE | exerc    |\n| pelo         |  TRUE | pel      |\n| corpo        | FALSE | corp     |\n| sem          |  TRUE | sem      |\n| coação       | FALSE | coaçã    |\n| física       | FALSE | físic    |\n| causando     | FALSE | caus     |\n| danos        | FALSE | dan      |\n| morais       | FALSE | mor      |\n| e            |  TRUE | e        |\n| psicológicos | FALSE | psicológ |\n\n",
            "text/latex": "A tibble: 30 × 3\n\\begin{tabular}{lll}\n token & stopword & stem\\\\\n <chr> & <lgl> & <chr>\\\\\n\\hline\n\t violência    & FALSE & violênc \\\\\n\t simbólica    & FALSE & simból  \\\\\n\t é            &  TRUE & é       \\\\\n\t um           &  TRUE & um      \\\\\n\t conceito     & FALSE & conceit \\\\\n\t social       & FALSE & social  \\\\\n\t elaborado    & FALSE & elabor  \\\\\n\t pelo         &  TRUE & pel     \\\\\n\t sociólogo    & FALSE & sociólog\\\\\n\t francês      & FALSE & francês \\\\\n\t pierre       & FALSE & pierr   \\\\\n\t bourdieu     & FALSE & bourdi  \\\\\n\t o            &  TRUE & o       \\\\\n\t qual         &  TRUE & qual    \\\\\n\t aborda       & FALSE & abord   \\\\\n\t uma          &  TRUE & uma     \\\\\n\t forma        & FALSE & form    \\\\\n\t de           &  TRUE & de      \\\\\n\t violência    & FALSE & violênc \\\\\n\t exercida     & FALSE & exerc   \\\\\n\t pelo         &  TRUE & pel     \\\\\n\t corpo        & FALSE & corp    \\\\\n\t sem          &  TRUE & sem     \\\\\n\t coação       & FALSE & coaçã   \\\\\n\t física       & FALSE & físic   \\\\\n\t causando     & FALSE & caus    \\\\\n\t danos        & FALSE & dan     \\\\\n\t morais       & FALSE & mor     \\\\\n\t e            &  TRUE & e       \\\\\n\t psicológicos & FALSE & psicológ\\\\\n\\end{tabular}\n",
            "text/plain": [
              "   token        stopword stem    \n",
              "1  violência    FALSE    violênc \n",
              "2  simbólica    FALSE    simból  \n",
              "3  é             TRUE    é       \n",
              "4  um            TRUE    um      \n",
              "5  conceito     FALSE    conceit \n",
              "6  social       FALSE    social  \n",
              "7  elaborado    FALSE    elabor  \n",
              "8  pelo          TRUE    pel     \n",
              "9  sociólogo    FALSE    sociólog\n",
              "10 francês      FALSE    francês \n",
              "11 pierre       FALSE    pierr   \n",
              "12 bourdieu     FALSE    bourdi  \n",
              "13 o             TRUE    o       \n",
              "14 qual          TRUE    qual    \n",
              "15 aborda       FALSE    abord   \n",
              "16 uma           TRUE    uma     \n",
              "17 forma        FALSE    form    \n",
              "18 de            TRUE    de      \n",
              "19 violência    FALSE    violênc \n",
              "20 exercida     FALSE    exerc   \n",
              "21 pelo          TRUE    pel     \n",
              "22 corpo        FALSE    corp    \n",
              "23 sem           TRUE    sem     \n",
              "24 coação       FALSE    coaçã   \n",
              "25 física       FALSE    físic   \n",
              "26 causando     FALSE    caus    \n",
              "27 danos        FALSE    dan     \n",
              "28 morais       FALSE    mor     \n",
              "29 e             TRUE    e       \n",
              "30 psicológicos FALSE    psicológ"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compare a coluna `stem` da tabela acima com a lista de `stem` gerada anteriormente pela função `tokenize_word_stems()`.\n",
        "\n",
        "Os resultados foram melhores ou piores?"
      ],
      "metadata": {
        "id": "6wbo21_mWXhK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "O código seguinte resume o que já fizemos até o momento. Ele processa um texto, elimina as stopwords e cria uma tabela que indica a frequência de cada palavra no texto e o seu respectivo stem."
      ],
      "metadata": {
        "id": "93PjAr69T9jv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if(!require('tidyverse')) install.packages('tidyverse')\n",
        "if(!require('tidytext')) install.packages('tidytext')\n",
        "if(!require('tokenizers')) install.packages('tokenizers')\n",
        "if(!require('tm')) install.packages('tm')\n",
        "\n",
        "library(tidyverse)\n",
        "library(tidytext)\n",
        "library(tokenizers)\n",
        "library(tm)\n",
        "\n",
        "# define lista de stopwords\n",
        "custom_stop_words <- tibble(word = append(tm::stopwords('portuguese'), list('é', 'um')))\n",
        "custom_stop_words <- mutate(custom_stop_words, word = as.character(word))\n",
        "\n",
        "# define o texto a ser processado e cria um tibble correspondente\n",
        "text <- paste0(\n",
        "  \"Este é um texto de teste a ser utilizado pelas funções de tokenização.\\n\",\n",
        "  \"Ele inclui números por extenso, dígitos e símbolos, tais como 1, 1.3, 1/4 e outros símbolos como !, % e ?\\n\",\n",
        "  \"Também inclui algumas hashtags e mentions:\\n\",\n",
        "  \"#hashtag @usuário #R #Rstudio #GoogleColab @alunos.\\n\",\n",
        "  \"Tente com o seu texto. Verifique o que acontece com diferentes opções de tokenizadores.\")\n",
        "\n",
        "lst_words <- tokenize_words(text)                                               # tokeniza\n",
        "\n",
        "tb_words <- data.frame(Reduce(rbind, lst_words)) %>%                            # cria dataframe\n",
        "  rename(token = Reduce.rbind..lst_words.) %>%                                  # troca nome da coluna para 'token'\n",
        "  as_tibble() %>%                                                               # transforma dataframe em tibble\n",
        "  anti_join(custom_stop_words, by=join_by(token==word))                         # remove stopwords\n",
        "\n",
        "# Cria tabela com as palavras e suas relativas frequências e stems\n",
        "tb_final_words <- tb_words %>%\n",
        "  group_by(token) %>%                                                           # agrupa por 'token'\n",
        "  mutate(stem = SnowballC::wordStem(token, language = \"portuguese\")) %>%        # adiciona coluna 'stem'\n",
        "  add_tally() %>%                                                               # adiciona a quantidade de elementos por grupos de palavras\n",
        "  arrange(desc(n)) %>%                                                          # ordena de forma decrescente pela frequência das palavras\n",
        "  unique()                                                                      # remove duplicatas\n",
        "\n",
        "tb_final_words"
      ],
      "metadata": {
        "id": "K7WR7f0dT9u3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "dddfcecf-1973-4461-caa2-8ada1a3eedca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A grouped_df: 31 × 3</caption>\n",
              "<thead>\n",
              "\t<tr><th scope=col>token</th><th scope=col>stem</th><th scope=col>n</th></tr>\n",
              "\t<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;int&gt;</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><td>texto        </td><td>text       </td><td>2</td></tr>\n",
              "\t<tr><td>inclui       </td><td>inclu      </td><td>2</td></tr>\n",
              "\t<tr><td>símbolos     </td><td>símbol     </td><td>2</td></tr>\n",
              "\t<tr><td>1            </td><td>1          </td><td>2</td></tr>\n",
              "\t<tr><td>teste        </td><td>test       </td><td>1</td></tr>\n",
              "\t<tr><td>ser          </td><td>ser        </td><td>1</td></tr>\n",
              "\t<tr><td>utilizado    </td><td>utiliz     </td><td>1</td></tr>\n",
              "\t<tr><td>funções      </td><td>funçõ      </td><td>1</td></tr>\n",
              "\t<tr><td>tokenização  </td><td>tokeniz    </td><td>1</td></tr>\n",
              "\t<tr><td>números      </td><td>númer      </td><td>1</td></tr>\n",
              "\t<tr><td>extenso      </td><td>extens     </td><td>1</td></tr>\n",
              "\t<tr><td>dígitos      </td><td>dígit      </td><td>1</td></tr>\n",
              "\t<tr><td>tais         </td><td>tais       </td><td>1</td></tr>\n",
              "\t<tr><td>1.3          </td><td>1.3        </td><td>1</td></tr>\n",
              "\t<tr><td>4            </td><td>4          </td><td>1</td></tr>\n",
              "\t<tr><td>outros       </td><td>outr       </td><td>1</td></tr>\n",
              "\t<tr><td>algumas      </td><td>algum      </td><td>1</td></tr>\n",
              "\t<tr><td>hashtags     </td><td>hashtags   </td><td>1</td></tr>\n",
              "\t<tr><td>mentions     </td><td>mentions   </td><td>1</td></tr>\n",
              "\t<tr><td>hashtag      </td><td>hashtag    </td><td>1</td></tr>\n",
              "\t<tr><td>usuário      </td><td>usuári     </td><td>1</td></tr>\n",
              "\t<tr><td>r            </td><td>r          </td><td>1</td></tr>\n",
              "\t<tr><td>rstudio      </td><td>rstudi     </td><td>1</td></tr>\n",
              "\t<tr><td>googlecolab  </td><td>googlecolab</td><td>1</td></tr>\n",
              "\t<tr><td>alunos       </td><td>alun       </td><td>1</td></tr>\n",
              "\t<tr><td>tente        </td><td>tent       </td><td>1</td></tr>\n",
              "\t<tr><td>verifique    </td><td>verifiqu   </td><td>1</td></tr>\n",
              "\t<tr><td>acontece     </td><td>acontec    </td><td>1</td></tr>\n",
              "\t<tr><td>diferentes   </td><td>diferent   </td><td>1</td></tr>\n",
              "\t<tr><td>opções       </td><td>opçõ       </td><td>1</td></tr>\n",
              "\t<tr><td>tokenizadores</td><td>tokeniz    </td><td>1</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ],
            "text/markdown": "\nA grouped_df: 31 × 3\n\n| token &lt;chr&gt; | stem &lt;chr&gt; | n &lt;int&gt; |\n|---|---|---|\n| texto         | text        | 2 |\n| inclui        | inclu       | 2 |\n| símbolos      | símbol      | 2 |\n| 1             | 1           | 2 |\n| teste         | test        | 1 |\n| ser           | ser         | 1 |\n| utilizado     | utiliz      | 1 |\n| funções       | funçõ       | 1 |\n| tokenização   | tokeniz     | 1 |\n| números       | númer       | 1 |\n| extenso       | extens      | 1 |\n| dígitos       | dígit       | 1 |\n| tais          | tais        | 1 |\n| 1.3           | 1.3         | 1 |\n| 4             | 4           | 1 |\n| outros        | outr        | 1 |\n| algumas       | algum       | 1 |\n| hashtags      | hashtags    | 1 |\n| mentions      | mentions    | 1 |\n| hashtag       | hashtag     | 1 |\n| usuário       | usuári      | 1 |\n| r             | r           | 1 |\n| rstudio       | rstudi      | 1 |\n| googlecolab   | googlecolab | 1 |\n| alunos        | alun        | 1 |\n| tente         | tent        | 1 |\n| verifique     | verifiqu    | 1 |\n| acontece      | acontec     | 1 |\n| diferentes    | diferent    | 1 |\n| opções        | opçõ        | 1 |\n| tokenizadores | tokeniz     | 1 |\n\n",
            "text/latex": "A grouped\\_df: 31 × 3\n\\begin{tabular}{lll}\n token & stem & n\\\\\n <chr> & <chr> & <int>\\\\\n\\hline\n\t texto         & text        & 2\\\\\n\t inclui        & inclu       & 2\\\\\n\t símbolos      & símbol      & 2\\\\\n\t 1             & 1           & 2\\\\\n\t teste         & test        & 1\\\\\n\t ser           & ser         & 1\\\\\n\t utilizado     & utiliz      & 1\\\\\n\t funções       & funçõ       & 1\\\\\n\t tokenização   & tokeniz     & 1\\\\\n\t números       & númer       & 1\\\\\n\t extenso       & extens      & 1\\\\\n\t dígitos       & dígit       & 1\\\\\n\t tais          & tais        & 1\\\\\n\t 1.3           & 1.3         & 1\\\\\n\t 4             & 4           & 1\\\\\n\t outros        & outr        & 1\\\\\n\t algumas       & algum       & 1\\\\\n\t hashtags      & hashtags    & 1\\\\\n\t mentions      & mentions    & 1\\\\\n\t hashtag       & hashtag     & 1\\\\\n\t usuário       & usuári      & 1\\\\\n\t r             & r           & 1\\\\\n\t rstudio       & rstudi      & 1\\\\\n\t googlecolab   & googlecolab & 1\\\\\n\t alunos        & alun        & 1\\\\\n\t tente         & tent        & 1\\\\\n\t verifique     & verifiqu    & 1\\\\\n\t acontece      & acontec     & 1\\\\\n\t diferentes    & diferent    & 1\\\\\n\t opções        & opçõ        & 1\\\\\n\t tokenizadores & tokeniz     & 1\\\\\n\\end{tabular}\n",
            "text/plain": [
              "   token         stem        n\n",
              "1  texto         text        2\n",
              "2  inclui        inclu       2\n",
              "3  símbolos      símbol      2\n",
              "4  1             1           2\n",
              "5  teste         test        1\n",
              "6  ser           ser         1\n",
              "7  utilizado     utiliz      1\n",
              "8  funções       funçõ       1\n",
              "9  tokenização   tokeniz     1\n",
              "10 números       númer       1\n",
              "11 extenso       extens      1\n",
              "12 dígitos       dígit       1\n",
              "13 tais          tais        1\n",
              "14 1.3           1.3         1\n",
              "15 4             4           1\n",
              "16 outros        outr        1\n",
              "17 algumas       algum       1\n",
              "18 hashtags      hashtags    1\n",
              "19 mentions      mentions    1\n",
              "20 hashtag       hashtag     1\n",
              "21 usuário       usuári      1\n",
              "22 r             r           1\n",
              "23 rstudio       rstudi      1\n",
              "24 googlecolab   googlecolab 1\n",
              "25 alunos        alun        1\n",
              "26 tente         tent        1\n",
              "27 verifique     verifiqu    1\n",
              "28 acontece      acontec     1\n",
              "29 diferentes    diferent    1\n",
              "30 opções        opçõ        1\n",
              "31 tokenizadores tokeniz     1"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7xGEXljio8P"
      },
      "source": [
        "# Representação do Conteúdo\n",
        "\n",
        "O conteúdo dos documentos pode ser representado através de um **Saco de Palavras (*Bag-of-Words*)**, que nada mais é do que um vetor que contém as palavras encontradas no texto e seu respectivo peso (i.e., importância).\n",
        "\n",
        "O **peso** de uma palavra pode ser calculado de diferentes maneiras, a mais simples consiste em identificar a **frequência absoluta** das palavras no texto (i.e., número de ocorrências). Outra opção consiste na **frequência relativa**, que é o número de ocorrências dividido pelo total de ocorrências de palavras de um texto. Uma terceira opção, mais completa, é a **tf-idf** e ela inclui a quantidade de documentos em que uma palavra aparece, tornando as palavras mais frequentes menos importantes. Existem outras abordagens, mas essas são as mais comuns.\n",
        "\n",
        "A seguir, vamos aprendar a calcular essas três medidas de peso, usando um texto real como exemplo.\n",
        "\n",
        "Para tanto, iremos carregar alguns textos de domínio público, disponíveis na biblioteca `janeaustenr`. Essa biblioteca contém alguns documentos em inglês, escritos por `Jane Austen`."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if(!require('tidyverse')) install.packages('tidyverse')\n",
        "if(!require('tidytext')) install.packages('tidytext')\n",
        "if(!require('janeaustenr')) install.packages('janeaustenr')\n",
        "\n",
        "library(tidyverse)\n",
        "library(tidytext)\n",
        "library(janeaustenr)\n",
        "\n",
        "books <- austen_books()\n",
        "books"
      ],
      "metadata": {
        "id": "t0mg8ERSecTK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fbcb4324-0920-4768-c8f1-629465fcfe8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A tibble: 73422 × 2</caption>\n",
              "<thead>\n",
              "\t<tr><th></th><th scope=col>text</th><th scope=col>book</th></tr>\n",
              "\t<tr><th></th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;fct&gt;</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><th scope=row>1</th><td><span style=white-space:pre-wrap>SENSE AND SENSIBILITY                                                  </span></td><td>Sense &amp; Sensibility</td></tr>\n",
              "\t<tr><th scope=row>2</th><td><span style=white-space:pre-wrap>                                                                       </span></td><td>Sense &amp; Sensibility</td></tr>\n",
              "\t<tr><th scope=row>3</th><td><span style=white-space:pre-wrap>by Jane Austen                                                         </span></td><td>Sense &amp; Sensibility</td></tr>\n",
              "\t<tr><th scope=row>4</th><td><span style=white-space:pre-wrap>                                                                       </span></td><td>Sense &amp; Sensibility</td></tr>\n",
              "\t<tr><th scope=row>5</th><td><span style=white-space:pre-wrap>(1811)                                                                 </span></td><td>Sense &amp; Sensibility</td></tr>\n",
              "\t<tr><th scope=row>6</th><td><span style=white-space:pre-wrap>                                                                       </span></td><td>Sense &amp; Sensibility</td></tr>\n",
              "\t<tr><th scope=row>7</th><td><span style=white-space:pre-wrap>                                                                       </span></td><td>Sense &amp; Sensibility</td></tr>\n",
              "\t<tr><th scope=row>8</th><td><span style=white-space:pre-wrap>                                                                       </span></td><td>Sense &amp; Sensibility</td></tr>\n",
              "\t<tr><th scope=row>9</th><td><span style=white-space:pre-wrap>                                                                       </span></td><td>Sense &amp; Sensibility</td></tr>\n",
              "\t<tr><th scope=row>10</th><td><span style=white-space:pre-wrap>CHAPTER 1                                                              </span></td><td>Sense &amp; Sensibility</td></tr>\n",
              "\t<tr><th scope=row>11</th><td><span style=white-space:pre-wrap>                                                                       </span></td><td>Sense &amp; Sensibility</td></tr>\n",
              "\t<tr><th scope=row>12</th><td><span style=white-space:pre-wrap>                                                                       </span></td><td>Sense &amp; Sensibility</td></tr>\n",
              "\t<tr><th scope=row>13</th><td><span style=white-space:pre-wrap>The family of Dashwood had long been settled in Sussex.  Their estate  </span></td><td>Sense &amp; Sensibility</td></tr>\n",
              "\t<tr><th scope=row>14</th><td><span style=white-space:pre-wrap>was large, and their residence was at Norland Park, in the centre of   </span></td><td>Sense &amp; Sensibility</td></tr>\n",
              "\t<tr><th scope=row>15</th><td><span style=white-space:pre-wrap>their property, where, for many generations, they had lived in so      </span></td><td>Sense &amp; Sensibility</td></tr>\n",
              "\t<tr><th scope=row>16</th><td><span style=white-space:pre-wrap>respectable a manner as to engage the general good opinion of their    </span></td><td>Sense &amp; Sensibility</td></tr>\n",
              "\t<tr><th scope=row>17</th><td><span style=white-space:pre-wrap>surrounding acquaintance.  The late owner of this estate was a single  </span></td><td>Sense &amp; Sensibility</td></tr>\n",
              "\t<tr><th scope=row>18</th><td><span style=white-space:pre-wrap>man, who lived to a very advanced age, and who for many years of his   </span></td><td>Sense &amp; Sensibility</td></tr>\n",
              "\t<tr><th scope=row>19</th><td><span style=white-space:pre-wrap>life, had a constant companion and housekeeper in his sister.  But her </span></td><td>Sense &amp; Sensibility</td></tr>\n",
              "\t<tr><th scope=row>20</th><td><span style=white-space:pre-wrap>death, which happened ten years before his own, produced a great       </span></td><td>Sense &amp; Sensibility</td></tr>\n",
              "\t<tr><th scope=row>21</th><td>alteration in his home; for to supply her loss, he invited and received</td><td>Sense &amp; Sensibility</td></tr>\n",
              "\t<tr><th scope=row>22</th><td><span style=white-space:pre-wrap>into his house the family of his nephew Mr. Henry Dashwood, the legal  </span></td><td>Sense &amp; Sensibility</td></tr>\n",
              "\t<tr><th scope=row>23</th><td>inheritor of the Norland estate, and the person to whom he intended to </td><td>Sense &amp; Sensibility</td></tr>\n",
              "\t<tr><th scope=row>24</th><td><span style=white-space:pre-wrap>bequeath it.  In the society of his nephew and niece, and their        </span></td><td>Sense &amp; Sensibility</td></tr>\n",
              "\t<tr><th scope=row>25</th><td><span style=white-space:pre-wrap>children, the old Gentleman's days were comfortably spent.  His        </span></td><td>Sense &amp; Sensibility</td></tr>\n",
              "\t<tr><th scope=row>26</th><td><span style=white-space:pre-wrap>attachment to them all increased.  The constant attention of Mr. and   </span></td><td>Sense &amp; Sensibility</td></tr>\n",
              "\t<tr><th scope=row>27</th><td><span style=white-space:pre-wrap>Mrs. Henry Dashwood to his wishes, which proceeded not merely from     </span></td><td>Sense &amp; Sensibility</td></tr>\n",
              "\t<tr><th scope=row>28</th><td><span style=white-space:pre-wrap>interest, but from goodness of heart, gave him every degree of solid   </span></td><td>Sense &amp; Sensibility</td></tr>\n",
              "\t<tr><th scope=row>29</th><td><span style=white-space:pre-wrap>comfort which his age could receive; and the cheerfulness of the       </span></td><td>Sense &amp; Sensibility</td></tr>\n",
              "\t<tr><th scope=row>30</th><td><span style=white-space:pre-wrap>children added a relish to his existence.                              </span></td><td>Sense &amp; Sensibility</td></tr>\n",
              "\t<tr><th scope=row>⋮</th><td>⋮</td><td>⋮</td></tr>\n",
              "\t<tr><th scope=row>73393</th><td>                                                                       </td><td>Persuasion</td></tr>\n",
              "\t<tr><th scope=row>73394</th><td>Her recent good offices by Anne had been enough in themselves, and     </td><td>Persuasion</td></tr>\n",
              "\t<tr><th scope=row>73395</th><td>their marriage, instead of depriving her of one friend, secured her    </td><td>Persuasion</td></tr>\n",
              "\t<tr><th scope=row>73396</th><td>two.  She was their earliest visitor in their settled life; and Captain</td><td>Persuasion</td></tr>\n",
              "\t<tr><th scope=row>73397</th><td>Wentworth, by putting her in the way of recovering her husband's       </td><td>Persuasion</td></tr>\n",
              "\t<tr><th scope=row>73398</th><td>property in the West Indies, by writing for her, acting for her, and   </td><td>Persuasion</td></tr>\n",
              "\t<tr><th scope=row>73399</th><td>seeing her through all the petty difficulties of the case with the     </td><td>Persuasion</td></tr>\n",
              "\t<tr><th scope=row>73400</th><td>activity and exertion of a fearless man and a determined friend, fully </td><td>Persuasion</td></tr>\n",
              "\t<tr><th scope=row>73401</th><td>requited the services which she had rendered, or ever meant to render, </td><td>Persuasion</td></tr>\n",
              "\t<tr><th scope=row>73402</th><td>to his wife.                                                           </td><td>Persuasion</td></tr>\n",
              "\t<tr><th scope=row>73403</th><td>                                                                       </td><td>Persuasion</td></tr>\n",
              "\t<tr><th scope=row>73404</th><td>Mrs Smith's enjoyments were not spoiled by this improvement of income, </td><td>Persuasion</td></tr>\n",
              "\t<tr><th scope=row>73405</th><td>with some improvement of health, and the acquisition of such friends to</td><td>Persuasion</td></tr>\n",
              "\t<tr><th scope=row>73406</th><td>be often with, for her cheerfulness and mental alacrity did not fail   </td><td>Persuasion</td></tr>\n",
              "\t<tr><th scope=row>73407</th><td>her; and while these prime supplies of good remained, she might have   </td><td>Persuasion</td></tr>\n",
              "\t<tr><th scope=row>73408</th><td>bid defiance even to greater accessions of worldly prosperity.  She    </td><td>Persuasion</td></tr>\n",
              "\t<tr><th scope=row>73409</th><td>might have been absolutely rich and perfectly healthy, and yet be      </td><td>Persuasion</td></tr>\n",
              "\t<tr><th scope=row>73410</th><td>happy.  Her spring of felicity was in the glow of her spirits, as her  </td><td>Persuasion</td></tr>\n",
              "\t<tr><th scope=row>73411</th><td>friend Anne's was in the warmth of her heart.  Anne was tenderness     </td><td>Persuasion</td></tr>\n",
              "\t<tr><th scope=row>73412</th><td>itself, and she had the full worth of it in Captain Wentworth's        </td><td>Persuasion</td></tr>\n",
              "\t<tr><th scope=row>73413</th><td>affection.  His profession was all that could ever make her friends    </td><td>Persuasion</td></tr>\n",
              "\t<tr><th scope=row>73414</th><td>wish that tenderness less, the dread of a future war all that could dim</td><td>Persuasion</td></tr>\n",
              "\t<tr><th scope=row>73415</th><td>her sunshine.  She gloried in being a sailor's wife, but she must pay  </td><td>Persuasion</td></tr>\n",
              "\t<tr><th scope=row>73416</th><td>the tax of quick alarm for belonging to that profession which is, if   </td><td>Persuasion</td></tr>\n",
              "\t<tr><th scope=row>73417</th><td>possible, more distinguished in its domestic virtues than in its       </td><td>Persuasion</td></tr>\n",
              "\t<tr><th scope=row>73418</th><td>national importance.                                                   </td><td>Persuasion</td></tr>\n",
              "\t<tr><th scope=row>73419</th><td>                                                                       </td><td>Persuasion</td></tr>\n",
              "\t<tr><th scope=row>73420</th><td>                                                                       </td><td>Persuasion</td></tr>\n",
              "\t<tr><th scope=row>73421</th><td>                                                                       </td><td>Persuasion</td></tr>\n",
              "\t<tr><th scope=row>73422</th><td>Finis                                                                  </td><td>Persuasion</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ],
            "text/markdown": "\nA tibble: 73422 × 2\n\n| <!--/--> | text &lt;chr&gt; | book &lt;fct&gt; |\n|---|---|---|\n| 1 | SENSE AND SENSIBILITY                                                   | Sense &amp; Sensibility |\n| 2 | <!----> | Sense &amp; Sensibility |\n| 3 | by Jane Austen                                                          | Sense &amp; Sensibility |\n| 4 | <!----> | Sense &amp; Sensibility |\n| 5 | (1811)                                                                  | Sense &amp; Sensibility |\n| 6 | <!----> | Sense &amp; Sensibility |\n| 7 | <!----> | Sense &amp; Sensibility |\n| 8 | <!----> | Sense &amp; Sensibility |\n| 9 | <!----> | Sense &amp; Sensibility |\n| 10 | CHAPTER 1                                                               | Sense &amp; Sensibility |\n| 11 | <!----> | Sense &amp; Sensibility |\n| 12 | <!----> | Sense &amp; Sensibility |\n| 13 | The family of Dashwood had long been settled in Sussex.  Their estate   | Sense &amp; Sensibility |\n| 14 | was large, and their residence was at Norland Park, in the centre of    | Sense &amp; Sensibility |\n| 15 | their property, where, for many generations, they had lived in so       | Sense &amp; Sensibility |\n| 16 | respectable a manner as to engage the general good opinion of their     | Sense &amp; Sensibility |\n| 17 | surrounding acquaintance.  The late owner of this estate was a single   | Sense &amp; Sensibility |\n| 18 | man, who lived to a very advanced age, and who for many years of his    | Sense &amp; Sensibility |\n| 19 | life, had a constant companion and housekeeper in his sister.  But her  | Sense &amp; Sensibility |\n| 20 | death, which happened ten years before his own, produced a great        | Sense &amp; Sensibility |\n| 21 | alteration in his home; for to supply her loss, he invited and received | Sense &amp; Sensibility |\n| 22 | into his house the family of his nephew Mr. Henry Dashwood, the legal   | Sense &amp; Sensibility |\n| 23 | inheritor of the Norland estate, and the person to whom he intended to  | Sense &amp; Sensibility |\n| 24 | bequeath it.  In the society of his nephew and niece, and their         | Sense &amp; Sensibility |\n| 25 | children, the old Gentleman's days were comfortably spent.  His         | Sense &amp; Sensibility |\n| 26 | attachment to them all increased.  The constant attention of Mr. and    | Sense &amp; Sensibility |\n| 27 | Mrs. Henry Dashwood to his wishes, which proceeded not merely from      | Sense &amp; Sensibility |\n| 28 | interest, but from goodness of heart, gave him every degree of solid    | Sense &amp; Sensibility |\n| 29 | comfort which his age could receive; and the cheerfulness of the        | Sense &amp; Sensibility |\n| 30 | children added a relish to his existence.                               | Sense &amp; Sensibility |\n| ⋮ | ⋮ | ⋮ |\n| 73393 | <!----> | Persuasion |\n| 73394 | Her recent good offices by Anne had been enough in themselves, and      | Persuasion |\n| 73395 | their marriage, instead of depriving her of one friend, secured her     | Persuasion |\n| 73396 | two.  She was their earliest visitor in their settled life; and Captain | Persuasion |\n| 73397 | Wentworth, by putting her in the way of recovering her husband's        | Persuasion |\n| 73398 | property in the West Indies, by writing for her, acting for her, and    | Persuasion |\n| 73399 | seeing her through all the petty difficulties of the case with the      | Persuasion |\n| 73400 | activity and exertion of a fearless man and a determined friend, fully  | Persuasion |\n| 73401 | requited the services which she had rendered, or ever meant to render,  | Persuasion |\n| 73402 | to his wife.                                                            | Persuasion |\n| 73403 | <!----> | Persuasion |\n| 73404 | Mrs Smith's enjoyments were not spoiled by this improvement of income,  | Persuasion |\n| 73405 | with some improvement of health, and the acquisition of such friends to | Persuasion |\n| 73406 | be often with, for her cheerfulness and mental alacrity did not fail    | Persuasion |\n| 73407 | her; and while these prime supplies of good remained, she might have    | Persuasion |\n| 73408 | bid defiance even to greater accessions of worldly prosperity.  She     | Persuasion |\n| 73409 | might have been absolutely rich and perfectly healthy, and yet be       | Persuasion |\n| 73410 | happy.  Her spring of felicity was in the glow of her spirits, as her   | Persuasion |\n| 73411 | friend Anne's was in the warmth of her heart.  Anne was tenderness      | Persuasion |\n| 73412 | itself, and she had the full worth of it in Captain Wentworth's         | Persuasion |\n| 73413 | affection.  His profession was all that could ever make her friends     | Persuasion |\n| 73414 | wish that tenderness less, the dread of a future war all that could dim | Persuasion |\n| 73415 | her sunshine.  She gloried in being a sailor's wife, but she must pay   | Persuasion |\n| 73416 | the tax of quick alarm for belonging to that profession which is, if    | Persuasion |\n| 73417 | possible, more distinguished in its domestic virtues than in its        | Persuasion |\n| 73418 | national importance.                                                    | Persuasion |\n| 73419 | <!----> | Persuasion |\n| 73420 | <!----> | Persuasion |\n| 73421 | <!----> | Persuasion |\n| 73422 | Finis                                                                   | Persuasion |\n\n",
            "text/latex": "A tibble: 73422 × 2\n\\begin{tabular}{r|ll}\n  & text & book\\\\\n  & <chr> & <fct>\\\\\n\\hline\n\t1 & SENSE AND SENSIBILITY                                                   & Sense \\& Sensibility\\\\\n\t2 &                                                                         & Sense \\& Sensibility\\\\\n\t3 & by Jane Austen                                                          & Sense \\& Sensibility\\\\\n\t4 &                                                                         & Sense \\& Sensibility\\\\\n\t5 & (1811)                                                                  & Sense \\& Sensibility\\\\\n\t6 &                                                                         & Sense \\& Sensibility\\\\\n\t7 &                                                                         & Sense \\& Sensibility\\\\\n\t8 &                                                                         & Sense \\& Sensibility\\\\\n\t9 &                                                                         & Sense \\& Sensibility\\\\\n\t10 & CHAPTER 1                                                               & Sense \\& Sensibility\\\\\n\t11 &                                                                         & Sense \\& Sensibility\\\\\n\t12 &                                                                         & Sense \\& Sensibility\\\\\n\t13 & The family of Dashwood had long been settled in Sussex.  Their estate   & Sense \\& Sensibility\\\\\n\t14 & was large, and their residence was at Norland Park, in the centre of    & Sense \\& Sensibility\\\\\n\t15 & their property, where, for many generations, they had lived in so       & Sense \\& Sensibility\\\\\n\t16 & respectable a manner as to engage the general good opinion of their     & Sense \\& Sensibility\\\\\n\t17 & surrounding acquaintance.  The late owner of this estate was a single   & Sense \\& Sensibility\\\\\n\t18 & man, who lived to a very advanced age, and who for many years of his    & Sense \\& Sensibility\\\\\n\t19 & life, had a constant companion and housekeeper in his sister.  But her  & Sense \\& Sensibility\\\\\n\t20 & death, which happened ten years before his own, produced a great        & Sense \\& Sensibility\\\\\n\t21 & alteration in his home; for to supply her loss, he invited and received & Sense \\& Sensibility\\\\\n\t22 & into his house the family of his nephew Mr. Henry Dashwood, the legal   & Sense \\& Sensibility\\\\\n\t23 & inheritor of the Norland estate, and the person to whom he intended to  & Sense \\& Sensibility\\\\\n\t24 & bequeath it.  In the society of his nephew and niece, and their         & Sense \\& Sensibility\\\\\n\t25 & children, the old Gentleman's days were comfortably spent.  His         & Sense \\& Sensibility\\\\\n\t26 & attachment to them all increased.  The constant attention of Mr. and    & Sense \\& Sensibility\\\\\n\t27 & Mrs. Henry Dashwood to his wishes, which proceeded not merely from      & Sense \\& Sensibility\\\\\n\t28 & interest, but from goodness of heart, gave him every degree of solid    & Sense \\& Sensibility\\\\\n\t29 & comfort which his age could receive; and the cheerfulness of the        & Sense \\& Sensibility\\\\\n\t30 & children added a relish to his existence.                               & Sense \\& Sensibility\\\\\n\t⋮ & ⋮ & ⋮\\\\\n\t73393 &                                                                         & Persuasion\\\\\n\t73394 & Her recent good offices by Anne had been enough in themselves, and      & Persuasion\\\\\n\t73395 & their marriage, instead of depriving her of one friend, secured her     & Persuasion\\\\\n\t73396 & two.  She was their earliest visitor in their settled life; and Captain & Persuasion\\\\\n\t73397 & Wentworth, by putting her in the way of recovering her husband's        & Persuasion\\\\\n\t73398 & property in the West Indies, by writing for her, acting for her, and    & Persuasion\\\\\n\t73399 & seeing her through all the petty difficulties of the case with the      & Persuasion\\\\\n\t73400 & activity and exertion of a fearless man and a determined friend, fully  & Persuasion\\\\\n\t73401 & requited the services which she had rendered, or ever meant to render,  & Persuasion\\\\\n\t73402 & to his wife.                                                            & Persuasion\\\\\n\t73403 &                                                                         & Persuasion\\\\\n\t73404 & Mrs Smith's enjoyments were not spoiled by this improvement of income,  & Persuasion\\\\\n\t73405 & with some improvement of health, and the acquisition of such friends to & Persuasion\\\\\n\t73406 & be often with, for her cheerfulness and mental alacrity did not fail    & Persuasion\\\\\n\t73407 & her; and while these prime supplies of good remained, she might have    & Persuasion\\\\\n\t73408 & bid defiance even to greater accessions of worldly prosperity.  She     & Persuasion\\\\\n\t73409 & might have been absolutely rich and perfectly healthy, and yet be       & Persuasion\\\\\n\t73410 & happy.  Her spring of felicity was in the glow of her spirits, as her   & Persuasion\\\\\n\t73411 & friend Anne's was in the warmth of her heart.  Anne was tenderness      & Persuasion\\\\\n\t73412 & itself, and she had the full worth of it in Captain Wentworth's         & Persuasion\\\\\n\t73413 & affection.  His profession was all that could ever make her friends     & Persuasion\\\\\n\t73414 & wish that tenderness less, the dread of a future war all that could dim & Persuasion\\\\\n\t73415 & her sunshine.  She gloried in being a sailor's wife, but she must pay   & Persuasion\\\\\n\t73416 & the tax of quick alarm for belonging to that profession which is, if    & Persuasion\\\\\n\t73417 & possible, more distinguished in its domestic virtues than in its        & Persuasion\\\\\n\t73418 & national importance.                                                    & Persuasion\\\\\n\t73419 &                                                                         & Persuasion\\\\\n\t73420 &                                                                         & Persuasion\\\\\n\t73421 &                                                                         & Persuasion\\\\\n\t73422 & Finis                                                                   & Persuasion\\\\\n\\end{tabular}\n",
            "text/plain": [
              "      text                                                                   \n",
              "1     SENSE AND SENSIBILITY                                                  \n",
              "2                                                                            \n",
              "3     by Jane Austen                                                         \n",
              "4                                                                            \n",
              "5     (1811)                                                                 \n",
              "6                                                                            \n",
              "7                                                                            \n",
              "8                                                                            \n",
              "9                                                                            \n",
              "10    CHAPTER 1                                                              \n",
              "11                                                                           \n",
              "12                                                                           \n",
              "13    The family of Dashwood had long been settled in Sussex.  Their estate  \n",
              "14    was large, and their residence was at Norland Park, in the centre of   \n",
              "15    their property, where, for many generations, they had lived in so      \n",
              "16    respectable a manner as to engage the general good opinion of their    \n",
              "17    surrounding acquaintance.  The late owner of this estate was a single  \n",
              "18    man, who lived to a very advanced age, and who for many years of his   \n",
              "19    life, had a constant companion and housekeeper in his sister.  But her \n",
              "20    death, which happened ten years before his own, produced a great       \n",
              "21    alteration in his home; for to supply her loss, he invited and received\n",
              "22    into his house the family of his nephew Mr. Henry Dashwood, the legal  \n",
              "23    inheritor of the Norland estate, and the person to whom he intended to \n",
              "24    bequeath it.  In the society of his nephew and niece, and their        \n",
              "25    children, the old Gentleman's days were comfortably spent.  His        \n",
              "26    attachment to them all increased.  The constant attention of Mr. and   \n",
              "27    Mrs. Henry Dashwood to his wishes, which proceeded not merely from     \n",
              "28    interest, but from goodness of heart, gave him every degree of solid   \n",
              "29    comfort which his age could receive; and the cheerfulness of the       \n",
              "30    children added a relish to his existence.                              \n",
              "⋮     ⋮                                                                      \n",
              "73393                                                                        \n",
              "73394 Her recent good offices by Anne had been enough in themselves, and     \n",
              "73395 their marriage, instead of depriving her of one friend, secured her    \n",
              "73396 two.  She was their earliest visitor in their settled life; and Captain\n",
              "73397 Wentworth, by putting her in the way of recovering her husband's       \n",
              "73398 property in the West Indies, by writing for her, acting for her, and   \n",
              "73399 seeing her through all the petty difficulties of the case with the     \n",
              "73400 activity and exertion of a fearless man and a determined friend, fully \n",
              "73401 requited the services which she had rendered, or ever meant to render, \n",
              "73402 to his wife.                                                           \n",
              "73403                                                                        \n",
              "73404 Mrs Smith's enjoyments were not spoiled by this improvement of income, \n",
              "73405 with some improvement of health, and the acquisition of such friends to\n",
              "73406 be often with, for her cheerfulness and mental alacrity did not fail   \n",
              "73407 her; and while these prime supplies of good remained, she might have   \n",
              "73408 bid defiance even to greater accessions of worldly prosperity.  She    \n",
              "73409 might have been absolutely rich and perfectly healthy, and yet be      \n",
              "73410 happy.  Her spring of felicity was in the glow of her spirits, as her  \n",
              "73411 friend Anne's was in the warmth of her heart.  Anne was tenderness     \n",
              "73412 itself, and she had the full worth of it in Captain Wentworth's        \n",
              "73413 affection.  His profession was all that could ever make her friends    \n",
              "73414 wish that tenderness less, the dread of a future war all that could dim\n",
              "73415 her sunshine.  She gloried in being a sailor's wife, but she must pay  \n",
              "73416 the tax of quick alarm for belonging to that profession which is, if   \n",
              "73417 possible, more distinguished in its domestic virtues than in its       \n",
              "73418 national importance.                                                   \n",
              "73419                                                                        \n",
              "73420                                                                        \n",
              "73421                                                                        \n",
              "73422 Finis                                                                  \n",
              "      book               \n",
              "1     Sense & Sensibility\n",
              "2     Sense & Sensibility\n",
              "3     Sense & Sensibility\n",
              "4     Sense & Sensibility\n",
              "5     Sense & Sensibility\n",
              "6     Sense & Sensibility\n",
              "7     Sense & Sensibility\n",
              "8     Sense & Sensibility\n",
              "9     Sense & Sensibility\n",
              "10    Sense & Sensibility\n",
              "11    Sense & Sensibility\n",
              "12    Sense & Sensibility\n",
              "13    Sense & Sensibility\n",
              "14    Sense & Sensibility\n",
              "15    Sense & Sensibility\n",
              "16    Sense & Sensibility\n",
              "17    Sense & Sensibility\n",
              "18    Sense & Sensibility\n",
              "19    Sense & Sensibility\n",
              "20    Sense & Sensibility\n",
              "21    Sense & Sensibility\n",
              "22    Sense & Sensibility\n",
              "23    Sense & Sensibility\n",
              "24    Sense & Sensibility\n",
              "25    Sense & Sensibility\n",
              "26    Sense & Sensibility\n",
              "27    Sense & Sensibility\n",
              "28    Sense & Sensibility\n",
              "29    Sense & Sensibility\n",
              "30    Sense & Sensibility\n",
              "⋮     ⋮                  \n",
              "73393 Persuasion         \n",
              "73394 Persuasion         \n",
              "73395 Persuasion         \n",
              "73396 Persuasion         \n",
              "73397 Persuasion         \n",
              "73398 Persuasion         \n",
              "73399 Persuasion         \n",
              "73400 Persuasion         \n",
              "73401 Persuasion         \n",
              "73402 Persuasion         \n",
              "73403 Persuasion         \n",
              "73404 Persuasion         \n",
              "73405 Persuasion         \n",
              "73406 Persuasion         \n",
              "73407 Persuasion         \n",
              "73408 Persuasion         \n",
              "73409 Persuasion         \n",
              "73410 Persuasion         \n",
              "73411 Persuasion         \n",
              "73412 Persuasion         \n",
              "73413 Persuasion         \n",
              "73414 Persuasion         \n",
              "73415 Persuasion         \n",
              "73416 Persuasion         \n",
              "73417 Persuasion         \n",
              "73418 Persuasion         \n",
              "73419 Persuasion         \n",
              "73420 Persuasion         \n",
              "73421 Persuasion         \n",
              "73422 Persuasion         "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Frequência absoluta\n",
        "\n",
        "Vamos agora identificar a frequência absoluta de cada `token`.\n",
        "\n",
        "Analise o script seguinte:"
      ],
      "metadata": {
        "id": "Vqwwsh_pZ9Sh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if(!require('tidyverse')) install.packages('tidyverse')\n",
        "if(!require('tidytext')) install.packages('tidytext')\n",
        "if(!require('janeaustenr')) install.packages('janeaustenr')\n",
        "\n",
        "library(tidyverse)\n",
        "library(tidytext)\n",
        "library(janeaustenr)\n",
        "\n",
        "book_words <- austen_books() %>%             # Carrega os textos dos livros da Jane Austen\n",
        "  unnest_tokens(word, text) %>%              # identifica os tokens a partir de uma coluna\n",
        "  count(book, word, sort = TRUE)             # contabiliza palavras por livros e coloca em ordem de frequência absoluta\n",
        "\n",
        "book_words"
      ],
      "metadata": {
        "id": "NYcz4lTpbAsy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "27f3394c-e32f-4984-97af-62c155b439d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A tibble: 40379 × 3</caption>\n",
              "<thead>\n",
              "\t<tr><th scope=col>book</th><th scope=col>word</th><th scope=col>n</th></tr>\n",
              "\t<tr><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;int&gt;</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><td>Mansfield Park     </td><td>the</td><td>6206</td></tr>\n",
              "\t<tr><td>Mansfield Park     </td><td>to </td><td>5475</td></tr>\n",
              "\t<tr><td>Mansfield Park     </td><td>and</td><td>5438</td></tr>\n",
              "\t<tr><td>Emma               </td><td>to </td><td>5239</td></tr>\n",
              "\t<tr><td>Emma               </td><td>the</td><td>5201</td></tr>\n",
              "\t<tr><td>Emma               </td><td>and</td><td>4896</td></tr>\n",
              "\t<tr><td>Mansfield Park     </td><td>of </td><td>4778</td></tr>\n",
              "\t<tr><td><span style=white-space:pre-wrap>Pride &amp; Prejudice  </span></td><td>the</td><td>4331</td></tr>\n",
              "\t<tr><td>Emma               </td><td>of </td><td>4291</td></tr>\n",
              "\t<tr><td><span style=white-space:pre-wrap>Pride &amp; Prejudice  </span></td><td>to </td><td>4162</td></tr>\n",
              "\t<tr><td>Sense &amp; Sensibility</td><td>to </td><td>4116</td></tr>\n",
              "\t<tr><td>Sense &amp; Sensibility</td><td>the</td><td>4105</td></tr>\n",
              "\t<tr><td><span style=white-space:pre-wrap>Pride &amp; Prejudice  </span></td><td>of </td><td>3610</td></tr>\n",
              "\t<tr><td><span style=white-space:pre-wrap>Pride &amp; Prejudice  </span></td><td>and</td><td>3585</td></tr>\n",
              "\t<tr><td>Sense &amp; Sensibility</td><td>of </td><td>3571</td></tr>\n",
              "\t<tr><td>Sense &amp; Sensibility</td><td>and</td><td>3490</td></tr>\n",
              "\t<tr><td>Persuasion         </td><td>the</td><td>3329</td></tr>\n",
              "\t<tr><td>Northanger Abbey   </td><td>the</td><td>3179</td></tr>\n",
              "\t<tr><td>Emma               </td><td>i  </td><td>3177</td></tr>\n",
              "\t<tr><td>Emma               </td><td>a  </td><td>3129</td></tr>\n",
              "\t<tr><td>Mansfield Park     </td><td>a  </td><td>3099</td></tr>\n",
              "\t<tr><td>Mansfield Park     </td><td>her</td><td>3082</td></tr>\n",
              "\t<tr><td>Persuasion         </td><td>to </td><td>2808</td></tr>\n",
              "\t<tr><td>Persuasion         </td><td>and</td><td>2800</td></tr>\n",
              "\t<tr><td>Mansfield Park     </td><td>was</td><td>2651</td></tr>\n",
              "\t<tr><td>Persuasion         </td><td>of </td><td>2570</td></tr>\n",
              "\t<tr><td>Sense &amp; Sensibility</td><td>her</td><td>2543</td></tr>\n",
              "\t<tr><td>Emma               </td><td>it </td><td>2528</td></tr>\n",
              "\t<tr><td>Mansfield Park     </td><td>in </td><td>2512</td></tr>\n",
              "\t<tr><td>Emma               </td><td>her</td><td>2462</td></tr>\n",
              "\t<tr><td>⋮</td><td>⋮</td><td>⋮</td></tr>\n",
              "\t<tr><td>Persuasion</td><td>withdrawing</td><td>1</td></tr>\n",
              "\t<tr><td>Persuasion</td><td>withdrawn  </td><td>1</td></tr>\n",
              "\t<tr><td>Persuasion</td><td>withered   </td><td>1</td></tr>\n",
              "\t<tr><td>Persuasion</td><td>withholding</td><td>1</td></tr>\n",
              "\t<tr><td>Persuasion</td><td>witness    </td><td>1</td></tr>\n",
              "\t<tr><td>Persuasion</td><td>wm         </td><td>1</td></tr>\n",
              "\t<tr><td>Persuasion</td><td>woe        </td><td>1</td></tr>\n",
              "\t<tr><td>Persuasion</td><td>won        </td><td>1</td></tr>\n",
              "\t<tr><td>Persuasion</td><td>wont       </td><td>1</td></tr>\n",
              "\t<tr><td>Persuasion</td><td>wonted     </td><td>1</td></tr>\n",
              "\t<tr><td>Persuasion</td><td>wood       </td><td>1</td></tr>\n",
              "\t<tr><td>Persuasion</td><td>woody      </td><td>1</td></tr>\n",
              "\t<tr><td>Persuasion</td><td>workmen    </td><td>1</td></tr>\n",
              "\t<tr><td>Persuasion</td><td>works      </td><td>1</td></tr>\n",
              "\t<tr><td>Persuasion</td><td>world's    </td><td>1</td></tr>\n",
              "\t<tr><td>Persuasion</td><td>worsting   </td><td>1</td></tr>\n",
              "\t<tr><td>Persuasion</td><td>wrapt      </td><td>1</td></tr>\n",
              "\t<tr><td>Persuasion</td><td>wreck      </td><td>1</td></tr>\n",
              "\t<tr><td>Persuasion</td><td>wretchedly </td><td>1</td></tr>\n",
              "\t<tr><td>Persuasion</td><td>wriggles   </td><td>1</td></tr>\n",
              "\t<tr><td>Persuasion</td><td>wrinkles   </td><td>1</td></tr>\n",
              "\t<tr><td>Persuasion</td><td>wrist      </td><td>1</td></tr>\n",
              "\t<tr><td>Persuasion</td><td>yearly     </td><td>1</td></tr>\n",
              "\t<tr><td>Persuasion</td><td>yeomen     </td><td>1</td></tr>\n",
              "\t<tr><td>Persuasion</td><td>yestermorn </td><td>1</td></tr>\n",
              "\t<tr><td>Persuasion</td><td>yield      </td><td>1</td></tr>\n",
              "\t<tr><td>Persuasion</td><td>younker    </td><td>1</td></tr>\n",
              "\t<tr><td>Persuasion</td><td>youthful   </td><td>1</td></tr>\n",
              "\t<tr><td>Persuasion</td><td>z          </td><td>1</td></tr>\n",
              "\t<tr><td>Persuasion</td><td>zealously  </td><td>1</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ],
            "text/markdown": "\nA tibble: 40379 × 3\n\n| book &lt;fct&gt; | word &lt;chr&gt; | n &lt;int&gt; |\n|---|---|---|\n| Mansfield Park      | the | 6206 |\n| Mansfield Park      | to  | 5475 |\n| Mansfield Park      | and | 5438 |\n| Emma                | to  | 5239 |\n| Emma                | the | 5201 |\n| Emma                | and | 4896 |\n| Mansfield Park      | of  | 4778 |\n| Pride &amp; Prejudice   | the | 4331 |\n| Emma                | of  | 4291 |\n| Pride &amp; Prejudice   | to  | 4162 |\n| Sense &amp; Sensibility | to  | 4116 |\n| Sense &amp; Sensibility | the | 4105 |\n| Pride &amp; Prejudice   | of  | 3610 |\n| Pride &amp; Prejudice   | and | 3585 |\n| Sense &amp; Sensibility | of  | 3571 |\n| Sense &amp; Sensibility | and | 3490 |\n| Persuasion          | the | 3329 |\n| Northanger Abbey    | the | 3179 |\n| Emma                | i   | 3177 |\n| Emma                | a   | 3129 |\n| Mansfield Park      | a   | 3099 |\n| Mansfield Park      | her | 3082 |\n| Persuasion          | to  | 2808 |\n| Persuasion          | and | 2800 |\n| Mansfield Park      | was | 2651 |\n| Persuasion          | of  | 2570 |\n| Sense &amp; Sensibility | her | 2543 |\n| Emma                | it  | 2528 |\n| Mansfield Park      | in  | 2512 |\n| Emma                | her | 2462 |\n| ⋮ | ⋮ | ⋮ |\n| Persuasion | withdrawing | 1 |\n| Persuasion | withdrawn   | 1 |\n| Persuasion | withered    | 1 |\n| Persuasion | withholding | 1 |\n| Persuasion | witness     | 1 |\n| Persuasion | wm          | 1 |\n| Persuasion | woe         | 1 |\n| Persuasion | won         | 1 |\n| Persuasion | wont        | 1 |\n| Persuasion | wonted      | 1 |\n| Persuasion | wood        | 1 |\n| Persuasion | woody       | 1 |\n| Persuasion | workmen     | 1 |\n| Persuasion | works       | 1 |\n| Persuasion | world's     | 1 |\n| Persuasion | worsting    | 1 |\n| Persuasion | wrapt       | 1 |\n| Persuasion | wreck       | 1 |\n| Persuasion | wretchedly  | 1 |\n| Persuasion | wriggles    | 1 |\n| Persuasion | wrinkles    | 1 |\n| Persuasion | wrist       | 1 |\n| Persuasion | yearly      | 1 |\n| Persuasion | yeomen      | 1 |\n| Persuasion | yestermorn  | 1 |\n| Persuasion | yield       | 1 |\n| Persuasion | younker     | 1 |\n| Persuasion | youthful    | 1 |\n| Persuasion | z           | 1 |\n| Persuasion | zealously   | 1 |\n\n",
            "text/latex": "A tibble: 40379 × 3\n\\begin{tabular}{lll}\n book & word & n\\\\\n <fct> & <chr> & <int>\\\\\n\\hline\n\t Mansfield Park      & the & 6206\\\\\n\t Mansfield Park      & to  & 5475\\\\\n\t Mansfield Park      & and & 5438\\\\\n\t Emma                & to  & 5239\\\\\n\t Emma                & the & 5201\\\\\n\t Emma                & and & 4896\\\\\n\t Mansfield Park      & of  & 4778\\\\\n\t Pride \\& Prejudice   & the & 4331\\\\\n\t Emma                & of  & 4291\\\\\n\t Pride \\& Prejudice   & to  & 4162\\\\\n\t Sense \\& Sensibility & to  & 4116\\\\\n\t Sense \\& Sensibility & the & 4105\\\\\n\t Pride \\& Prejudice   & of  & 3610\\\\\n\t Pride \\& Prejudice   & and & 3585\\\\\n\t Sense \\& Sensibility & of  & 3571\\\\\n\t Sense \\& Sensibility & and & 3490\\\\\n\t Persuasion          & the & 3329\\\\\n\t Northanger Abbey    & the & 3179\\\\\n\t Emma                & i   & 3177\\\\\n\t Emma                & a   & 3129\\\\\n\t Mansfield Park      & a   & 3099\\\\\n\t Mansfield Park      & her & 3082\\\\\n\t Persuasion          & to  & 2808\\\\\n\t Persuasion          & and & 2800\\\\\n\t Mansfield Park      & was & 2651\\\\\n\t Persuasion          & of  & 2570\\\\\n\t Sense \\& Sensibility & her & 2543\\\\\n\t Emma                & it  & 2528\\\\\n\t Mansfield Park      & in  & 2512\\\\\n\t Emma                & her & 2462\\\\\n\t ⋮ & ⋮ & ⋮\\\\\n\t Persuasion & withdrawing & 1\\\\\n\t Persuasion & withdrawn   & 1\\\\\n\t Persuasion & withered    & 1\\\\\n\t Persuasion & withholding & 1\\\\\n\t Persuasion & witness     & 1\\\\\n\t Persuasion & wm          & 1\\\\\n\t Persuasion & woe         & 1\\\\\n\t Persuasion & won         & 1\\\\\n\t Persuasion & wont        & 1\\\\\n\t Persuasion & wonted      & 1\\\\\n\t Persuasion & wood        & 1\\\\\n\t Persuasion & woody       & 1\\\\\n\t Persuasion & workmen     & 1\\\\\n\t Persuasion & works       & 1\\\\\n\t Persuasion & world's     & 1\\\\\n\t Persuasion & worsting    & 1\\\\\n\t Persuasion & wrapt       & 1\\\\\n\t Persuasion & wreck       & 1\\\\\n\t Persuasion & wretchedly  & 1\\\\\n\t Persuasion & wriggles    & 1\\\\\n\t Persuasion & wrinkles    & 1\\\\\n\t Persuasion & wrist       & 1\\\\\n\t Persuasion & yearly      & 1\\\\\n\t Persuasion & yeomen      & 1\\\\\n\t Persuasion & yestermorn  & 1\\\\\n\t Persuasion & yield       & 1\\\\\n\t Persuasion & younker     & 1\\\\\n\t Persuasion & youthful    & 1\\\\\n\t Persuasion & z           & 1\\\\\n\t Persuasion & zealously   & 1\\\\\n\\end{tabular}\n",
            "text/plain": [
              "      book                word        n   \n",
              "1     Mansfield Park      the         6206\n",
              "2     Mansfield Park      to          5475\n",
              "3     Mansfield Park      and         5438\n",
              "4     Emma                to          5239\n",
              "5     Emma                the         5201\n",
              "6     Emma                and         4896\n",
              "7     Mansfield Park      of          4778\n",
              "8     Pride & Prejudice   the         4331\n",
              "9     Emma                of          4291\n",
              "10    Pride & Prejudice   to          4162\n",
              "11    Sense & Sensibility to          4116\n",
              "12    Sense & Sensibility the         4105\n",
              "13    Pride & Prejudice   of          3610\n",
              "14    Pride & Prejudice   and         3585\n",
              "15    Sense & Sensibility of          3571\n",
              "16    Sense & Sensibility and         3490\n",
              "17    Persuasion          the         3329\n",
              "18    Northanger Abbey    the         3179\n",
              "19    Emma                i           3177\n",
              "20    Emma                a           3129\n",
              "21    Mansfield Park      a           3099\n",
              "22    Mansfield Park      her         3082\n",
              "23    Persuasion          to          2808\n",
              "24    Persuasion          and         2800\n",
              "25    Mansfield Park      was         2651\n",
              "26    Persuasion          of          2570\n",
              "27    Sense & Sensibility her         2543\n",
              "28    Emma                it          2528\n",
              "29    Mansfield Park      in          2512\n",
              "30    Emma                her         2462\n",
              "⋮     ⋮                   ⋮           ⋮   \n",
              "40350 Persuasion          withdrawing 1   \n",
              "40351 Persuasion          withdrawn   1   \n",
              "40352 Persuasion          withered    1   \n",
              "40353 Persuasion          withholding 1   \n",
              "40354 Persuasion          witness     1   \n",
              "40355 Persuasion          wm          1   \n",
              "40356 Persuasion          woe         1   \n",
              "40357 Persuasion          won         1   \n",
              "40358 Persuasion          wont        1   \n",
              "40359 Persuasion          wonted      1   \n",
              "40360 Persuasion          wood        1   \n",
              "40361 Persuasion          woody       1   \n",
              "40362 Persuasion          workmen     1   \n",
              "40363 Persuasion          works       1   \n",
              "40364 Persuasion          world's     1   \n",
              "40365 Persuasion          worsting    1   \n",
              "40366 Persuasion          wrapt       1   \n",
              "40367 Persuasion          wreck       1   \n",
              "40368 Persuasion          wretchedly  1   \n",
              "40369 Persuasion          wriggles    1   \n",
              "40370 Persuasion          wrinkles    1   \n",
              "40371 Persuasion          wrist       1   \n",
              "40372 Persuasion          yearly      1   \n",
              "40373 Persuasion          yeomen      1   \n",
              "40374 Persuasion          yestermorn  1   \n",
              "40375 Persuasion          yield       1   \n",
              "40376 Persuasion          younker     1   \n",
              "40377 Persuasion          youthful    1   \n",
              "40378 Persuasion          z           1   \n",
              "40379 Persuasion          zealously   1   "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Identifica total de palavras por livro\n",
        "total_words <- book_words %>%\n",
        "  group_by(book) %>%\n",
        "  summarize(total = sum(n))\n",
        "\n",
        "total_words"
      ],
      "metadata": {
        "id": "Km7B3_q9b7hi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "9065a89d-0480-4a06-f45b-483f3945adcc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A tibble: 6 × 2</caption>\n",
              "<thead>\n",
              "\t<tr><th scope=col>book</th><th scope=col>total</th></tr>\n",
              "\t<tr><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;int&gt;</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><td>Sense &amp; Sensibility</td><td>119957</td></tr>\n",
              "\t<tr><td><span style=white-space:pre-wrap>Pride &amp; Prejudice  </span></td><td>122204</td></tr>\n",
              "\t<tr><td>Mansfield Park     </td><td>160460</td></tr>\n",
              "\t<tr><td>Emma               </td><td>160996</td></tr>\n",
              "\t<tr><td>Northanger Abbey   </td><td> 77780</td></tr>\n",
              "\t<tr><td>Persuasion         </td><td> 83658</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ],
            "text/markdown": "\nA tibble: 6 × 2\n\n| book &lt;fct&gt; | total &lt;int&gt; |\n|---|---|\n| Sense &amp; Sensibility | 119957 |\n| Pride &amp; Prejudice   | 122204 |\n| Mansfield Park      | 160460 |\n| Emma                | 160996 |\n| Northanger Abbey    |  77780 |\n| Persuasion          |  83658 |\n\n",
            "text/latex": "A tibble: 6 × 2\n\\begin{tabular}{ll}\n book & total\\\\\n <fct> & <int>\\\\\n\\hline\n\t Sense \\& Sensibility & 119957\\\\\n\t Pride \\& Prejudice   & 122204\\\\\n\t Mansfield Park      & 160460\\\\\n\t Emma                & 160996\\\\\n\t Northanger Abbey    &  77780\\\\\n\t Persuasion          &  83658\\\\\n\\end{tabular}\n",
            "text/plain": [
              "  book                total \n",
              "1 Sense & Sensibility 119957\n",
              "2 Pride & Prejudice   122204\n",
              "3 Mansfield Park      160460\n",
              "4 Emma                160996\n",
              "5 Northanger Abbey     77780\n",
              "6 Persuasion           83658"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se desejarmos, podemos adicionar essa informação em nossa tabela:\n"
      ],
      "metadata": {
        "id": "U_7lMnOyf9My"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# adiciona total de palavras à tabela de dados\n",
        "book_words <- left_join(book_words, total_words)\n",
        "head(book_words, n=10)"
      ],
      "metadata": {
        "id": "eVWipCr1gBBE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        },
        "outputId": "015ceb68-cb4c-4ed8-91db-fe0394b4718a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1m\u001b[22mJoining with `by = join_by(book)`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A tibble: 10 × 4</caption>\n",
              "<thead>\n",
              "\t<tr><th scope=col>book</th><th scope=col>word</th><th scope=col>n</th><th scope=col>total</th></tr>\n",
              "\t<tr><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><td>Mansfield Park   </td><td>the</td><td>6206</td><td>160460</td></tr>\n",
              "\t<tr><td>Mansfield Park   </td><td>to </td><td>5475</td><td>160460</td></tr>\n",
              "\t<tr><td>Mansfield Park   </td><td>and</td><td>5438</td><td>160460</td></tr>\n",
              "\t<tr><td>Emma             </td><td>to </td><td>5239</td><td>160996</td></tr>\n",
              "\t<tr><td>Emma             </td><td>the</td><td>5201</td><td>160996</td></tr>\n",
              "\t<tr><td>Emma             </td><td>and</td><td>4896</td><td>160996</td></tr>\n",
              "\t<tr><td>Mansfield Park   </td><td>of </td><td>4778</td><td>160460</td></tr>\n",
              "\t<tr><td>Pride &amp; Prejudice</td><td>the</td><td>4331</td><td>122204</td></tr>\n",
              "\t<tr><td>Emma             </td><td>of </td><td>4291</td><td>160996</td></tr>\n",
              "\t<tr><td>Pride &amp; Prejudice</td><td>to </td><td>4162</td><td>122204</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ],
            "text/markdown": "\nA tibble: 10 × 4\n\n| book &lt;fct&gt; | word &lt;chr&gt; | n &lt;int&gt; | total &lt;int&gt; |\n|---|---|---|---|\n| Mansfield Park    | the | 6206 | 160460 |\n| Mansfield Park    | to  | 5475 | 160460 |\n| Mansfield Park    | and | 5438 | 160460 |\n| Emma              | to  | 5239 | 160996 |\n| Emma              | the | 5201 | 160996 |\n| Emma              | and | 4896 | 160996 |\n| Mansfield Park    | of  | 4778 | 160460 |\n| Pride &amp; Prejudice | the | 4331 | 122204 |\n| Emma              | of  | 4291 | 160996 |\n| Pride &amp; Prejudice | to  | 4162 | 122204 |\n\n",
            "text/latex": "A tibble: 10 × 4\n\\begin{tabular}{llll}\n book & word & n & total\\\\\n <fct> & <chr> & <int> & <int>\\\\\n\\hline\n\t Mansfield Park    & the & 6206 & 160460\\\\\n\t Mansfield Park    & to  & 5475 & 160460\\\\\n\t Mansfield Park    & and & 5438 & 160460\\\\\n\t Emma              & to  & 5239 & 160996\\\\\n\t Emma              & the & 5201 & 160996\\\\\n\t Emma              & and & 4896 & 160996\\\\\n\t Mansfield Park    & of  & 4778 & 160460\\\\\n\t Pride \\& Prejudice & the & 4331 & 122204\\\\\n\t Emma              & of  & 4291 & 160996\\\\\n\t Pride \\& Prejudice & to  & 4162 & 122204\\\\\n\\end{tabular}\n",
            "text/plain": [
              "   book              word n    total \n",
              "1  Mansfield Park    the  6206 160460\n",
              "2  Mansfield Park    to   5475 160460\n",
              "3  Mansfield Park    and  5438 160460\n",
              "4  Emma              to   5239 160996\n",
              "5  Emma              the  5201 160996\n",
              "6  Emma              and  4896 160996\n",
              "7  Mansfield Park    of   4778 160460\n",
              "8  Pride & Prejudice the  4331 122204\n",
              "9  Emma              of   4291 160996\n",
              "10 Pride & Prejudice to   4162 122204"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Frequência Relativa e TF-IDF\n",
        "\n",
        "O cálculo de `tf` e `idf` não é muito complicado, mas não necessitamos realizar esse cálculo nós mesmos, pois a biblioteca `tidytext` já tem uma função que realiza esse cálculo para nós.\n",
        "\n",
        "A função `bind_tf_idf()` calcular os valores de `tf`, `idf` e `tf-idf`.\n",
        "\n",
        "É muito simples:"
      ],
      "metadata": {
        "id": "6jqg2SVfcgwS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "book_tf_idf <- book_words %>% bind_tf_idf(word, book, n)   # Acrescenta tf (frequência relativa)\n",
        "book_tf_idf"
      ],
      "metadata": {
        "id": "mylxhHAIcj_2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0c99d2dd-89da-4e05-ecf7-d14bafef5a56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A tibble: 40379 × 7</caption>\n",
              "<thead>\n",
              "\t<tr><th scope=col>book</th><th scope=col>word</th><th scope=col>n</th><th scope=col>total</th><th scope=col>tf</th><th scope=col>idf</th><th scope=col>tf_idf</th></tr>\n",
              "\t<tr><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><td>Mansfield Park     </td><td>the</td><td>6206</td><td>160460</td><td>0.03867631</td><td>0</td><td>0</td></tr>\n",
              "\t<tr><td>Mansfield Park     </td><td>to </td><td>5475</td><td>160460</td><td>0.03412065</td><td>0</td><td>0</td></tr>\n",
              "\t<tr><td>Mansfield Park     </td><td>and</td><td>5438</td><td>160460</td><td>0.03389007</td><td>0</td><td>0</td></tr>\n",
              "\t<tr><td>Emma               </td><td>to </td><td>5239</td><td>160996</td><td>0.03254118</td><td>0</td><td>0</td></tr>\n",
              "\t<tr><td>Emma               </td><td>the</td><td>5201</td><td>160996</td><td>0.03230515</td><td>0</td><td>0</td></tr>\n",
              "\t<tr><td>Emma               </td><td>and</td><td>4896</td><td>160996</td><td>0.03041069</td><td>0</td><td>0</td></tr>\n",
              "\t<tr><td>Mansfield Park     </td><td>of </td><td>4778</td><td>160460</td><td>0.02977689</td><td>0</td><td>0</td></tr>\n",
              "\t<tr><td><span style=white-space:pre-wrap>Pride &amp; Prejudice  </span></td><td>the</td><td>4331</td><td>122204</td><td>0.03544074</td><td>0</td><td>0</td></tr>\n",
              "\t<tr><td>Emma               </td><td>of </td><td>4291</td><td>160996</td><td>0.02665284</td><td>0</td><td>0</td></tr>\n",
              "\t<tr><td><span style=white-space:pre-wrap>Pride &amp; Prejudice  </span></td><td>to </td><td>4162</td><td>122204</td><td>0.03405780</td><td>0</td><td>0</td></tr>\n",
              "\t<tr><td>Sense &amp; Sensibility</td><td>to </td><td>4116</td><td>119957</td><td>0.03431230</td><td>0</td><td>0</td></tr>\n",
              "\t<tr><td>Sense &amp; Sensibility</td><td>the</td><td>4105</td><td>119957</td><td>0.03422060</td><td>0</td><td>0</td></tr>\n",
              "\t<tr><td><span style=white-space:pre-wrap>Pride &amp; Prejudice  </span></td><td>of </td><td>3610</td><td>122204</td><td>0.02954077</td><td>0</td><td>0</td></tr>\n",
              "\t<tr><td><span style=white-space:pre-wrap>Pride &amp; Prejudice  </span></td><td>and</td><td>3585</td><td>122204</td><td>0.02933619</td><td>0</td><td>0</td></tr>\n",
              "\t<tr><td>Sense &amp; Sensibility</td><td>of </td><td>3571</td><td>119957</td><td>0.02976900</td><td>0</td><td>0</td></tr>\n",
              "\t<tr><td>Sense &amp; Sensibility</td><td>and</td><td>3490</td><td>119957</td><td>0.02909376</td><td>0</td><td>0</td></tr>\n",
              "\t<tr><td>Persuasion         </td><td>the</td><td>3329</td><td> 83658</td><td>0.03979297</td><td>0</td><td>0</td></tr>\n",
              "\t<tr><td>Northanger Abbey   </td><td>the</td><td>3179</td><td> 77780</td><td>0.04087169</td><td>0</td><td>0</td></tr>\n",
              "\t<tr><td>Emma               </td><td>i  </td><td>3177</td><td>160996</td><td>0.01973341</td><td>0</td><td>0</td></tr>\n",
              "\t<tr><td>Emma               </td><td>a  </td><td>3129</td><td>160996</td><td>0.01943527</td><td>0</td><td>0</td></tr>\n",
              "\t<tr><td>Mansfield Park     </td><td>a  </td><td>3099</td><td>160460</td><td>0.01931322</td><td>0</td><td>0</td></tr>\n",
              "\t<tr><td>Mansfield Park     </td><td>her</td><td>3082</td><td>160460</td><td>0.01920728</td><td>0</td><td>0</td></tr>\n",
              "\t<tr><td>Persuasion         </td><td>to </td><td>2808</td><td> 83658</td><td>0.03356523</td><td>0</td><td>0</td></tr>\n",
              "\t<tr><td>Persuasion         </td><td>and</td><td>2800</td><td> 83658</td><td>0.03346960</td><td>0</td><td>0</td></tr>\n",
              "\t<tr><td>Mansfield Park     </td><td>was</td><td>2651</td><td>160460</td><td>0.01652125</td><td>0</td><td>0</td></tr>\n",
              "\t<tr><td>Persuasion         </td><td>of </td><td>2570</td><td> 83658</td><td>0.03072031</td><td>0</td><td>0</td></tr>\n",
              "\t<tr><td>Sense &amp; Sensibility</td><td>her</td><td>2543</td><td>119957</td><td>0.02119926</td><td>0</td><td>0</td></tr>\n",
              "\t<tr><td>Emma               </td><td>it </td><td>2528</td><td>160996</td><td>0.01570225</td><td>0</td><td>0</td></tr>\n",
              "\t<tr><td>Mansfield Park     </td><td>in </td><td>2512</td><td>160460</td><td>0.01565499</td><td>0</td><td>0</td></tr>\n",
              "\t<tr><td>Emma               </td><td>her</td><td>2462</td><td>160996</td><td>0.01529231</td><td>0</td><td>0</td></tr>\n",
              "\t<tr><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td></tr>\n",
              "\t<tr><td>Persuasion</td><td>withdrawing</td><td>1</td><td>83658</td><td>1.195343e-05</td><td>0.6931472</td><td>8.285486e-06</td></tr>\n",
              "\t<tr><td>Persuasion</td><td>withdrawn  </td><td>1</td><td>83658</td><td>1.195343e-05</td><td>0.0000000</td><td>0.000000e+00</td></tr>\n",
              "\t<tr><td>Persuasion</td><td>withered   </td><td>1</td><td>83658</td><td>1.195343e-05</td><td>1.0986123</td><td>1.313218e-05</td></tr>\n",
              "\t<tr><td>Persuasion</td><td>withholding</td><td>1</td><td>83658</td><td>1.195343e-05</td><td>1.7917595</td><td>2.141767e-05</td></tr>\n",
              "\t<tr><td>Persuasion</td><td>witness    </td><td>1</td><td>83658</td><td>1.195343e-05</td><td>0.0000000</td><td>0.000000e+00</td></tr>\n",
              "\t<tr><td>Persuasion</td><td>wm         </td><td>1</td><td>83658</td><td>1.195343e-05</td><td>1.7917595</td><td>2.141767e-05</td></tr>\n",
              "\t<tr><td>Persuasion</td><td>woe        </td><td>1</td><td>83658</td><td>1.195343e-05</td><td>0.4054651</td><td>4.846699e-06</td></tr>\n",
              "\t<tr><td>Persuasion</td><td>won        </td><td>1</td><td>83658</td><td>1.195343e-05</td><td>0.6931472</td><td>8.285486e-06</td></tr>\n",
              "\t<tr><td>Persuasion</td><td>wont       </td><td>1</td><td>83658</td><td>1.195343e-05</td><td>0.4054651</td><td>4.846699e-06</td></tr>\n",
              "\t<tr><td>Persuasion</td><td>wonted     </td><td>1</td><td>83658</td><td>1.195343e-05</td><td>1.0986123</td><td>1.313218e-05</td></tr>\n",
              "\t<tr><td>Persuasion</td><td>wood       </td><td>1</td><td>83658</td><td>1.195343e-05</td><td>0.0000000</td><td>0.000000e+00</td></tr>\n",
              "\t<tr><td>Persuasion</td><td>woody      </td><td>1</td><td>83658</td><td>1.195343e-05</td><td>0.4054651</td><td>4.846699e-06</td></tr>\n",
              "\t<tr><td>Persuasion</td><td>workmen    </td><td>1</td><td>83658</td><td>1.195343e-05</td><td>0.6931472</td><td>8.285486e-06</td></tr>\n",
              "\t<tr><td>Persuasion</td><td>works      </td><td>1</td><td>83658</td><td>1.195343e-05</td><td>0.1823216</td><td>2.179368e-06</td></tr>\n",
              "\t<tr><td>Persuasion</td><td>world's    </td><td>1</td><td>83658</td><td>1.195343e-05</td><td>1.0986123</td><td>1.313218e-05</td></tr>\n",
              "\t<tr><td>Persuasion</td><td>worsting   </td><td>1</td><td>83658</td><td>1.195343e-05</td><td>1.7917595</td><td>2.141767e-05</td></tr>\n",
              "\t<tr><td>Persuasion</td><td>wrapt      </td><td>1</td><td>83658</td><td>1.195343e-05</td><td>0.4054651</td><td>4.846699e-06</td></tr>\n",
              "\t<tr><td>Persuasion</td><td>wreck      </td><td>1</td><td>83658</td><td>1.195343e-05</td><td>1.7917595</td><td>2.141767e-05</td></tr>\n",
              "\t<tr><td>Persuasion</td><td>wretchedly </td><td>1</td><td>83658</td><td>1.195343e-05</td><td>0.0000000</td><td>0.000000e+00</td></tr>\n",
              "\t<tr><td>Persuasion</td><td>wriggles   </td><td>1</td><td>83658</td><td>1.195343e-05</td><td>1.7917595</td><td>2.141767e-05</td></tr>\n",
              "\t<tr><td>Persuasion</td><td>wrinkles   </td><td>1</td><td>83658</td><td>1.195343e-05</td><td>1.0986123</td><td>1.313218e-05</td></tr>\n",
              "\t<tr><td>Persuasion</td><td>wrist      </td><td>1</td><td>83658</td><td>1.195343e-05</td><td>1.0986123</td><td>1.313218e-05</td></tr>\n",
              "\t<tr><td>Persuasion</td><td>yearly     </td><td>1</td><td>83658</td><td>1.195343e-05</td><td>0.4054651</td><td>4.846699e-06</td></tr>\n",
              "\t<tr><td>Persuasion</td><td>yeomen     </td><td>1</td><td>83658</td><td>1.195343e-05</td><td>1.7917595</td><td>2.141767e-05</td></tr>\n",
              "\t<tr><td>Persuasion</td><td>yestermorn </td><td>1</td><td>83658</td><td>1.195343e-05</td><td>1.7917595</td><td>2.141767e-05</td></tr>\n",
              "\t<tr><td>Persuasion</td><td>yield      </td><td>1</td><td>83658</td><td>1.195343e-05</td><td>0.1823216</td><td>2.179368e-06</td></tr>\n",
              "\t<tr><td>Persuasion</td><td>younker    </td><td>1</td><td>83658</td><td>1.195343e-05</td><td>1.7917595</td><td>2.141767e-05</td></tr>\n",
              "\t<tr><td>Persuasion</td><td>youthful   </td><td>1</td><td>83658</td><td>1.195343e-05</td><td>0.4054651</td><td>4.846699e-06</td></tr>\n",
              "\t<tr><td>Persuasion</td><td>z          </td><td>1</td><td>83658</td><td>1.195343e-05</td><td>1.7917595</td><td>2.141767e-05</td></tr>\n",
              "\t<tr><td>Persuasion</td><td>zealously  </td><td>1</td><td>83658</td><td>1.195343e-05</td><td>1.0986123</td><td>1.313218e-05</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ],
            "text/markdown": "\nA tibble: 40379 × 7\n\n| book &lt;fct&gt; | word &lt;chr&gt; | n &lt;int&gt; | total &lt;int&gt; | tf &lt;dbl&gt; | idf &lt;dbl&gt; | tf_idf &lt;dbl&gt; |\n|---|---|---|---|---|---|---|\n| Mansfield Park      | the | 6206 | 160460 | 0.03867631 | 0 | 0 |\n| Mansfield Park      | to  | 5475 | 160460 | 0.03412065 | 0 | 0 |\n| Mansfield Park      | and | 5438 | 160460 | 0.03389007 | 0 | 0 |\n| Emma                | to  | 5239 | 160996 | 0.03254118 | 0 | 0 |\n| Emma                | the | 5201 | 160996 | 0.03230515 | 0 | 0 |\n| Emma                | and | 4896 | 160996 | 0.03041069 | 0 | 0 |\n| Mansfield Park      | of  | 4778 | 160460 | 0.02977689 | 0 | 0 |\n| Pride &amp; Prejudice   | the | 4331 | 122204 | 0.03544074 | 0 | 0 |\n| Emma                | of  | 4291 | 160996 | 0.02665284 | 0 | 0 |\n| Pride &amp; Prejudice   | to  | 4162 | 122204 | 0.03405780 | 0 | 0 |\n| Sense &amp; Sensibility | to  | 4116 | 119957 | 0.03431230 | 0 | 0 |\n| Sense &amp; Sensibility | the | 4105 | 119957 | 0.03422060 | 0 | 0 |\n| Pride &amp; Prejudice   | of  | 3610 | 122204 | 0.02954077 | 0 | 0 |\n| Pride &amp; Prejudice   | and | 3585 | 122204 | 0.02933619 | 0 | 0 |\n| Sense &amp; Sensibility | of  | 3571 | 119957 | 0.02976900 | 0 | 0 |\n| Sense &amp; Sensibility | and | 3490 | 119957 | 0.02909376 | 0 | 0 |\n| Persuasion          | the | 3329 |  83658 | 0.03979297 | 0 | 0 |\n| Northanger Abbey    | the | 3179 |  77780 | 0.04087169 | 0 | 0 |\n| Emma                | i   | 3177 | 160996 | 0.01973341 | 0 | 0 |\n| Emma                | a   | 3129 | 160996 | 0.01943527 | 0 | 0 |\n| Mansfield Park      | a   | 3099 | 160460 | 0.01931322 | 0 | 0 |\n| Mansfield Park      | her | 3082 | 160460 | 0.01920728 | 0 | 0 |\n| Persuasion          | to  | 2808 |  83658 | 0.03356523 | 0 | 0 |\n| Persuasion          | and | 2800 |  83658 | 0.03346960 | 0 | 0 |\n| Mansfield Park      | was | 2651 | 160460 | 0.01652125 | 0 | 0 |\n| Persuasion          | of  | 2570 |  83658 | 0.03072031 | 0 | 0 |\n| Sense &amp; Sensibility | her | 2543 | 119957 | 0.02119926 | 0 | 0 |\n| Emma                | it  | 2528 | 160996 | 0.01570225 | 0 | 0 |\n| Mansfield Park      | in  | 2512 | 160460 | 0.01565499 | 0 | 0 |\n| Emma                | her | 2462 | 160996 | 0.01529231 | 0 | 0 |\n| ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ |\n| Persuasion | withdrawing | 1 | 83658 | 1.195343e-05 | 0.6931472 | 8.285486e-06 |\n| Persuasion | withdrawn   | 1 | 83658 | 1.195343e-05 | 0.0000000 | 0.000000e+00 |\n| Persuasion | withered    | 1 | 83658 | 1.195343e-05 | 1.0986123 | 1.313218e-05 |\n| Persuasion | withholding | 1 | 83658 | 1.195343e-05 | 1.7917595 | 2.141767e-05 |\n| Persuasion | witness     | 1 | 83658 | 1.195343e-05 | 0.0000000 | 0.000000e+00 |\n| Persuasion | wm          | 1 | 83658 | 1.195343e-05 | 1.7917595 | 2.141767e-05 |\n| Persuasion | woe         | 1 | 83658 | 1.195343e-05 | 0.4054651 | 4.846699e-06 |\n| Persuasion | won         | 1 | 83658 | 1.195343e-05 | 0.6931472 | 8.285486e-06 |\n| Persuasion | wont        | 1 | 83658 | 1.195343e-05 | 0.4054651 | 4.846699e-06 |\n| Persuasion | wonted      | 1 | 83658 | 1.195343e-05 | 1.0986123 | 1.313218e-05 |\n| Persuasion | wood        | 1 | 83658 | 1.195343e-05 | 0.0000000 | 0.000000e+00 |\n| Persuasion | woody       | 1 | 83658 | 1.195343e-05 | 0.4054651 | 4.846699e-06 |\n| Persuasion | workmen     | 1 | 83658 | 1.195343e-05 | 0.6931472 | 8.285486e-06 |\n| Persuasion | works       | 1 | 83658 | 1.195343e-05 | 0.1823216 | 2.179368e-06 |\n| Persuasion | world's     | 1 | 83658 | 1.195343e-05 | 1.0986123 | 1.313218e-05 |\n| Persuasion | worsting    | 1 | 83658 | 1.195343e-05 | 1.7917595 | 2.141767e-05 |\n| Persuasion | wrapt       | 1 | 83658 | 1.195343e-05 | 0.4054651 | 4.846699e-06 |\n| Persuasion | wreck       | 1 | 83658 | 1.195343e-05 | 1.7917595 | 2.141767e-05 |\n| Persuasion | wretchedly  | 1 | 83658 | 1.195343e-05 | 0.0000000 | 0.000000e+00 |\n| Persuasion | wriggles    | 1 | 83658 | 1.195343e-05 | 1.7917595 | 2.141767e-05 |\n| Persuasion | wrinkles    | 1 | 83658 | 1.195343e-05 | 1.0986123 | 1.313218e-05 |\n| Persuasion | wrist       | 1 | 83658 | 1.195343e-05 | 1.0986123 | 1.313218e-05 |\n| Persuasion | yearly      | 1 | 83658 | 1.195343e-05 | 0.4054651 | 4.846699e-06 |\n| Persuasion | yeomen      | 1 | 83658 | 1.195343e-05 | 1.7917595 | 2.141767e-05 |\n| Persuasion | yestermorn  | 1 | 83658 | 1.195343e-05 | 1.7917595 | 2.141767e-05 |\n| Persuasion | yield       | 1 | 83658 | 1.195343e-05 | 0.1823216 | 2.179368e-06 |\n| Persuasion | younker     | 1 | 83658 | 1.195343e-05 | 1.7917595 | 2.141767e-05 |\n| Persuasion | youthful    | 1 | 83658 | 1.195343e-05 | 0.4054651 | 4.846699e-06 |\n| Persuasion | z           | 1 | 83658 | 1.195343e-05 | 1.7917595 | 2.141767e-05 |\n| Persuasion | zealously   | 1 | 83658 | 1.195343e-05 | 1.0986123 | 1.313218e-05 |\n\n",
            "text/latex": "A tibble: 40379 × 7\n\\begin{tabular}{lllllll}\n book & word & n & total & tf & idf & tf\\_idf\\\\\n <fct> & <chr> & <int> & <int> & <dbl> & <dbl> & <dbl>\\\\\n\\hline\n\t Mansfield Park      & the & 6206 & 160460 & 0.03867631 & 0 & 0\\\\\n\t Mansfield Park      & to  & 5475 & 160460 & 0.03412065 & 0 & 0\\\\\n\t Mansfield Park      & and & 5438 & 160460 & 0.03389007 & 0 & 0\\\\\n\t Emma                & to  & 5239 & 160996 & 0.03254118 & 0 & 0\\\\\n\t Emma                & the & 5201 & 160996 & 0.03230515 & 0 & 0\\\\\n\t Emma                & and & 4896 & 160996 & 0.03041069 & 0 & 0\\\\\n\t Mansfield Park      & of  & 4778 & 160460 & 0.02977689 & 0 & 0\\\\\n\t Pride \\& Prejudice   & the & 4331 & 122204 & 0.03544074 & 0 & 0\\\\\n\t Emma                & of  & 4291 & 160996 & 0.02665284 & 0 & 0\\\\\n\t Pride \\& Prejudice   & to  & 4162 & 122204 & 0.03405780 & 0 & 0\\\\\n\t Sense \\& Sensibility & to  & 4116 & 119957 & 0.03431230 & 0 & 0\\\\\n\t Sense \\& Sensibility & the & 4105 & 119957 & 0.03422060 & 0 & 0\\\\\n\t Pride \\& Prejudice   & of  & 3610 & 122204 & 0.02954077 & 0 & 0\\\\\n\t Pride \\& Prejudice   & and & 3585 & 122204 & 0.02933619 & 0 & 0\\\\\n\t Sense \\& Sensibility & of  & 3571 & 119957 & 0.02976900 & 0 & 0\\\\\n\t Sense \\& Sensibility & and & 3490 & 119957 & 0.02909376 & 0 & 0\\\\\n\t Persuasion          & the & 3329 &  83658 & 0.03979297 & 0 & 0\\\\\n\t Northanger Abbey    & the & 3179 &  77780 & 0.04087169 & 0 & 0\\\\\n\t Emma                & i   & 3177 & 160996 & 0.01973341 & 0 & 0\\\\\n\t Emma                & a   & 3129 & 160996 & 0.01943527 & 0 & 0\\\\\n\t Mansfield Park      & a   & 3099 & 160460 & 0.01931322 & 0 & 0\\\\\n\t Mansfield Park      & her & 3082 & 160460 & 0.01920728 & 0 & 0\\\\\n\t Persuasion          & to  & 2808 &  83658 & 0.03356523 & 0 & 0\\\\\n\t Persuasion          & and & 2800 &  83658 & 0.03346960 & 0 & 0\\\\\n\t Mansfield Park      & was & 2651 & 160460 & 0.01652125 & 0 & 0\\\\\n\t Persuasion          & of  & 2570 &  83658 & 0.03072031 & 0 & 0\\\\\n\t Sense \\& Sensibility & her & 2543 & 119957 & 0.02119926 & 0 & 0\\\\\n\t Emma                & it  & 2528 & 160996 & 0.01570225 & 0 & 0\\\\\n\t Mansfield Park      & in  & 2512 & 160460 & 0.01565499 & 0 & 0\\\\\n\t Emma                & her & 2462 & 160996 & 0.01529231 & 0 & 0\\\\\n\t ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮\\\\\n\t Persuasion & withdrawing & 1 & 83658 & 1.195343e-05 & 0.6931472 & 8.285486e-06\\\\\n\t Persuasion & withdrawn   & 1 & 83658 & 1.195343e-05 & 0.0000000 & 0.000000e+00\\\\\n\t Persuasion & withered    & 1 & 83658 & 1.195343e-05 & 1.0986123 & 1.313218e-05\\\\\n\t Persuasion & withholding & 1 & 83658 & 1.195343e-05 & 1.7917595 & 2.141767e-05\\\\\n\t Persuasion & witness     & 1 & 83658 & 1.195343e-05 & 0.0000000 & 0.000000e+00\\\\\n\t Persuasion & wm          & 1 & 83658 & 1.195343e-05 & 1.7917595 & 2.141767e-05\\\\\n\t Persuasion & woe         & 1 & 83658 & 1.195343e-05 & 0.4054651 & 4.846699e-06\\\\\n\t Persuasion & won         & 1 & 83658 & 1.195343e-05 & 0.6931472 & 8.285486e-06\\\\\n\t Persuasion & wont        & 1 & 83658 & 1.195343e-05 & 0.4054651 & 4.846699e-06\\\\\n\t Persuasion & wonted      & 1 & 83658 & 1.195343e-05 & 1.0986123 & 1.313218e-05\\\\\n\t Persuasion & wood        & 1 & 83658 & 1.195343e-05 & 0.0000000 & 0.000000e+00\\\\\n\t Persuasion & woody       & 1 & 83658 & 1.195343e-05 & 0.4054651 & 4.846699e-06\\\\\n\t Persuasion & workmen     & 1 & 83658 & 1.195343e-05 & 0.6931472 & 8.285486e-06\\\\\n\t Persuasion & works       & 1 & 83658 & 1.195343e-05 & 0.1823216 & 2.179368e-06\\\\\n\t Persuasion & world's     & 1 & 83658 & 1.195343e-05 & 1.0986123 & 1.313218e-05\\\\\n\t Persuasion & worsting    & 1 & 83658 & 1.195343e-05 & 1.7917595 & 2.141767e-05\\\\\n\t Persuasion & wrapt       & 1 & 83658 & 1.195343e-05 & 0.4054651 & 4.846699e-06\\\\\n\t Persuasion & wreck       & 1 & 83658 & 1.195343e-05 & 1.7917595 & 2.141767e-05\\\\\n\t Persuasion & wretchedly  & 1 & 83658 & 1.195343e-05 & 0.0000000 & 0.000000e+00\\\\\n\t Persuasion & wriggles    & 1 & 83658 & 1.195343e-05 & 1.7917595 & 2.141767e-05\\\\\n\t Persuasion & wrinkles    & 1 & 83658 & 1.195343e-05 & 1.0986123 & 1.313218e-05\\\\\n\t Persuasion & wrist       & 1 & 83658 & 1.195343e-05 & 1.0986123 & 1.313218e-05\\\\\n\t Persuasion & yearly      & 1 & 83658 & 1.195343e-05 & 0.4054651 & 4.846699e-06\\\\\n\t Persuasion & yeomen      & 1 & 83658 & 1.195343e-05 & 1.7917595 & 2.141767e-05\\\\\n\t Persuasion & yestermorn  & 1 & 83658 & 1.195343e-05 & 1.7917595 & 2.141767e-05\\\\\n\t Persuasion & yield       & 1 & 83658 & 1.195343e-05 & 0.1823216 & 2.179368e-06\\\\\n\t Persuasion & younker     & 1 & 83658 & 1.195343e-05 & 1.7917595 & 2.141767e-05\\\\\n\t Persuasion & youthful    & 1 & 83658 & 1.195343e-05 & 0.4054651 & 4.846699e-06\\\\\n\t Persuasion & z           & 1 & 83658 & 1.195343e-05 & 1.7917595 & 2.141767e-05\\\\\n\t Persuasion & zealously   & 1 & 83658 & 1.195343e-05 & 1.0986123 & 1.313218e-05\\\\\n\\end{tabular}\n",
            "text/plain": [
              "      book                word        n    total  tf           idf      \n",
              "1     Mansfield Park      the         6206 160460 0.03867631   0        \n",
              "2     Mansfield Park      to          5475 160460 0.03412065   0        \n",
              "3     Mansfield Park      and         5438 160460 0.03389007   0        \n",
              "4     Emma                to          5239 160996 0.03254118   0        \n",
              "5     Emma                the         5201 160996 0.03230515   0        \n",
              "6     Emma                and         4896 160996 0.03041069   0        \n",
              "7     Mansfield Park      of          4778 160460 0.02977689   0        \n",
              "8     Pride & Prejudice   the         4331 122204 0.03544074   0        \n",
              "9     Emma                of          4291 160996 0.02665284   0        \n",
              "10    Pride & Prejudice   to          4162 122204 0.03405780   0        \n",
              "11    Sense & Sensibility to          4116 119957 0.03431230   0        \n",
              "12    Sense & Sensibility the         4105 119957 0.03422060   0        \n",
              "13    Pride & Prejudice   of          3610 122204 0.02954077   0        \n",
              "14    Pride & Prejudice   and         3585 122204 0.02933619   0        \n",
              "15    Sense & Sensibility of          3571 119957 0.02976900   0        \n",
              "16    Sense & Sensibility and         3490 119957 0.02909376   0        \n",
              "17    Persuasion          the         3329  83658 0.03979297   0        \n",
              "18    Northanger Abbey    the         3179  77780 0.04087169   0        \n",
              "19    Emma                i           3177 160996 0.01973341   0        \n",
              "20    Emma                a           3129 160996 0.01943527   0        \n",
              "21    Mansfield Park      a           3099 160460 0.01931322   0        \n",
              "22    Mansfield Park      her         3082 160460 0.01920728   0        \n",
              "23    Persuasion          to          2808  83658 0.03356523   0        \n",
              "24    Persuasion          and         2800  83658 0.03346960   0        \n",
              "25    Mansfield Park      was         2651 160460 0.01652125   0        \n",
              "26    Persuasion          of          2570  83658 0.03072031   0        \n",
              "27    Sense & Sensibility her         2543 119957 0.02119926   0        \n",
              "28    Emma                it          2528 160996 0.01570225   0        \n",
              "29    Mansfield Park      in          2512 160460 0.01565499   0        \n",
              "30    Emma                her         2462 160996 0.01529231   0        \n",
              "⋮     ⋮                   ⋮           ⋮    ⋮      ⋮            ⋮        \n",
              "40350 Persuasion          withdrawing 1    83658  1.195343e-05 0.6931472\n",
              "40351 Persuasion          withdrawn   1    83658  1.195343e-05 0.0000000\n",
              "40352 Persuasion          withered    1    83658  1.195343e-05 1.0986123\n",
              "40353 Persuasion          withholding 1    83658  1.195343e-05 1.7917595\n",
              "40354 Persuasion          witness     1    83658  1.195343e-05 0.0000000\n",
              "40355 Persuasion          wm          1    83658  1.195343e-05 1.7917595\n",
              "40356 Persuasion          woe         1    83658  1.195343e-05 0.4054651\n",
              "40357 Persuasion          won         1    83658  1.195343e-05 0.6931472\n",
              "40358 Persuasion          wont        1    83658  1.195343e-05 0.4054651\n",
              "40359 Persuasion          wonted      1    83658  1.195343e-05 1.0986123\n",
              "40360 Persuasion          wood        1    83658  1.195343e-05 0.0000000\n",
              "40361 Persuasion          woody       1    83658  1.195343e-05 0.4054651\n",
              "40362 Persuasion          workmen     1    83658  1.195343e-05 0.6931472\n",
              "40363 Persuasion          works       1    83658  1.195343e-05 0.1823216\n",
              "40364 Persuasion          world's     1    83658  1.195343e-05 1.0986123\n",
              "40365 Persuasion          worsting    1    83658  1.195343e-05 1.7917595\n",
              "40366 Persuasion          wrapt       1    83658  1.195343e-05 0.4054651\n",
              "40367 Persuasion          wreck       1    83658  1.195343e-05 1.7917595\n",
              "40368 Persuasion          wretchedly  1    83658  1.195343e-05 0.0000000\n",
              "40369 Persuasion          wriggles    1    83658  1.195343e-05 1.7917595\n",
              "40370 Persuasion          wrinkles    1    83658  1.195343e-05 1.0986123\n",
              "40371 Persuasion          wrist       1    83658  1.195343e-05 1.0986123\n",
              "40372 Persuasion          yearly      1    83658  1.195343e-05 0.4054651\n",
              "40373 Persuasion          yeomen      1    83658  1.195343e-05 1.7917595\n",
              "40374 Persuasion          yestermorn  1    83658  1.195343e-05 1.7917595\n",
              "40375 Persuasion          yield       1    83658  1.195343e-05 0.1823216\n",
              "40376 Persuasion          younker     1    83658  1.195343e-05 1.7917595\n",
              "40377 Persuasion          youthful    1    83658  1.195343e-05 0.4054651\n",
              "40378 Persuasion          z           1    83658  1.195343e-05 1.7917595\n",
              "40379 Persuasion          zealously   1    83658  1.195343e-05 1.0986123\n",
              "      tf_idf      \n",
              "1     0           \n",
              "2     0           \n",
              "3     0           \n",
              "4     0           \n",
              "5     0           \n",
              "6     0           \n",
              "7     0           \n",
              "8     0           \n",
              "9     0           \n",
              "10    0           \n",
              "11    0           \n",
              "12    0           \n",
              "13    0           \n",
              "14    0           \n",
              "15    0           \n",
              "16    0           \n",
              "17    0           \n",
              "18    0           \n",
              "19    0           \n",
              "20    0           \n",
              "21    0           \n",
              "22    0           \n",
              "23    0           \n",
              "24    0           \n",
              "25    0           \n",
              "26    0           \n",
              "27    0           \n",
              "28    0           \n",
              "29    0           \n",
              "30    0           \n",
              "⋮     ⋮           \n",
              "40350 8.285486e-06\n",
              "40351 0.000000e+00\n",
              "40352 1.313218e-05\n",
              "40353 2.141767e-05\n",
              "40354 0.000000e+00\n",
              "40355 2.141767e-05\n",
              "40356 4.846699e-06\n",
              "40357 8.285486e-06\n",
              "40358 4.846699e-06\n",
              "40359 1.313218e-05\n",
              "40360 0.000000e+00\n",
              "40361 4.846699e-06\n",
              "40362 8.285486e-06\n",
              "40363 2.179368e-06\n",
              "40364 1.313218e-05\n",
              "40365 2.141767e-05\n",
              "40366 4.846699e-06\n",
              "40367 2.141767e-05\n",
              "40368 0.000000e+00\n",
              "40369 2.141767e-05\n",
              "40370 1.313218e-05\n",
              "40371 1.313218e-05\n",
              "40372 4.846699e-06\n",
              "40373 2.141767e-05\n",
              "40374 2.141767e-05\n",
              "40375 2.179368e-06\n",
              "40376 2.141767e-05\n",
              "40377 4.846699e-06\n",
              "40378 2.141767e-05\n",
              "40379 1.313218e-05"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUE11Oqqio8P"
      },
      "source": [
        "Se desejarmos, podemos ordenar a tabela por alguma dessas colunas (por exemplo, por tf_idf):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-11-10T17:33:24.116971Z",
          "start_time": "2020-11-10T17:33:24.079Z"
        },
        "id": "Jr_mzb_Vio8Q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "outputId": "36093aac-3a4c-421d-eacd-6cd8e954d428"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A tibble: 10 × 6</caption>\n",
              "<thead>\n",
              "\t<tr><th scope=col>book</th><th scope=col>word</th><th scope=col>n</th><th scope=col>tf</th><th scope=col>idf</th><th scope=col>tf_idf</th></tr>\n",
              "\t<tr><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><td>Sense &amp; Sensibility</td><td><span style=white-space:pre-wrap>elinor   </span></td><td>623</td><td>0.005193528</td><td>1.791759</td><td>0.009305552</td></tr>\n",
              "\t<tr><td>Sense &amp; Sensibility</td><td>marianne </td><td>492</td><td>0.004101470</td><td>1.791759</td><td>0.007348847</td></tr>\n",
              "\t<tr><td>Mansfield Park     </td><td>crawford </td><td>493</td><td>0.003072417</td><td>1.791759</td><td>0.005505032</td></tr>\n",
              "\t<tr><td><span style=white-space:pre-wrap>Pride &amp; Prejudice  </span></td><td><span style=white-space:pre-wrap>darcy    </span></td><td>373</td><td>0.003052273</td><td>1.791759</td><td>0.005468939</td></tr>\n",
              "\t<tr><td>Persuasion         </td><td>elliot   </td><td>254</td><td>0.003036171</td><td>1.791759</td><td>0.005440088</td></tr>\n",
              "\t<tr><td>Emma               </td><td>emma     </td><td>786</td><td>0.004882109</td><td>1.098612</td><td>0.005363545</td></tr>\n",
              "\t<tr><td>Northanger Abbey   </td><td>tilney   </td><td>196</td><td>0.002519928</td><td>1.791759</td><td>0.004515105</td></tr>\n",
              "\t<tr><td>Emma               </td><td>weston   </td><td>389</td><td>0.002416209</td><td>1.791759</td><td>0.004329266</td></tr>\n",
              "\t<tr><td><span style=white-space:pre-wrap>Pride &amp; Prejudice  </span></td><td><span style=white-space:pre-wrap>bennet   </span></td><td>294</td><td>0.002405813</td><td>1.791759</td><td>0.004310639</td></tr>\n",
              "\t<tr><td>Persuasion         </td><td>wentworth</td><td>191</td><td>0.002283105</td><td>1.791759</td><td>0.004090775</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ],
            "text/markdown": "\nA tibble: 10 × 6\n\n| book &lt;fct&gt; | word &lt;chr&gt; | n &lt;int&gt; | tf &lt;dbl&gt; | idf &lt;dbl&gt; | tf_idf &lt;dbl&gt; |\n|---|---|---|---|---|---|\n| Sense &amp; Sensibility | elinor    | 623 | 0.005193528 | 1.791759 | 0.009305552 |\n| Sense &amp; Sensibility | marianne  | 492 | 0.004101470 | 1.791759 | 0.007348847 |\n| Mansfield Park      | crawford  | 493 | 0.003072417 | 1.791759 | 0.005505032 |\n| Pride &amp; Prejudice   | darcy     | 373 | 0.003052273 | 1.791759 | 0.005468939 |\n| Persuasion          | elliot    | 254 | 0.003036171 | 1.791759 | 0.005440088 |\n| Emma                | emma      | 786 | 0.004882109 | 1.098612 | 0.005363545 |\n| Northanger Abbey    | tilney    | 196 | 0.002519928 | 1.791759 | 0.004515105 |\n| Emma                | weston    | 389 | 0.002416209 | 1.791759 | 0.004329266 |\n| Pride &amp; Prejudice   | bennet    | 294 | 0.002405813 | 1.791759 | 0.004310639 |\n| Persuasion          | wentworth | 191 | 0.002283105 | 1.791759 | 0.004090775 |\n\n",
            "text/latex": "A tibble: 10 × 6\n\\begin{tabular}{llllll}\n book & word & n & tf & idf & tf\\_idf\\\\\n <fct> & <chr> & <int> & <dbl> & <dbl> & <dbl>\\\\\n\\hline\n\t Sense \\& Sensibility & elinor    & 623 & 0.005193528 & 1.791759 & 0.009305552\\\\\n\t Sense \\& Sensibility & marianne  & 492 & 0.004101470 & 1.791759 & 0.007348847\\\\\n\t Mansfield Park      & crawford  & 493 & 0.003072417 & 1.791759 & 0.005505032\\\\\n\t Pride \\& Prejudice   & darcy     & 373 & 0.003052273 & 1.791759 & 0.005468939\\\\\n\t Persuasion          & elliot    & 254 & 0.003036171 & 1.791759 & 0.005440088\\\\\n\t Emma                & emma      & 786 & 0.004882109 & 1.098612 & 0.005363545\\\\\n\t Northanger Abbey    & tilney    & 196 & 0.002519928 & 1.791759 & 0.004515105\\\\\n\t Emma                & weston    & 389 & 0.002416209 & 1.791759 & 0.004329266\\\\\n\t Pride \\& Prejudice   & bennet    & 294 & 0.002405813 & 1.791759 & 0.004310639\\\\\n\t Persuasion          & wentworth & 191 & 0.002283105 & 1.791759 & 0.004090775\\\\\n\\end{tabular}\n",
            "text/plain": [
              "   book                word      n   tf          idf      tf_idf     \n",
              "1  Sense & Sensibility elinor    623 0.005193528 1.791759 0.009305552\n",
              "2  Sense & Sensibility marianne  492 0.004101470 1.791759 0.007348847\n",
              "3  Mansfield Park      crawford  493 0.003072417 1.791759 0.005505032\n",
              "4  Pride & Prejudice   darcy     373 0.003052273 1.791759 0.005468939\n",
              "5  Persuasion          elliot    254 0.003036171 1.791759 0.005440088\n",
              "6  Emma                emma      786 0.004882109 1.098612 0.005363545\n",
              "7  Northanger Abbey    tilney    196 0.002519928 1.791759 0.004515105\n",
              "8  Emma                weston    389 0.002416209 1.791759 0.004329266\n",
              "9  Pride & Prejudice   bennet    294 0.002405813 1.791759 0.004310639\n",
              "10 Persuasion          wentworth 191 0.002283105 1.791759 0.004090775"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "df <- book_tf_idf %>%\n",
        "  select(-total) %>%\n",
        "  arrange(desc(tf_idf))\n",
        "\n",
        "head(df,n=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Atividade que vale nota\n",
        "\n",
        "Defina um texto qualquer que contenha pelo menos 30 palavras (algumas delas repetidas). Para tanto, você criar um texto como foi feito pelo professor no primeiro exemplo ou pode carregar de um arquivo-texto disponível no seu computador (caso necessário, veja o material complementar sobre como carregar arquivos-texto, no Moodle). Você só não pode usar a biblioteca `janeaustenr`, mas pode usar a biblioteca `gutenbergr`, que tem outros textos (se necessário, procure no Google instruções de como usá-la).\n",
        "\n",
        "Depois, elabore um *script* que identifique os *tokens* desse texto e crie uma tabela (do tipo *tibble*) que armazene cada *token*. Para cada um deles, em uma coluna extra, indique se são ou não *stopwords*. Depois, inclua uma coluna que contenha o `stem` correspondente ao *token* em questão (use o algoritmo adequado para a língua do texto).\n",
        "\n",
        "Finalmente, crie uma nova tabela (do tipo *tible*) que contenha somente os `stems` que não são *stopwords*. Para cada um deles, indique (em colunas diferentes), seu total de ocorrências (frequência absoluta) e a frequência relativa (tf).\n",
        "\n",
        "Mostre o conteúdo dessa tabela por ordem de `tf`."
      ],
      "metadata": {
        "id": "Jot4AxdQXa2r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Carregar Bibliotecas\n",
        "if (!require('tidytext')) install.packages('tidytext')\n",
        "if (!require('tokenizers')) install.packages('tokenizers')\n",
        "if (!require('tm')) install.packages('tm')\n",
        "\n",
        "library(tidytext)\n",
        "library(tokenizers)\n",
        "library(tm)\n",
        "\n",
        "# texto\n",
        "texto <- \"O gato preto é um animal muito curioso. Ele gosta de explorar todos os cantos da casa, mas às vezes assusta os outros animais. O cachorro fica com medo quando o gato se esconde debaixo da cama. No entanto, eles são bons amigos.\""
      ],
      "metadata": {
        "id": "RKdAODahOXOv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c052fb8-7c2c-44ed-9bc5-7951cce331bd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading required package: tidytext\n",
            "\n",
            "Warning message in library(package, lib.loc = lib.loc, character.only = TRUE, logical.return = TRUE, :\n",
            "“there is no package called ‘tidytext’”\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "also installing the dependency ‘janeaustenr’\n",
            "\n",
            "\n",
            "Loading required package: tm\n",
            "\n",
            "Warning message in library(package, lib.loc = lib.loc, character.only = TRUE, logical.return = TRUE, :\n",
            "“there is no package called ‘tm’”\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "also installing the dependencies ‘NLP’, ‘slam’, ‘BH’\n",
            "\n",
            "\n",
            "Loading required package: NLP\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define lista de stopwords\n",
        "stopwords <- tibble(palavra = append(tm::stopwords('portuguese'), list('é', 'um', 'os', 'da', 'de', 'se', 'no', 'com', 'as', 'os', 'mas', 'e')))"
      ],
      "metadata": {
        "id": "1e_pVfpdzSjw"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenização do texto\n",
        "tokens <- texto %>%\n",
        "  tokenize_words() %>%\n",
        "  unlist()"
      ],
      "metadata": {
        "id": "feDx66JZzq45"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Converte para tibble\n",
        "tokens_df <- tibble(token = tokens)"
      ],
      "metadata": {
        "id": "pqPwRvjzzxpx"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verifica se os tokens são stopwords\n",
        "tokens_df <- tokens_df %>%\n",
        "  mutate(stopwords = token %in% stopwords$palavra)"
      ],
      "metadata": {
        "id": "A2dde1pfz0w3"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encontra os stems dos tokens\n",
        "tokens_df <- tokens_df %>%\n",
        "  mutate(terminacao = SnowballC::wordStem(token, language = \"portuguese\"))"
      ],
      "metadata": {
        "id": "C6t5oUzV0B8a"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtra os tokens que não são stopwords\n",
        "stopwords_no <- tokens_df %>%\n",
        "  filter(!stopwords) %>%\n",
        "  count(terminacao, sort = TRUE)"
      ],
      "metadata": {
        "id": "XDK40nyt0Ged"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcula a frequência relativa (tf)\n",
        "total_stopwords_no <- sum(stopwords_no$n)\n",
        "stopwords_no <- stopwords_no %>%\n",
        "  mutate(tf = n / total_stopwords_no)"
      ],
      "metadata": {
        "id": "RhFC1EA20cr8"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Renomeia as colunas\n",
        "colnames(stopwords_no) <- c(\"terminacao\", \"frequencia_absoluta\", \"frequencia_relativa\")"
      ],
      "metadata": {
        "id": "PUtn5GI10uDg"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mostra a tabela por ordem de tf\n",
        "stopwords_no %>%\n",
        "  arrange(desc(frequencia_relativa))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 788
        },
        "id": "HNv9468r06Oz",
        "outputId": "6e65ae3c-781b-4252-b4a9-37d9f60dff9f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A tibble: 22 × 3</caption>\n",
              "<thead>\n",
              "\t<tr><th scope=col>terminacao</th><th scope=col>frequencia_absoluta</th><th scope=col>frequencia_relativa</th></tr>\n",
              "\t<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><td>gat    </td><td>2</td><td>0.08695652</td></tr>\n",
              "\t<tr><td>amig   </td><td>1</td><td>0.04347826</td></tr>\n",
              "\t<tr><td>anim   </td><td>1</td><td>0.04347826</td></tr>\n",
              "\t<tr><td>animal </td><td>1</td><td>0.04347826</td></tr>\n",
              "\t<tr><td>assust </td><td>1</td><td>0.04347826</td></tr>\n",
              "\t<tr><td>bons   </td><td>1</td><td>0.04347826</td></tr>\n",
              "\t<tr><td>cachorr</td><td>1</td><td>0.04347826</td></tr>\n",
              "\t<tr><td>cam    </td><td>1</td><td>0.04347826</td></tr>\n",
              "\t<tr><td>cant   </td><td>1</td><td>0.04347826</td></tr>\n",
              "\t<tr><td>cas    </td><td>1</td><td>0.04347826</td></tr>\n",
              "\t<tr><td>curios </td><td>1</td><td>0.04347826</td></tr>\n",
              "\t<tr><td>debaix </td><td>1</td><td>0.04347826</td></tr>\n",
              "\t<tr><td>entant </td><td>1</td><td>0.04347826</td></tr>\n",
              "\t<tr><td>escond </td><td>1</td><td>0.04347826</td></tr>\n",
              "\t<tr><td>explor </td><td>1</td><td>0.04347826</td></tr>\n",
              "\t<tr><td>fic    </td><td>1</td><td>0.04347826</td></tr>\n",
              "\t<tr><td>gost   </td><td>1</td><td>0.04347826</td></tr>\n",
              "\t<tr><td>med    </td><td>1</td><td>0.04347826</td></tr>\n",
              "\t<tr><td>outr   </td><td>1</td><td>0.04347826</td></tr>\n",
              "\t<tr><td>pret   </td><td>1</td><td>0.04347826</td></tr>\n",
              "\t<tr><td>tod    </td><td>1</td><td>0.04347826</td></tr>\n",
              "\t<tr><td>vez    </td><td>1</td><td>0.04347826</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ],
            "text/markdown": "\nA tibble: 22 × 3\n\n| terminacao &lt;chr&gt; | frequencia_absoluta &lt;int&gt; | frequencia_relativa &lt;dbl&gt; |\n|---|---|---|\n| gat     | 2 | 0.08695652 |\n| amig    | 1 | 0.04347826 |\n| anim    | 1 | 0.04347826 |\n| animal  | 1 | 0.04347826 |\n| assust  | 1 | 0.04347826 |\n| bons    | 1 | 0.04347826 |\n| cachorr | 1 | 0.04347826 |\n| cam     | 1 | 0.04347826 |\n| cant    | 1 | 0.04347826 |\n| cas     | 1 | 0.04347826 |\n| curios  | 1 | 0.04347826 |\n| debaix  | 1 | 0.04347826 |\n| entant  | 1 | 0.04347826 |\n| escond  | 1 | 0.04347826 |\n| explor  | 1 | 0.04347826 |\n| fic     | 1 | 0.04347826 |\n| gost    | 1 | 0.04347826 |\n| med     | 1 | 0.04347826 |\n| outr    | 1 | 0.04347826 |\n| pret    | 1 | 0.04347826 |\n| tod     | 1 | 0.04347826 |\n| vez     | 1 | 0.04347826 |\n\n",
            "text/latex": "A tibble: 22 × 3\n\\begin{tabular}{lll}\n terminacao & frequencia\\_absoluta & frequencia\\_relativa\\\\\n <chr> & <int> & <dbl>\\\\\n\\hline\n\t gat     & 2 & 0.08695652\\\\\n\t amig    & 1 & 0.04347826\\\\\n\t anim    & 1 & 0.04347826\\\\\n\t animal  & 1 & 0.04347826\\\\\n\t assust  & 1 & 0.04347826\\\\\n\t bons    & 1 & 0.04347826\\\\\n\t cachorr & 1 & 0.04347826\\\\\n\t cam     & 1 & 0.04347826\\\\\n\t cant    & 1 & 0.04347826\\\\\n\t cas     & 1 & 0.04347826\\\\\n\t curios  & 1 & 0.04347826\\\\\n\t debaix  & 1 & 0.04347826\\\\\n\t entant  & 1 & 0.04347826\\\\\n\t escond  & 1 & 0.04347826\\\\\n\t explor  & 1 & 0.04347826\\\\\n\t fic     & 1 & 0.04347826\\\\\n\t gost    & 1 & 0.04347826\\\\\n\t med     & 1 & 0.04347826\\\\\n\t outr    & 1 & 0.04347826\\\\\n\t pret    & 1 & 0.04347826\\\\\n\t tod     & 1 & 0.04347826\\\\\n\t vez     & 1 & 0.04347826\\\\\n\\end{tabular}\n",
            "text/plain": [
              "   terminacao frequencia_absoluta frequencia_relativa\n",
              "1  gat        2                   0.08695652         \n",
              "2  amig       1                   0.04347826         \n",
              "3  anim       1                   0.04347826         \n",
              "4  animal     1                   0.04347826         \n",
              "5  assust     1                   0.04347826         \n",
              "6  bons       1                   0.04347826         \n",
              "7  cachorr    1                   0.04347826         \n",
              "8  cam        1                   0.04347826         \n",
              "9  cant       1                   0.04347826         \n",
              "10 cas        1                   0.04347826         \n",
              "11 curios     1                   0.04347826         \n",
              "12 debaix     1                   0.04347826         \n",
              "13 entant     1                   0.04347826         \n",
              "14 escond     1                   0.04347826         \n",
              "15 explor     1                   0.04347826         \n",
              "16 fic        1                   0.04347826         \n",
              "17 gost       1                   0.04347826         \n",
              "18 med        1                   0.04347826         \n",
              "19 outr       1                   0.04347826         \n",
              "20 pret       1                   0.04347826         \n",
              "21 tod        1                   0.04347826         \n",
              "22 vez        1                   0.04347826         "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4e_Gl2foio8Q"
      },
      "source": [
        "# Referências\n",
        "- Aggarwal, Charu C..  1994. **Data Mining**: the Textbook. Springer: Cham. 2015. https://link.springer.com/book/10.1007%2F978-3-319-14142-8\n",
        "- Bengfort, B.; Bilbro, R.; Ojeda, T. **Applied Text Analysis with Python**: Enabling Language-Aware Data Products with Machine Learning. O´Reilly, 2018. 334 p.\n",
        "- Fayyad, U M.; Piatetsky-Shapiro, G.; Smyth, P.; Uthurusamy, R. **Advances in Knowledge Discovery and Data Mining**. AAAI Press. 1996. 626 p.\n",
        "- Feldman, R.; Hirsh, H. Exploiting Background Information in Knowledge Discovery from Text. **Journal of Intelligent Informatino Systems**, 9, 83-92. 1997. https://doi.org/10.1023/A:1008693204338\n",
        "- Goldschmidt, R.; Passos, E.; Bezerra, E. **Data Mining**: Conceitos, Técnicas, Algoritmos, Orientações e Aplicações. 2a Ed. Campus/Elsevier, São Paulo. 2015. https://bridge.minhabiblioteca.com.br/books/9788595156395\n",
        "- Tan, A. H. Text mining: the state of the art and the challenges. In: Workshop on Knowledge Discovery from Advanced Databases, 1999. **Proceedings...** Heidelberg, 1999. p.65-70."
      ]
    }
  ],
  "metadata": {
    "celltoolbar": "Slideshow",
    "hide_input": false,
    "kernelspec": {
      "display_name": "R",
      "language": "R",
      "name": "ir"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}